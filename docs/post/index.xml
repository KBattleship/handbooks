<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Quinn</title>
    <link>https://example.com/post/</link>
    <description>Recent content in Posts on Quinn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 02 Mar 2021 11:13:47 +0800</lastBuildDate><atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ Pulsar ] 1. Pulsar本地安装</title>
      <link>https://example.com/p/pulsar-1.-pulsar%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85/</link>
      <pubDate>Tue, 02 Mar 2021 11:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/pulsar-1.-pulsar%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85/</guid>
      <description>Pulsar本地单机安装 1. OS要求  目前Pulsar仅支持操作系统 MacOS 与 Linux，使用Pulsar，需保证已安装 Oracle的 Java 8 运行环境。
 2. 安装二进制版本 </description>
    </item>
    
    <item>
      <title>[ Standard ] 1.关于Restful规范</title>
      <link>https://example.com/p/standard-1.%E5%85%B3%E4%BA%8Erestful%E8%A7%84%E8%8C%83/</link>
      <pubDate>Mon, 01 Mar 2021 11:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/standard-1.%E5%85%B3%E4%BA%8Erestful%E8%A7%84%E8%8C%83/</guid>
      <description>关于Restful规范 1. Restful API Design定义 2. Action命名规范 3. 自定义方法 3.1 </description>
    </item>
    
    <item>
      <title>[ Interview ] 2. 面试之算法</title>
      <link>https://example.com/p/interview-2.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E7%AE%97%E6%B3%95/</link>
      <pubDate>Fri, 08 Jan 2021 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/interview-2.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E7%AE%97%E6%B3%95/</guid>
      <description>面试之算法 1. 删除UserList中年龄大于20的User对象 // User实体类 public class User{ private Integer age; public Integet getAge(){ return this.age; } } 解题思路：
此题按照最简单的lambda方式进行解答(JDK8才支持)
public class Main{ public static void remove(List&amp;lt;User&amp;gt; userList){ // removeIf(Predicate&amp;lt;? super E&amp;gt; filter)  userList.removeIf(x -&amp;gt; x != null &amp;amp;&amp;amp; x.getAge() != null &amp;amp;&amp;amp; x.getAge() &amp;gt; 20); } } 2. 从1000W个数中取出最小的10个数，并按照顺序打印。 解题思路： 首先应该想到堆排序(Top K堆问题)，大根堆(前k小)或小根堆(后k大)。在Java中有已经实现的PriorityQueue，解决此问题将最为简单，复杂度为O(NlogK)。
本题是求前K小，因此选用一个容量为K的大根堆，每次poll出最大的数，则堆中保留的则是前K项小。(谨记：需要不可用小根堆，小根堆需把全部元素入堆，时间复杂度为O(NlogN),将不再是O(NlogK))，Java中PriorityQueue默认为小根堆，需作出调整重写比较器。
public class MaxHeap { public static void main(String[] args) { int[] arr = new int[]{10,1,0,9,22,77,12,883,99983,2772,848,3663,2626,737,2772,8388,266,83,72,7272,83883,27727,263,840,2740,884}; print(arr); } public static void print2(int[] arr) { int k = 10; int[] vec = new int[k]; // 重写PriorityQueue为大根堆  // PriorityQueue&amp;lt;Integer&amp;gt; queue = new PriorityQueue&amp;lt;&amp;gt;();默认为小根堆  PriorityQueue&amp;lt;Integer&amp;gt; queue = new PriorityQueue&amp;lt;&amp;gt;((num1, num2) -&amp;gt; num2 - num1); for (int i = 0; i &amp;lt; k; ++i) { queue.</description>
    </item>
    
    <item>
      <title>[ Interview ] 3. 面试之Java</title>
      <link>https://example.com/p/interview-3.-%E9%9D%A2%E8%AF%95%E4%B9%8Bjava/</link>
      <pubDate>Fri, 08 Jan 2021 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/interview-3.-%E9%9D%A2%E8%AF%95%E4%B9%8Bjava/</guid>
      <description>面试 X_Q 1.JVM垃圾回收机制 Java编程中，程序员不需要刻意显式进行垃圾回收去释放一个对象内存，而是JVM会进行自动垃圾回收。 JVM中存在一个 优先级较低 的线程，只有当 JVM处于空闲 或者 堆空间不足 的情况触发执行。此过程中，将扫描到 没有被引用的对象 防止垃圾回收集合中，进行垃圾回收。
 判断对象是否可以被回收   引用计数器：
 为每一个对象创建一个引用计数器，有引用此对象，计数器进行+1；引用释放后，计数器进行-1。当对象引用计数器 == 0时，说明此对象可以进行回收。(不能解决循环引用问题)    可达性分析算法
 从GC Roots开始向下搜索，走过的搜索路径将形成引用链，当一个对象到 GC Roots不存在任何引用链式，说明此对象可以进行回收。      2.什么是Netty？  见 Netty
 3.Netty粘包/拆包 3.Kubernetes工作原理 4.快排实现原理 B_D 1. Hash最终一致性算法   算法目标：
当K个Key的请求时，后台增减节点，只会引起 K/N 的 Key发生重新映射。
 在后台节点稳定时，同一个key的每次请求映射到的节点是一样的。 在后台节点增减时，此算法尽量将 K 个Key映射到之前相同的节点上。    Hash存在问题：
 假定N为后台服务节点数，当前台携带关键字key发出请求时，我们通常将key进行Hash后采用 模运算(hash(key)%N) 来讲请求分发在不同的节点上。 对前台请求于后台无状态服务节点不敏感的场景而言，只要请求key具有一定的随机性，哪怕节点动态增删，该算法对于后台而言一样可以起到很好的负载均衡效果。 但在对于分布式缓存，或者分布式数据这样有状态服务的情况下，上述方式将存在问题。因为后台节点的增删会引起几乎所有的Key的重新映射：  针对分布式缓存而言，均发生cache miss； 针对分布式数据库而言，发生数据错乱的情况，影响都是灾难性的。      判断标准：</description>
    </item>
    
    <item>
      <title>[ RocketMQ ] 1.面试</title>
      <link>https://example.com/p/rocketmq-1.%E9%9D%A2%E8%AF%95/</link>
      <pubDate>Fri, 08 Jan 2021 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/rocketmq-1.%E9%9D%A2%E8%AF%95/</guid>
      <description>面试准备 1. 什么是解耦 2. 什么是异步 3. 什么是消峰填谷 4. RocketMQ执行流程 5. 怎么理解Producer 6. 怎么理解Consumer 7. 消费者消费模式有哪些 8. 消费者获取消息有几种模式 9. 定时消息是什么样的？如何实现的？ 10. RocketMQ如何保证高可用的？ 11. 如何保证消息不被重复消费？或者说如何保证消息消费是的幂等性？ 12. 如何保证消息的可靠性传输？若消息出现丢失如何处理？ 13. 如何保证消息的顺序性？ 14. 如何解决消息队列的延时以及过期失效问题？ 15. 消息队列满了以后如何处理？有几百万消息持续挤压几小时，如何解决？ 16. 如何解决高性能读写数据问题？ </description>
    </item>
    
    <item>
      <title>[ Interview ] 1. 面试之清单</title>
      <link>https://example.com/p/interview-1.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%B8%85%E5%8D%95/</link>
      <pubDate>Thu, 07 Jan 2021 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/interview-1.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%B8%85%E5%8D%95/</guid>
      <description>面试之清单  加粗加斜 : 为本人面试所遇到重复出现的点儿 加粗 : 为本人面试所遇到的点儿 正常 : 为本人面试刷的面经  Algorithm Sort  手撸插入排序 手撸二分查找 堆排序(Top K) 快素排序思想 反转单链表 合并二叉树(递归与非递归两种办法)  Java Basic  Object是所有对象的父类，那Object类中有哪些方法 hashCode()与equals()有什么关系 String、StringBuilder、StringBuffer区别 反射机制 方法(静态、一般方法)；代码块(this，ClassName.class)  Collections  List之ArrayList List之LinkedList List之Vector Map之HashMap Map之LinkedHashMap Map之ConcurrentHashMap Map之TreeMap HashTable Set之HashSet Set之TreeSet Queue之ArrayBlockingQueue Queue之ConcurrentLinkedQueue Queue之LinkedBlockingQueue  Thread  线程的几种状态以及如何转化的 三种线程初始化方法的区别(Thread,Callable,Runnable) 线程池几个重要参数 线程池四种拒绝策略 线程池四个类型 线程池(ThreadPoolExecutor)原理 关于锁 synchronized锁以及锁升级 ReentrantLock与synchronized区别 有界、无界任务队列，手写BlockingQueue ThreadLocal：底层数据结构、ThreadLocalMap、原理、应用场景 Atomic类：原理、应用场景 Volatile：原理、有序性、可见性  JVM   JVM内存结构
  final修饰的常量处于JVM中哪部分内存</description>
    </item>
    
    <item>
      <title>[ Netty ] 1.Netty基础</title>
      <link>https://example.com/p/netty-1.netty%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Tue, 05 Jan 2021 10:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/netty-1.netty%E5%9F%BA%E7%A1%80/</guid>
      <description>Netty基础 从一答一问开始Netty 1. 为什么用Netty？ a. Netty是一个基于JDK NIO的Client/Server架构的框架。可以快速进行网络开发; b. 相比JDK NIO，极大简化TCP、UDP套接字服务器网络变成，并且性能、安全性出色; c. 支持多种协议：FTP、SMTP、HTTP以及各种二进制和基于文本的传统协议; d. 统一的API、支持多种传输类型(阻塞、非阻塞I/O); e. 简单且强大的线程模型; f. 自带编解码器解决粘包、拆包问题; g. 自带各种协议栈; h. 安全性不错，支持完整的SSL/TLS及StartTLS协议; i. 相比JDK NIO，API具有更高吞吐量、更低延迟、更低资源消耗和更少的内存复制; j. 成熟项目很多：Dubbo、RocketMQ。 2. Netty应用场景 a. RPC框架的网络通信工具 b. 自实现HTTP服务器 c. 实现即时通信系统 d. 实现消息推送系统 3. Netty核心组件   Channel
对网络操作的抽象类。除I/O基本操作之外，支持bind(),connect(),read(),write()操作。
  EventLoop
EventLoop是Netty的核心抽象，用于处理连接在生命周期中所发生的事件。 主要作用：负责监听网络事件并调用事件处理器进行相关的I/O操作。
EventLoop 负责处理注册到其上的 Channel 处理I/O操作，两者配合参与I/O操作。
  ChannelFuture
Netty是异步非阻塞，所有的I/O操作都是异步。所以不可以立即得到操作结果。但是
（1）通过 ChannelFuture 接口的 addListener() 注册一个 ChannelFutureListener 对象，操作执行成功或失败后，监听会自动触发返回结果；
（2）也可以通过 ChannelFuture 的 channel() 获取关联的 Channel 对象；</description>
    </item>
    
    <item>
      <title>[ Interview ] 2.面试准备</title>
      <link>https://example.com/p/interview-2.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</link>
      <pubDate>Tue, 05 Jan 2021 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/interview-2.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</guid>
      <description>面试准备 一、学习路线 1.Java基础  面向对象特性：封装、继承、多态(动态绑定、向上转型) 泛型、类型擦除 反射、其原理及其优缺点 static,final关键字 String,StringBuffer,StringBuilder底层区别 BIO、NIO、AIO Object类的方法 自动拆箱与自动装箱  2.集合框架  List  ArrayList LinkedList Vector CopyOnWriteArrayList   Set  HashSet TreeSet LinkedHashSet   Queue  PriorityQueue   Map  HashMap TreeMap LinkedMap   fast-fail，fast-safe机制 源码分析(底层数据结构，插入、扩容过程)、线程安全分析  3.Java虚拟机  类加载机制、双亲委派模式、3种加载器(BootstrapClassLoader，ExtensionClassLoader，ApplicationClassLoader) 运行时内存分区(PC，Java虚拟机栈，本地方法栈，堆，方法区[永久代、元空间]) JMM: Java内存模型分析 引用计数、可达性分析 垃圾回收算法：标记-清除、标记-整理、复制 垃圾回收器：比较区别(Serial，ParNew，ParallelScavenge，CMS，G1) 强、软、弱、虚引用 内存溢出、内存泄漏排查 JVM调优、常用命令  4.Java并发  三种线程初始化方法的区别(Thread,Callable,Runnable) 线程池(ThreadPoolExecutor，7大参数、原理、四种拒绝策略、四个类型[Fixed、Single、Cached、Scheduled]) Synchronized 使用：方法(静态、一般方法)；代码块(this，ClassName.class) jdk1.6优化：锁粗化、锁消除、自适应自旋锁、偏向锁、轻量级锁 锁升级的过程与细节：无锁-&amp;gt;偏向锁-&amp;gt;轻量级锁-&amp;gt;重量级锁(不可逆) ReentrantLock:与Synchronized区别、公平锁、非公平锁、可中断锁、原理、用法 有界、无界任务队列，手写BlockingQueue 乐观锁：CAS(优缺点，ABA问题，DCAS) 悲观锁 ThreadLocal：底层数据结构、ThreadLocalMap、原理、应用场景 Atomic类：原理、应用场景 Volatile：原理、有序性、可见性  5.</description>
    </item>
    
    <item>
      <title>[ Interview ] 1.面试准备</title>
      <link>https://example.com/p/interview-1.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</link>
      <pubDate>Thu, 31 Dec 2020 11:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/interview-1.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</guid>
      <description>面试准备  Java线程池  JDK中JUC包  JVM调优：如果发现某个服务慢，如何排查，如何处理；发现某个服务器CPU100%了，应该如何处理 遵循六步走原则： 1）找到罪魁祸首的进程 2）分析进程对应的线程 3）生成JVM当前时刻线程快照 4）分析定位代码问题 5）  垃圾回收器G1与GC算法CMS  Tomcat 如何实现类隔离  Spring IOC原理  Spring AOP原理  Spring事务  Dubbo服务发现、注册流程  Dubbo通信原理  Dubbo SPI与Java SPI  Zookeeper选举协议  大数据量的排序如何处理  如何判断链表是回文链表、快排序、归并排序  MySQL调优：B+ Tree索引、Hash索引  Mybatis的一、二级缓存  Mybatis工作原理  Redis Bitmap  </description>
    </item>
    
    <item>
      <title>[ Dubbo ] 2. Dubbo中的SPI</title>
      <link>https://example.com/p/dubbo-2.-dubbo%E4%B8%AD%E7%9A%84spi/</link>
      <pubDate>Fri, 25 Dec 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/dubbo-2.-dubbo%E4%B8%AD%E7%9A%84spi/</guid>
      <description>Dubbo中的SPI 1. Dubbo SPI与Java SPI  SPI(Service Provider Interface)，主要用于框架，框架定义接口。   不同使用者将存在不同需求，也必然出现不同实现方式。
  而SPI就是通过定义一个特定的位置，Java SPI约定在Classpath下的META-INF/services/路径下创建一个以服务接口命名的文件，然后文件中记录的是此jar包提供的具体实现类的全限定名，并由服务加载器读取配置文件，加载实现类，这样可以在运行时动态为接口替换实现类。
  Dubbo SPI
 并非是Java原生的SPI，而是重新实现的SPI。   Java SPI通过ServiceLoader进行加载； Dubbo SPI通过ExtensionLoader进行拓展加载。  支持的注解：  @SPI(标记为拓展接口) @Adaptive(自适应拓展实现类标志) @Activate(自动激活条件标记)   配置文件放在classpath下的META-INF/dubbo/以及 META-INF/dubbo/internal下 Dubbo SPI增加了对拓展点IOC和AOP的支持，一个拓展点可以直接通过Setter注入其他拓展点。 Java SPI会一次性实例化拓展点所有实现，如果有拓展实现初始化过程很耗时，并且用不上，将会造成资源浪费。    Dubbo中SPI的具体实现
 协议扩展(Protocol)：RPC协议扩展，用于封装远程调用细节 调用拦截扩展(Filter)：服务提供方和服务消费方调用过程拦截，Dubbo本身大多数功能都是基于此扩展点实现，每次远程方法执行，该拦截都会被执行 引用监听扩展(InvokerListener)：当有服务被引用时触发此事件 暴露监听扩展(ExporterListener)：当有服务被暴露时触发此事件 集群扩展(Cluster)：当存在多个服务提供方时，将多个服务提供方组成一个集群，并伪装成一个服务提供方 路由扩展(RouterFactory)：从多个服务提供方中选择一个进行调用 负载均衡(LoadBalance)：从多个服务提供方中选择一个进行调用 合并扩展(Merger)：合并返回结果，用于分组聚合 注册中心扩展(Registry)：负责服务的注册与发现 监控扩展(Monitor) ：负责服务调用次数以及调用时间的监控 扩展点加载扩展(ExtensionFactory)：扩展本身的加载容器，可从不同容器加载扩展点 动态代理扩展(ProxyFactory)：将Invoker接口转换成业务接口 编译器扩展(Compiler)： Java代码编译器，用于动态生成字节码，加速调用 配置中心扩展(DynamicConfiguration)：作为Key-Value存储 消息派发扩展(Dispatcher)：通道信息派发器，用于指定线程池模型 线程池扩展(ThreadPool)：服务提供方线程池的实现策略 序列化扩展(Serialization)：将对象转化成字节流，用于网络传输，以及将字节流转为对象，用于接收到字节流数据时还原成对象 网络传输扩展(Transporter)：远程通信的服务器以及客户端传输实现 信息交换扩展(Exchange)：`` 组网扩展(Networker)：对等网络节点组网器 Telnet命令扩展(TelnetHandler)：所有服务器均支持telnet访问，用于人工干预 状态检查扩展(StatusChecker)：检查服务依赖各种资源的状态，此状态检查可同时用于telnet的status命令和hosting的status页面 容器扩展(Container)：服务容器扩展，用于自定义加载内容 缓存扩展(CacheFactory)：用于请求参数作为Key，缓存返回结果 验证扩展(Validation)：参数验证扩展点 日志适配扩展(LoggerAdapter)：日志输出适配扩展点      2.</description>
    </item>
    
    <item>
      <title>[ Dubbo ] 3-1. Dubbo SPI中的Protocol扩展点</title>
      <link>https://example.com/p/dubbo-3-1.-dubbo-spi%E4%B8%AD%E7%9A%84protocol%E6%89%A9%E5%B1%95%E7%82%B9/</link>
      <pubDate>Fri, 25 Dec 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/dubbo-3-1.-dubbo-spi%E4%B8%AD%E7%9A%84protocol%E6%89%A9%E5%B1%95%E7%82%B9/</guid>
      <description>Dubbo SPI中的Protocol扩展点 </description>
    </item>
    
    <item>
      <title>[ Dubbo ] 3-2. Dubbo SPI中的Filter扩展点</title>
      <link>https://example.com/p/dubbo-3-2.-dubbo-spi%E4%B8%AD%E7%9A%84filter%E6%89%A9%E5%B1%95%E7%82%B9/</link>
      <pubDate>Fri, 25 Dec 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/dubbo-3-2.-dubbo-spi%E4%B8%AD%E7%9A%84filter%E6%89%A9%E5%B1%95%E7%82%B9/</guid>
      <description>Dubbo SPI中的Filter扩展点 </description>
    </item>
    
    <item>
      <title>[ Dubbo ] 3. Dubbo通信原理</title>
      <link>https://example.com/p/dubbo-3.-dubbo%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 25 Dec 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/dubbo-3.-dubbo%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</guid>
      <description>Dubbo通信原理 1. Dubbo多线程通信原理  获取DubboInvoker对象； 将请求体信息封装在一个Request对象中，Request中会包括一个自增的id； 然后将Request存到一个ConcurrentHashMap中（key=id，value= DefaultFuture）,将request数据写入Channel Consumer Thread执行Defaultfuture#get()方法等待返回结果 服务提供方创建多线程处理用户请求，并将放回结果封装在Response中（包括Request#id）将response写入Channel 消费方从Channel中收到数据以后，解析出id，从Map中解析出DefaultFuture唤醒Consumer Thread，返回结果 DefaultFuture也会启动一个定时程序，检查在timeout内，结果是否返回，如果未返回，将DefaultFuture从map中移除，并抛出超时异常  </description>
    </item>
    
    <item>
      <title>[ Dubbo ] 1.Dubbo基础概念</title>
      <link>https://example.com/p/dubbo-1.dubbo%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Tue, 22 Dec 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/dubbo-1.dubbo%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</guid>
      <description>Dubbo基础概念 1.Dubbo核心组件  Provider： 暴露服务的服务提供方 Consumer： 调用远程服务的消费方 Register： 服务注册与发现注册中心 Monitor： 监控中心和访问调用统计 Container：服务运行时容器   Dubbo分层主要为业务层、RPC层和Remote层，如果把每层进行详细划分的话，整体划分为：
  业务层：  service: 包含各业务代码的接口与实现；   RPC层：  config: 配置层，主要围绕ServiceConfig(暴露的服务配置)和ReferenceConfig(引用的服务配置)两个类展开，初始化配置信息； proxy: 服务代理层，不论生产者还是消费者，Dubbo都会生成一个代理类，在调用远程接口时，就可以像本地接口一样，代理层自动做远程调用并返回结果； registry: 注册层，负责Dubbo框架的服务注册与发现； cluster: 集群容错层，主要负责远程调用失败时的集群容错策略(如快速失败、快速重试等)； monitor: 监控层，负责监控统计调用次数和调用时间等； protocol: 远程调用层，封装RPC调用具体过程，是Invoker暴露和引用的主要功能入口，负责管理Invoker的整个生命周期；   Remote层：  exchange: 信息交换层，封装请求相应模式，如同步请求转换为异步请求； transport: 网络传输层，把网络传输抽象为统一接口； serialize: 序列化层，将需要网络传输的数据极性序列化，转为二进制流。    2.Dubbo服务注册与发现流程  Container负责启动，加载，运行服务提供者 Provider启动时，向注册中心注册自己并提供服务 Consumer启动时，向注册中心订阅自已需调用服务 Register返回服务提供者地址列表给服务消费者，如运行期间，服务提供者发生变动，将通过长连接推送至服务消费者 Consumer通过负载均衡算法(软方式)，选取注册中心所返回的服务提供者列表中的一个节点进行调用，如果调用失败将尝试其他节点进行调用 Consumer、Provider将调用次数、时间记录于内存中，并定时每分钟发送至Monitor监控中心  3-1. Dubbo服务暴露过程  Dubbo 会在 Spring 实例化完 bean 之后， 在刷新容器最后一步发布 ContextRefreshEvent 事件的时候，通知实现了 ApplicationListener 的 ServiceBean 类进行回调 onApplicationEvent 事件方法。 Dubbo 会在这个方法中调用 ServiceBean 父类 ServiceConfig 的 export 方法，而该方法真正实现了服务的发布。  3-2.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 3-1.深入Service</title>
      <link>https://example.com/p/kubernetes-3-1.%E6%B7%B1%E5%85%A5service/</link>
      <pubDate>Fri, 18 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-3-1.%E6%B7%B1%E5%85%A5service/</guid>
      <description>深入Service  Service是Kubernetes最为核心的概念。Service可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发至后端的各个容器应用上。
 1.Service参数定义 # 必填，版本号apiVersion:v1# 必填kind:Service# 必填，元数据metadata:# 必填，Service名称(符合RFC 1035规范)name:string# 必填，命名空间(默认default)namespace:string# 自定义标签属性列表labels:- name:string# 自定义注解属性列表annotations:- name:string# 必填，配置内容详细描述 spec:# 必填，LabelSelector配置，将选择具有特定Label标签的Pod对象作为管理对象selector:[]# 必填，可选值[ClusterIP | NodePort | LoadBalancer]## ClusterIP:虚拟服务IP地址，该地址用于Kubernetes集群内部Pod对象访问，#在Node节点上Kube-proxy通过设置的Iptables规则进行转发## NodePort:使用宿主机端口，使能够访问各Node的外部客户端通过Node的#IP地址和端口号即可访问到应用。## LoadBalancer:使用外接负载均衡器完成到服务的负载分发，需要#spec.status.loadBalaner字段指定外部负载均衡器的IP地址，并同时定义#nodePort和clusterIP，用于公有云环境。type:string# 虚拟服务IP地址：当type为ClusterIP时，如果不指定将自动进行分配；也可手动指定。#当type为LoadBalancer时，必须指定clusterIP:string# 是否支持Session，可选值为ClientIP，默认值为空。#ClientIP表示将同一个客户端(有客户端IP地址决定)的访问请求都转发到同一个后端#Pod对象sessionAffinity:string# Service需要暴露的端口列表ports:- name:string# 端口协议：TCP/UDP(默认TCP)protocol:string# 服务监听端口号port:int# 需要转发到后端Pod对象的端口号targetPort:int# type为NodePort时，指定映射到物理机的端口号nodePort:int# type为LoadBalancer时，设置外部负载均衡器的地址，用于公有云环境。status:# 外部负载均衡器loadBalancer:ingress:ip:stringhostname:string</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 2-1.了解Pod对象</title>
      <link>https://example.com/p/kubernetes-2-1.%E4%BA%86%E8%A7%A3pod%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Thu, 17 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-2-1.%E4%BA%86%E8%A7%A3pod%E5%AF%B9%E8%B1%A1/</guid>
      <description>了解Pod对象 1.Pod参数定义 # 必填,版本号apiVersion:stringkind:Pod# 必填,元数据metadata:# 必填,Pod对象的名称(命名规范需要符合RFC 1035规范)name:string# 必填,Pod对象所属的命名空间,默认值为defaultnamespace:string# 自定义标签列表(取值类型:List)labels:- name:string# 自定义标签注解(取值类型:List)annotations:- name:string# 必填,Pod对象中容器的详细定义 spec:# 必填,Pod对象容器列表(取值类型:List)containers:# 必填,容器的名称(需要符合RFC 1035规范)- name:string# 必填,容器镜像名称image:string# 获取镜像的策略，默认值为:Always# Always: 每次都尝试重新下载镜像# Never: 仅使用本地镜像# IfNotPresent: 如果本地不存在，就下载镜像imagePullPolicy:[Always | Never | IfNotPresent]# 容器启动命令列表，若不指定则使用镜像打包时使用的启动命令command:[string]# 容器的启动命令参数列表args:[string]# 容器的工作目录workingDir:string# 挂载到容器内部的存储卷配置(取值类型:List)volumeMounts:# 引用Pod定义的共享存储卷的名称，需使用镜像volumes[]部分定义的共享卷名称- name:string# 存储卷在容器内Mount的绝对路径(应少于512个字符)mountPath:string# 是否只读模式,默认false(读写模式)readOnly:boolean# 容器需要暴露的端口号(取值类型:List) ports:# 端口的名称- name:string# 容器需要监听的端口号containerPort:int# 容器所在主机需要监听的端口号，默认与containerPort相同# (设置hostPort时，同一台宿主机将无法启动该容器的第二副本，由于端口占用问题)hostPort:int# 端口协议[TCP/UDP],默认为TCPprotocol:string# 容器运行前需要设置的环境变量列表env:# 环境变量的名称- name:string# 环境变量的值value:string# 资源限制和资源请求的设置resource:# 资源限制设置limits:# CPU限制(单位为：core)将用于docker run --cpu-shares参数cpu:string# 内存限制(单位为：MiB/GiB)将用于docker run --memory参数memory:string# 资源限制设置(请求)requests:# CPU请求(单位为：core)将用于容器启动的初始化可用数量cpu:string# 内存请求(单位为：MiB/GiB)将用于容器启动的初始化可用数量memory:string# 对Pod对象内各个容器进行安全检查的设置，当探测无响应几次后，将自动重启该容器# 包含[exec | httpGet | TcpSocket]三种方式，任选其一即可livenessProbe:exec:# 需要执行的脚本command:[string]httpGet:# 请求路径path:string# 请求端口port:numberhost:stringscheme:stringhttpHeader:- name:stringvalue:stringtcpSocket:port:number# 完成容器启动后首次进行探测的时间(单位为：s)initialDelaySeconds:0# 对容器健康检查探测等待超时时间(单位为：s)，默认值为1timeoutSeconds:0# 对容器健康检查的探测时间周期(单位为：s)，默认值为10periodSeconds:0successThreshold:0failureThreshold:0securityContext:privileged:boolean## Pod对象的重启策略，可选值[Always | Never | OnFailure]## Always: Pod对象一旦终止，则不关心容器是如何停止的，kubelet都将重器容器## Never: Pod对象终止后，kubelet将退出码返回给Master，不再重启该容器## OnFailure: 只有当Pod对象以非零退出码终止时，kubelet才会重启该容器# (容器正常结束的退出码为零)#restartPolicy:[Always | Never | OnFailure]# 表示将Pod对象调度到包含这些label的Node上(以key:value形式指定)nodeSelector:object# Pull镜像时使用的secret名称(以name:secretValue形式指定)imagePullSecrets:- name:string# 是否使用主机模式(默认值为:false)## 如果设置为true，表示容器使用宿主机网络，不再使用Docker网桥# 该Pod对象将无法在同一台宿主机上启动第二个副本hostNetwork:boolean# 在该Pod对象上定义的共享储存卷列表volumes:# 共享储存卷名称，一个Pod对象中每个储存卷定义一个名称(命名应按照RFC 1035规范)- name:string# Pod对象同生命周期的一个临时目录，值为{}空对象emptyDir:{}# 挂载Pod对象所在宿主机的目录hostPath:# 将用于容器中mount的目录path:string# 挂载集群中预定义的secret对象到容器内部secret:secretName:stringitems:- key:stringpath:string# 挂载集群预定义的configMap对象到容器内部configMap:name:stringitems:- key:stringpath:string2.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 2-2.SpringBoot--Pods项目初体验</title>
      <link>https://example.com/p/kubernetes-2-2.springboot-pods%E9%A1%B9%E7%9B%AE%E5%88%9D%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Thu, 17 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-2-2.springboot-pods%E9%A1%B9%E7%9B%AE%E5%88%9D%E4%BD%93%E9%AA%8C/</guid>
      <description>SpringBoot&amp;ndash;Pods项目初体验  在SpringBoot项目中通过fabric8打包插件构建docker镜像
 通过Kubernetes的接口请求Pod对象，相信信息如下：
{ &amp;#34;kind&amp;#34;: &amp;#34;Pod&amp;#34;, &amp;#34;apiVersion&amp;#34;: &amp;#34;v1&amp;#34;, &amp;#34;metadata&amp;#34;: { &amp;#34;name&amp;#34;: &amp;#34;kubernetes-hello-world-779c4c748b-2rv27&amp;#34;, &amp;#34;generateName&amp;#34;: &amp;#34;kubernetes-hello-world-779c4c748b-&amp;#34;, &amp;#34;namespace&amp;#34;: &amp;#34;default&amp;#34;, &amp;#34;selfLink&amp;#34;: &amp;#34;/api/v1/namespaces/default/pods/kubernetes-hello-world-779c4c748b-2rv27&amp;#34;, &amp;#34;uid&amp;#34;: &amp;#34;dea46f9f-cd4b-11e9-b38e-025000000001&amp;#34;, &amp;#34;resourceVersion&amp;#34;: &amp;#34;34209&amp;#34;, &amp;#34;creationTimestamp&amp;#34;: &amp;#34;2019-09-02T06:35:35Z&amp;#34;, &amp;#34;labels&amp;#34;: { &amp;#34;app&amp;#34;: &amp;#34;kubernetes-hello-world&amp;#34;, &amp;#34;group&amp;#34;: &amp;#34;org.springframework.cloud&amp;#34;, &amp;#34;pod-template-hash&amp;#34;: &amp;#34;779c4c748b&amp;#34;, &amp;#34;provider&amp;#34;: &amp;#34;fabric8&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;1.1.0.M2&amp;#34; }, &amp;#34;annotations&amp;#34;: { &amp;#34;fabric8.io/docs-url&amp;#34;: &amp;#34;scp://static.springframework.org/var/www/domains/springframework.org/static/htdocs/spring-cloud/docs/kubernetes-hello-world/1.1.0.M2/spring-cloud-kubernetes/spring-cloud-kubernetes-examples/kubernetes-hello-world&amp;#34;, &amp;#34;fabric8.io/iconUrl&amp;#34;: &amp;#34;img/icons/spring-boot.svg&amp;#34;, &amp;#34;fabric8.io/metrics-path&amp;#34;: &amp;#34;dashboard/file/kubernetes-pods.json/?var-project=kubernetes-hello-world\u0026var-version=1.1.0.M2&amp;#34;, &amp;#34;fabric8.io/scm-con-url&amp;#34;: &amp;#34;scm:git:git://github.com/spring-cloud-incubator/spring-cloud-kubernetes.git/spring-cloud-kubernetes-examples/kubernetes-hello-world&amp;#34;, &amp;#34;fabric8.io/scm-devcon-url&amp;#34;: &amp;#34;scm:git:ssh://git@github.com/spring-cloud-incubator/spring-cloud-kubernetes.git/spring-cloud-kubernetes-examples/kubernetes-hello-world&amp;#34;, &amp;#34;fabric8.io/scm-tag&amp;#34;: &amp;#34;HEAD&amp;#34;, &amp;#34;fabric8.io/scm-url&amp;#34;: &amp;#34;https://github.com/spring-cloud-incubator/spring-cloud-kubernetes/spring-cloud-kubernetes-examples/kubernetes-hello-world&amp;#34; }, &amp;#34;ownerReferences&amp;#34;: [ { &amp;#34;apiVersion&amp;#34;: &amp;#34;apps/v1&amp;#34;, &amp;#34;kind&amp;#34;: &amp;#34;ReplicaSet&amp;#34;, &amp;#34;name&amp;#34;: &amp;#34;kubernetes-hello-world-779c4c748b&amp;#34;, &amp;#34;uid&amp;#34;: &amp;#34;dea3c6a5-cd4b-11e9-b38e-025000000001&amp;#34;, &amp;#34;controller&amp;#34;: true, &amp;#34;blockOwnerDeletion&amp;#34;: true } ] }, &amp;#34;spec&amp;#34;: { &amp;#34;volumes&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;default-token-b4crd&amp;#34;, &amp;#34;secret&amp;#34;: { &amp;#34;secretName&amp;#34;: &amp;#34;default-token-b4crd&amp;#34;, &amp;#34;defaultMode&amp;#34;: 420 } } ], &amp;#34;containers&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;spring-boot&amp;#34;, &amp;#34;image&amp;#34;: &amp;#34;cloud/kubernetes-hello-world:1.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 1-4.kubeadm命令使用</title>
      <link>https://example.com/p/kubernetes-1-4.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 14 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-1-4.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</guid>
      <description>安装初始化K8s集群 1.安装K8s 1.1CentOS安装   预先准备工作
# 修改设置主机名称 hostnamectl set-hostname master # 绑定主机各节点hosts 192.168.0.1 master 192.168.0.2 node1 192.168.0.3 node2 # 验证每节点的Mac地址与UUID是否唯一 # mac地址注意查看网卡 cat /sys/class/net/eth1/address cat /sys/class/dmi/id/product_uuid # 关闭缓存交换swap swapoff -a # 临时关闭 sed -i.bak &amp;#39;/swap/s/^/#/&amp;#39; /etc/fstab #永久关闭   安装Kubernetes
# 设置K8s安装源，由于防火墙问题使用阿里云源 cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/yum.repos.d/kubernetes.repo   [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 更新源缓存 yum clean all yum -y makecache
# 查看k8s版本 yum list kubelet --showduplicates | sort -r # 默认安装最新版本 yum install -y kubelet kubeadm kubectl # 选择指定版本进行安装 yum install -y kubelet-&amp;lt;version&amp;gt; kubeadm-&amp;lt;version&amp;gt; kubectl-&amp;lt;version&amp;gt; ```  1.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 1-2.Kubectl命令行工具</title>
      <link>https://example.com/p/kubernetes-1-2.kubectl%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Sat, 12 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-1-2.kubectl%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/</guid>
      <description>Kubectl命令行工具 1.kubectl用法  $~: kubectl [command] [TYPE] [NAME] [flags]
   [command] 子命令。用于操作Kubernetes集群资源对象。
可取值：[create | delete | describe | get | apply]
  [TYPE] 资源对象的类型。区分大小写
备注：可以通过单数形式、复数形式、简写形式表示。
# 例：不同写法的Type,但是效果一致 kubectl get pod pod1 kubectl get pods pod1 kubectl get po pod1   [NAME] 资源对象名称。区分大小写 备注： 如果不指定名称，将返回属于TYPE的所有对象列表。
# 例：返回所有对象列表 kubectl get pods   [flags] kubectl子命令的可选参数
  2.kubectl操作实例   创建资源对象
# 由配置文件(*.yaml)创建一次性对象 # 创建一个对象 kubectl create -f service.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 1-3.kubeadm命令使用</title>
      <link>https://example.com/p/kubernetes-1-3.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 12 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-1-3.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/</guid>
      <description>kubeadm命令使用 一、kubeadm概述 $~:kubeadm --help # kubeadm [command] |———— alpha [command] |———— completion |———— config |———— images |———— list 列出所有依赖镜像 |———— pull |———— help 查看命令详细描述 |———— init 初始化Kubernetes集群Master |———— join 在Kubernetes集群中增加Node |———— reset 重置Kubernetes集群 |———— token |———— upgrade |———— version </description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 1-5.K8s之Helm包管理工具</title>
      <link>https://example.com/p/kubernetes-1-5.k8s%E4%B9%8Bhelm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Sat, 12 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-1-5.k8s%E4%B9%8Bhelm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/</guid>
      <description>K8s之Helm包管理工具  Helm 是 Deis 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理 Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。
 一、安装 Helm Release Link
1.OS-CentOS 当前使用版本为Helm v3.1.2 linux
# 下载二进制可执行文件压缩包 wget -O /data/helm.tar.gz https://get.helm.sh/helm-v3.1.2-linux-amd64.tar.gz # 解压 tar -xzvf /data/helm.tar.gz # 移动helm二进制文件，方便全局访问 mv linux-amd64/helm /usr/local/bin/helm 2.OS-MacOS ①.自动安装 PS：操作系统已安装brew工具
brew install helm ②.手动安装 当前使用版本为Helm v3.1.2 darwin
# 下载二进制可执行文件压缩包 wget -O ~/helm.tar.gz https://get.helm.sh/helm-v3.1.2-darwin-amd64.tar.gz # 解压缩 tar -xzvf ~/helm.tar.gz # 移动helm二进制文件，方便全局访问 mv darwin-amd64/helm /usr/local/bin/helm 二、入门 1.调整helm源 # 查看源 helm repo list # 设置国内镜像源(选用阿里云源) helm repo add stable https://kubernetes.</description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 0.Kubernetes</title>
      <link>https://example.com/p/kubernetes-0.kubernetes/</link>
      <pubDate>Fri, 11 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-0.kubernetes/</guid>
      <description>Kubernetes Kubernetes(K8s)，译文成为【舵手】。从官网的Logo可以看出是轮船上的舵。结合container(集装箱，容器)的概念，Kubernetes看起来则是管理这些容器的。是一个自动化的容器编排平台，负责应用的部署、应用的弹性以及应用的管理，前提则是这些应用都是基于容器的。
核心功能   服务的发现与负载均衡
附属组件KubeDNS为系统内置了服务发现功能，可以将每一个Service增加DNS名称，使得集群内节点直接通过此名称访问到；同时Service通过iptables、ipvs支持了负载均衡。
  自动装箱
构建于容器之上，基于资源依赖及其他约束在不影响其可用性的情况下自动完成容器的部署工作。
  自我修复
容器故障后自动重启、节点故障后自动重新进行容器调度、节点健康状态检查异常后会关闭容器进行重新创建。
  水平扩展
通过命令、UI手动水平扩展、基于CPU等资源负载率进行自动水平扩展。
  自动发布与回滚
使用灰度方式更新应用或其配置，过程中的应用健康状态将得到监控，以保证不在同一时刻kill掉所有实例；同时，过程中健康状态出现异常情况，将会立即自动执行回滚。
  存储编排
Pod对象自动挂载不同类型的存储系统。
  批量处理
支持批处理作业、CI持续集成。
  秘钥与配置管理
K8s的configMap将配置与Docker镜像解耦，更新配置时，无需重新构建Docker镜像。同时，敏感数据将通过Secret对象进行解耦，以保障一定程度上的最大安全。
  </description>
    </item>
    
    <item>
      <title>[ Kubernetes ] 1-1.初识K8s</title>
      <link>https://example.com/p/kubernetes-1-1.%E5%88%9D%E8%AF%86k8s/</link>
      <pubDate>Fri, 11 Sep 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/kubernetes-1-1.%E5%88%9D%E8%AF%86k8s/</guid>
      <description>初识K8s 术语及原理   Master(主节点:control plane) 集群中的神经中枢网关。负责整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控、纠错等管理功能。
  ApiServer
集群的网关。
 负责输出RESTful风格K8s接口，则是通往集群所有REST操作命令的入口，并负责接收、校验、相应所有的REST请求，最终结果状态存储在etcd中。
   Controller Manager
负责生命周期功能及API业务逻辑。
 **a.生命周期功能：**Namespace创建和生命周期、Event垃圾回收、Pod对象终止相关的垃圾回收、级联垃圾回收、Node的垃圾回收 **b.API业务逻辑：**由ReplicaSet执行的Pod对象扩展
   Scheduler
在API Server确认Pod对象之后，由调度器(Scheduler)根据集群中各节点的可用资源状态、目标运行容器的资源需求做出调度策略。
  Etcd
基于Raft协议开发的分布式键值存储，用于服务发现、共享配置、保证一致性(数据库的主从节点选择，分布式锁等)。
 a.etcd是独立的组件，并不属于K8s集群。 b.生产环境etcd应该按照集群方式部署运行，以提升高可用。
     Node(从节点:worker node)
工作节点。负责接收来自Master节点的工作指令并根据指令相应的创建或者销毁Pod对象，以及调整网络规则以合理的路由转发流量。
  Pod
Kubernetes并不会直接运行容器，而是使用一个抽象的资源对象封装一个或者多个容器，此对象就是Pod对象。 是K8s最小的调度单元。 **一个Pod对象可以拥有多个Container容器应用。**通常情况下，这些在同一个Pod对象中的Container容器是高耦合。因为其共用同一个Pod对象下的网络名称空间、存储资源、UTS命名空间(同一个主机名称)、PID命名空间(不同应用程序可以看到其他应用程序的PID)
  Pod Controller(Pod 控制器)
虽说Pod对象是最小的调度单元，但实际应用中，并不会直接部署、管理Pod对象，而是借助Pod Controller对其进行管理。
  Replication Controller(复制控制器)
K8s的核心概念，用于管理Pod的声明周期。在主节点中，控制管理器进程同RC的定义完成Pod的创建、监控、启停等操作。
  Replica Set
保证在某个时间点儿上，一定数量的Pod对象在运行。是Replication Controller的升级版本。
 主要区别在于Selector选择器 Replica Set:支持集合级别的选择器。 Replication Controller:支持在等号描述的选择器。</description>
    </item>
    
    <item>
      <title>[ Etcd ] 1.基础入门(1)</title>
      <link>https://example.com/p/etcd-1.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A81/</link>
      <pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/etcd-1.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A81/</guid>
      <description>ETCD  其中ETCD是一个用于存储关键数据的键值存储，ZK是一个用于管理配置等信息的中心化服务 ETCD包括 Raft 协议、存储两大模块. etcd 的使用其实非常简单，它对外提供了 gRPC 接口，我们可以通过 Protobuf 和 gRPC 直接对 etcd 中存储的数据进行管理，也可以使用官方提供的 etcdctl 操作存储的数据。
 raft协议  每一个 Raft 集群中都包含多个服务器，在任意时刻，每一台服务器只可能处于 Leader、Follower 以及 Candidate 三种状态；在处于正常的状态时，集群中只会存在一个 Leader，其余的服务器都是 Follower。
 节点选举  使用 Raft 协议的 etcd 集群在启动节点时，会遵循 Raft 协议的规则，所有节点一开始都被初始化为 Follower 状态，新加入的节点会在 NewNode 中做一些配置的初始化，包括用于接收各种信息的 Channel
 竞选流程 如果集群中的某一个 Follower 节点长时间内没有收到来自 Leader 的心跳请求，当前节点就会通过 MsgHup 消息进入预选举或者选举的流程。 如果收到 MsgHup 消息的节点不是 Leader 状态，就会根据当前集群的配置选择进入 PreElection 或者 Election 阶段，PreElection 阶段并不会真正增加当前节点的 Term，它的主要作用是得到当前集群能否成功选举出一个 Leader 的答案，如果当前集群中只有两个节点而且没有预选举阶段，那么这两个节点的 Term 会无休止的增加，预选举阶段就是为了解决这一问题而出现的。 当前节点会立刻调用 becomeCandidate 将当前节点的 Raft 状态变成候选人；在这之后，它会将票投给自己，如果当前集群只有一个节点，该节点就会直接成为集群中的 Leader 节点。</description>
    </item>
    
    <item>
      <title>[ Etcd ] 2.基础入门(2)</title>
      <link>https://example.com/p/etcd-2.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A82/</link>
      <pubDate>Sun, 30 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/etcd-2.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A82/</guid>
      <description>Etcd源码阅读与分析①-raft demo Etcd 与 Zookeeper 对比  一致性协议:配置共享&amp;amp;服务发现组件的核心基础。  Zookeeper采用ZAB协议(一种类Paxos协议)实现一致性 Etcd采用Raft协议，相比Paxos协议更容易理解，工程化。   API接口: 包含有两个版本V2、V3  V2: 提供HTTP+Json方式调用 V3: 提供grpc方式调用   性能  官方测试数据显示：10000+/s写入(优于Zookeeper性能)   安全  Etcd支持TSL(权限控制优于Zookeeper)    Etcd是一个基于Raft协议的简单内存KV项目
源码分析 本文档将以etcd作者在项目中所提供的demo程序进行源码试读。demo名称为raftexample。 路径在
1.项目结构 (base) {11:45}~/etcd:master ✗ ➭ tree -d -L 1 . . ├── Documentation # 项目文档 ├── auth # 认证授权 ├── client # 客户端相关(v2) ├── clientv3 # 客户端相关(v3) ├── contrib # (待验证) ├── default.etcd # 已编译完成的etcd ├── embed # 封装的etcd函数 ├── etcdctl # etcd操作命令，命令行客户端 ├── etcdmain # main函数入口这里 ├── etcdserver # 服务端相关 ├── functional # 目测验证功能测试套件 ├── hack # 开发者相关 ├── integration # (待验证) ├── lease # 实现etcd租约 ├── logos # 日志相关 ├── mvcc # MVCC存储相关 ├── pkg # 通用依赖库 ├── proxy # 代理相关Http、Https、Socks ├── raft # raft一致性协议实现 ├── scripts # 各类脚本 ├── security # 安全相关 ├── tests # (待验证) ├── tools # 工具 ├── vendor # go vendor依赖环境 ├── version # 版本信息 └── wal # Write-Ahead-Log实现 </description>
    </item>
    
    <item>
      <title>[ Docker ] 8.文件系统之UFS</title>
      <link>https://example.com/p/docker-8.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B9%8Bufs/</link>
      <pubDate>Sun, 23 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-8.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B9%8Bufs/</guid>
      <description>文件系统之UFS UFS 联合文件系统[Union File System]，把其他文件系统联合到一个联合挂载点的文件系统服务(适用于Linux、FreeBSD、NetBSD OS)。
 原理： 使用branch把不同文件系统的文件、目录「透明的」进行覆盖，形成一个单一一直的文件系统。branch具有要么read-only,要么read-write的特点。
  思想： 写时复制(copy-on-write),如果一个资源重复，但并未被修改，将不被立即创建出新的资源，直接为新旧实例提供共享。创建新资源将发生在第一次被修改写入时。该资源共享方式，可以明显降低未修改资源复制时的消耗，但同样的，也会在写入修改是增加部分开销。
  AFUS(Advanced Multi-Layered Unification FileSystem)  </description>
    </item>
    
    <item>
      <title>[ Docker ] 7.关于Linux的Cgroups</title>
      <link>https://example.com/p/docker-7.%E5%85%B3%E4%BA%8Elinux%E7%9A%84cgroups/</link>
      <pubDate>Sat, 22 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-7.%E5%85%B3%E4%BA%8Elinux%E7%9A%84cgroups/</guid>
      <description>关于Linux的Cgroups 概念  Linux Cgroups(Control Groups)在Linux Namespace为进程隔离出一定空间的基础上为此进行的资源限制、控制以及统计的能力。资源包含有：CPU、内存、存储、网络等。通过Cgroups可以限制某个进程的资源占用、并且可以实时监控进程以及统计信息。
 cgroups各模块   cgroup: 针对进程进行分组的一种策略机制。
 每一个cgroup中包含有一组进程。并且可以使用subsystem模块进行参数控制作用于此cgroup上的进程。
   subsystem: 此模块对资源进行控制。
 Ubuntu OS可以通过apt install cgroup-bin安装命令行工具，使用lssubsys查看Kernel所支持的subsystem list。
  blkio: 设置对块设备输入输出进行控制 cpu: 设置cgroup中进程的CPU调度策略 cpuacct: 统计cgroup中进程CPU占用情况 cpuset: 在多核机器上设置cgroup中进程可以使用的CPU和内存(内存仅适用于NUMA架构) devices: 控制cgroup中进程对设备的访问 freezer: 用于挂起(suspend)和恢复(resume)cgroup中的进程 memory: 限制cgroup中进程的内存占用 net_cls: 将cgroup中进程的网络包进行分类，以至于通过分类区区分不同cgroup中进程的网络包，并进行监控、限流等。 net_prio: 设置cgroup中进程产生的网络流量的优先级 ns: 使cgroup中进程在新的Namespace中fork出新进程(NEWNS)，同时创建出新的cgroup，并且此cgroup包含有新Namespace中的进程。    hierarchy: cgroup进程的继承关系。
 例如： 系统通过cgroup1针对一组定时任务进程进行CPU使用限制，同时其中一个进程还需要限制磁盘IO，这时候将可以通过cgroup2继承cgroup1限制CPU的同时增加磁盘IO限制。即cgroup2同时具有CPU、IO限制，并且不影响cgroup1组中其他进程的IO限制。
   cgroup各模块间关系  系统创建hierarchy后，系统下所有进程都将被加入cgroup中，cgroup为根节点，被hierarchy创建的cgroup将被作为此cgroup根节点下的子节点; subsystem与hierarchy是1:1关系(即，一个subsystem只能作用于一个hierarchy之上); hierarchy与subsystem是1:n关系(即，一个hierarchy可以作用于多个subsystem之上); 一个进程可以分布在不同的cgroup中，但需满足cgroup分布在不同的hierarchy中; 一个进程fork出一个子进程的同时，子进程与父进程在同一cgroup中，但可以根据需求调整到其他cgroup中。  </description>
    </item>
    
    <item>
      <title>[ Docker ] 5.Docker-本地构建none包处理</title>
      <link>https://example.com/p/docker-5.docker-%E6%9C%AC%E5%9C%B0%E6%9E%84%E5%BB%BAnone%E5%8C%85%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 21 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-5.docker-%E6%9C%AC%E5%9C%B0%E6%9E%84%E5%BB%BAnone%E5%8C%85%E5%A4%84%E7%90%86/</guid>
      <description>Docker-本地构建none包处理 踩坑①.打包构建Dockerfile镜像 每次本地打包构建Dockerfile镜像，如果更新镜像版本号会出现none的镜像在仓库中
# 停掉none相关的镜像进程占用 docker rm $(docker ps -a | grep &amp;#34;Exited&amp;#34; | awk &amp;#39;{print $1 }&amp;#39;) # 递归依次从仓库移除这些镜像 docker rmi $(docker images | grep &amp;#34;^&amp;lt;none&amp;gt;&amp;#34; | awk &amp;#34;{print $3}&amp;#34;) # 或者，使用一下命令进行移除 docker image prune # (此命令用于删除未使用的映像) # docker image prune [options] # -- options可选值： # -a 显示所有映像(默认隐藏中间映像) # -f 不提示确认，强制直接执行删除 </description>
    </item>
    
    <item>
      <title>[ Docker ] 6.关于命名空间(Linux Namespace)</title>
      <link>https://example.com/p/docker-6.%E5%85%B3%E4%BA%8E%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4linux-namespace/</link>
      <pubDate>Fri, 21 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-6.%E5%85%B3%E4%BA%8E%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4linux-namespace/</guid>
      <description>关于命名空间(Linux Namespace) 概念  1.Linux Namespace 是Kernel的一个功能，可以针对一系列的系统资源进行隔离。例如：PID(process id)、UID(User id)、Network so on.
  2.就像chroot允许把当前目录变成根目录一样进行隔离。
  3.Namespace进行隔离用户，当前用户将在特定的Namespace中具有root权限。但在真是物理机层面，此用户仍然是以UID运行的那个用户。
 Linux包含的Namespace类型    Type Params Kernel Effect Information     Mount CLONE_NEWNS 2.4.19 隔离Namespace下的文件系统   UTS CLONE_NEWUTS 2.6.19 用作隔离nodename和domainname   IPC CLONE_NEWIPC 2.6.19 隔离System V IPC 和POSIX Message queues   PID CLONE_NEWPID 2.6.24 针对进程ID进行隔离   Network CLONE_NEWNET 2.6.29 用于隔离网络设备、IP地址端口等网络栈   User CLONE_NEWUSER 3.8 用于隔离用户及用户组    #Demo Coding </description>
    </item>
    
    <item>
      <title>[ Docker ] 4.SpringBoot项目Docker化</title>
      <link>https://example.com/p/docker-4.springboot%E9%A1%B9%E7%9B%AEdocker%E5%8C%96/</link>
      <pubDate>Thu, 20 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-4.springboot%E9%A1%B9%E7%9B%AEdocker%E5%8C%96/</guid>
      <description>SpringBoot项目Docker化 一 </description>
    </item>
    
    <item>
      <title>[ Docker ] 2.Docker安装</title>
      <link>https://example.com/p/docker-2.docker%E5%AE%89%E8%A3%85/</link>
      <pubDate>Tue, 18 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-2.docker%E5%AE%89%E8%A3%85/</guid>
      <description>Docker安装  存储库安装   安装yum-config-manager所需依赖包
$~:sudo yum install -y yum-utils \  device-mapper-persistent-data \  lvm2   通过yum-config-manager添加存储库
$~:sudo yum-config-manager \  --add-repo \  https://download.docker.com/linux/centos/docker-ce.repo   列出存储库中排序后可用的全部版本
yum list docker-ce --showduplicates | sort -r   进行安装
# 指定版本号安装 sudo yum install docker-ce-&amp;lt;VERSION_STRING&amp;gt; docker-ce-cli-&amp;lt;VERSION_STRING&amp;gt; containerd.io # 安装最新版本（不指定版本号默认为最新） sudo yum install docker-ce docker-ce-cli containerd.io   安装docker-compose
# 下载二进制可执行文件，并保存在指定路径 sudo curl -L &amp;#34;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose # 修改文件权限 sudo chmod +x /usr/local/bin/docker-compose # 创建软链到全局可执行路径 sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose    软件包安装  </description>
    </item>
    
    <item>
      <title>[ Docker ] 3.Docker之jdk1.8最简镜像构建</title>
      <link>https://example.com/p/docker-3.docker%E4%B9%8Bjdk1.8%E6%9C%80%E7%AE%80%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/</link>
      <pubDate>Tue, 18 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-3.docker%E4%B9%8Bjdk1.8%E6%9C%80%E7%AE%80%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/</guid>
      <description>Docker之jdk1.8最简镜像构建 1.准备JRE 在Java下载网站下载JRE。 Tips:此JRE为Oracle作品，而非Openjdk
2.精简JRE中无关文件 # 进入已经下载jre压缩包的路径,执行解压 tar xzvf ~/Downloads/jre-8u241-linux-x64.tar.gz&amp;amp;&amp;amp;cd jre1.8.0_241 # 删除说明、其他文档 rm -rf COPYRIGHT LICENSE README \ THIRDPARTYLICENSEREADME-JAVAFX.txt \ THIRDPARTYLICENSEREADME.txt \ Welcome.html # 删除非必要依赖文件 rm -rf lib/plugin.jar \  lib/ext/jfxrt.jar \  bin/javaws \  lib/javaws.jar \  lib/desktop \  plugin \  lib/deploy* \  lib/*javafx* \  lib/*jfx* \  lib/amd64/libdecora_sse.so \  lib/amd64/libprism_*.so \  lib/amd64/libfxplugins.so \  lib/amd64/libglass.so \  lib/amd64/libgstreamer-lite.so \  lib/amd64/libjavafx*.</description>
    </item>
    
    <item>
      <title>[ Docker ] 1.Docker命令</title>
      <link>https://example.com/p/docker-1.docker%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Sun, 16 Aug 2020 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/docker-1.docker%E5%91%BD%E4%BB%A4/</guid>
      <description>Docker命令  docker [option] command
   option
 &amp;ndash;config string: 客户端配置文件的位置 &amp;ndash;context string[-c]: 用于连接到守护程序的上下文的名称 &amp;ndash;debug[-D]: 调试模式 &amp;ndash;host list[-H]: 要连接的守护程序套接字 &amp;ndash;log-level string[-l]: 日志等级[ debug | info | warn | error | fatal ]默认为info &amp;ndash;tls: 使用加密模式 &amp;ndash;tlscacert string: 签名证书文件路径 &amp;ndash;tlscert string: 密钥文件路径 &amp;ndash;tlskey string: key文件路径 &amp;ndash;tlsverify: 使用加密并验证远程连接 &amp;ndash;version[-v]: 版本信息    Management Commands(管理命令)
 builder: 管理构建 config: 管理Docker配置 container: 管理容器 context: 管理镜像构建上下文 image: 管理镜像 network: 管理网络 node: 管理Swarm节点 plugin: 管理插件 secret: 管理Docker secrets service: 管理服务 stack: 管理Docker stacks swarm: 管理Swarm集群 system: 查看系统信息 trust: 管理对Docker映像的信任 volume: 管理卷    Commands(命令)</description>
    </item>
    
    <item>
      <title>1.Go并发之协程</title>
      <link>https://example.com/p/1.go%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%8D%8F%E7%A8%8B/</link>
      <pubDate>Wed, 22 Apr 2020 21:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/1.go%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%8D%8F%E7%A8%8B/</guid>
      <description>Go并发之协程 首先需要了解几个概念：  channel(通道) select  1.协程、线程与进程 进程，属于操作系统，是系统资源分配的最小单位。充分利用CPU资源实现并发。
线程，所属于进程，是进程的内部实现，大大降低了上下文切换的消耗，突破一个进程只可以处理一件事的缺陷，从而提高了系统的并发性。
协程，粒度更细，属于线程中的调度。填补了线程在IO上性能的缺陷，避免陷入内核级上下文切换所导致的性能损耗。
2.协程实现原理 线程实现原理
线程是操作系统的内核对象，多线程情况下，线程达到一定数量，将会导致上下文频繁切换，CPU的额外消耗会提升。 高并发的网络编程如果一个线程对应一个socket连接将不是最好的处理方式，所以操作系统提供基于事件模式的异步编程模型。 协程实现原理
 </description>
    </item>
    
    <item>
      <title>[ MySQL ] 2-1.MySQL基础</title>
      <link>https://example.com/p/mysql-2-1.mysql%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Mon, 06 Jan 2020 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/mysql-2-1.mysql%E5%9F%BA%E7%A1%80/</guid>
      <description>Mysql基础 Mysql引擎   MyISAM
  InnoDB
  Memory
  Archive
     功能点 MyISAM InnoDB Memory Archive      存储限制 256TB RAM 64TB -    事务 N N Y N    全文检索 Y N N N    B+ Tree索引        哈希索引        数据缓存        外键         </description>
    </item>
    
    <item>
      <title>[ MySQL ] 2.MySQL索引</title>
      <link>https://example.com/p/mysql-2.mysql%E7%B4%A2%E5%BC%95/</link>
      <pubDate>Mon, 06 Jan 2020 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/mysql-2.mysql%E7%B4%A2%E5%BC%95/</guid>
      <description>MySQL索引  Index(索引)，在存储引擎中用于快速找到记录的一种数据结构。索引用来快速寻找特定值的记录。
 如果没有索引，执行查询时，MySQL必须从第一个记录开始扫描整个表的所有记录，知道找到符合要求的记录。如果存在索引，MySQL无需扫描全表即可迅速查找到目标记录所在的位置。
1. 索引类型   Hash索引：
 底层实现是基于哈希表，是一种以Key-Value形式存储数据的结构。 多个数据在存储关系上是没有任何顺序关系的。对于区间查询是无法通过索引查询的， 只能通过全表扫描的方式进行。Hash索引适用于等值查询场景。    B+ Tree索引：(MySQL引擎Innodb实现方式)
 B+ Tree索引是一种多路平衡查询树。 其节点是天然有序的(左节点 &amp;lt; 父节点 &amp;lt; 右节点)。 对于范围查询时候不需要做全表扫描。    相比Hash索引，B+ Tree的优点：
 Hash索引适合等值查询，但是无法进行范围查询 Hash索引没办法利用索引完成排序 Hash索引不支持多列联合索引的最左匹配规则 如果有大量重复键值的情况下，Hash索引的效率会很低，因为存在Hash碰撞问题    2. MySQL索引失效的几种情况  如果条件中有or，即使其中有条件带索引也不会使用 对于多列索引，不是使用的第一部分(第一个)，则不会使用索引 like查询是以%开头 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 not in ,not exist. 范围查询  索引的底层实现是B+树，为何不采用红黑树，B树? （1）：B+Tree非叶子节点只存储键值信息，降低B+Tree的高度，所有叶子节点之间都有一个链指针，数据记录都存放在叶子节点中
（2）： 红黑树这种结构，h明显要深的多，效率明显比B-Tree差很多
（3）：B+树也存在劣势，由于键会重复出现，因此会占用更多的空间。但是与带来的性能优势相比，空间劣势往往可以接受，因此B+树的在数据库中的使用比B树更加广泛
七种事务传播行为 （1）Propagation.REQUIRED&amp;lt;默认&amp;gt; 如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。
（2）Propagation.SUPPORTS 如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。
（3）Propagation.MANDATORY 如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。
（4）Propagation.REQUIRES_NEW 重新创建一个新的事务，如果当前存在事务，延缓当前的事务。
（5）Propagation.NOT_SUPPORTED 以非事务的方式运行，如果当前存在事务，暂停当前的事务。</description>
    </item>
    
    <item>
      <title>[ Redis ] 1. Redis</title>
      <link>https://example.com/p/redis-1.-redis/</link>
      <pubDate>Mon, 06 Jan 2020 01:13:47 +0800</pubDate>
      
      <guid>https://example.com/p/redis-1.-redis/</guid>
      <description>Redis 1. 什么是跳表  跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他的几点指针，从而达到快速访问队尾目的。跳跃表的效率可以和平衡树想媲美了，最关键是它的实现相对于平衡树来说，代码的实现上简单很多 跳跃表 level 层级完全是随机的。一般来说，层级越多，访问节点的速度越快。 一是实现有序集合键，二是集群节点中用作内部数据结构。 相比于红黑树、平衡二叉树，跳表不仅查找、插入、删除时间复杂度都是O(logN)，并且实现简单很多。  2. Redis中BitMap   Bitmap并不是一种独立的数据结构，而是基于String数据结构进行的位图操作。
 最大空间即为String数据结构所支持的512MB， 所以bitmap所支持的最大offset为2^32-1.    一般使用场景用于大数据签到、日活统计、在线统计等等。
 其主要优点可以节省大量空间。 例如： 进行日活统计：  使用日期作为key，用户ID作为偏移量，1为当日活跃，0为不活跃      ### 基本操作演示(以下为Redis-cli命令) # 设置一个字符串 1Aa  # 存储在redis中的二进制为 0b001100010100000101100001 set testkey 1Aa # 进行bitmap操作 setbit testkey 10 1 setbit testkey 18 0 # testkey对象index为10的bit值为1 getbit testkey 10 # testkey对象index为18的bit值为1 getbit testkey 18 # 进行位统计 ,结果为bit上为1的和， # testkey输出结果为 8 bitcount testkey # testkey输出结果为 3 bitcount testkey 0 0 3.</description>
    </item>
    
    <item>
      <title>1.ElasticSearch集群搭建</title>
      <link>https://example.com/p/1.elasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Sun, 22 Dec 2019 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/1.elasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</guid>
      <description>ElasticSearch集群搭建 注： #A:修改/etc/security/limits.conf #&amp;lt;domain&amp;gt; &amp;lt;type&amp;gt; &amp;lt;item&amp;gt; &amp;lt;value&amp;gt; * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 4096 #B:修改/etc/sysctl.conf vm.max_map_count=262144 # 保存执行： sysctl -p # 或者 sysctl -w vm.max_map_count=262144 </description>
    </item>
    
    <item>
      <title>2.ElasticSearch集群原理</title>
      <link>https://example.com/p/2.elasticsearch%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 22 Dec 2019 15:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/2.elasticsearch%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86/</guid>
      <description>ElasticSearch集群原理 一、关于ES集群需要思考几个问题  需要多大规模的集群？  # 首先从两个方面考虑 ①.数据量有多大？数据增长情况如何？ ②.服务器硬件设施配置：CPU、Memory、Disk # 推算依据 ES Jvm heap 最大设置为32G。 30G heap大约可以存储数据量10T；服务器memory若为128G，可运行多个实例节点。 # 应用场景 A:用于构建业务搜索模块，且多是垂直领域搜索。（数据量级几千万至十亿级,一般需要2-4台机器） B:用于大规模数据的实时联机处理分析(OLAP),例如ELK，数据规模可达上千亿乃至更多，需要几十甚至上百实例节点。  集群中节点角色如何分配？  # 一个节点可以充当一个或多个角色，默认三个角色都有 # 节点角色 ①.Master node.master: true # 实例节点为主节点 ②.DataNode node.data: true # 默认是数据节点。 ③.CoordinateNode # 以上两项置为false，则此节点为协调节点； # 协调节点：一个节点只作为接收请求、转发请求到其他节点、汇总各个节点返回数据等功能的节点。 # 具体分配 A:小规模集群不需要具体区分； B:中、大规模集群(十个节点以上)，并发查询量大，查询的合并量大，可以增加独立的协调节点。角色分开的好处是分工分开，不互影响。如不会因协调角色负载过高而影响数据节点的能力。  如何避免脑裂问题发生？   索引应该设置多少个分片？ 分片应该设置多少个副本？  </description>
    </item>
    
    <item>
      <title>1.MySQL之热备份工具(xtrabackup)</title>
      <link>https://example.com/p/1.mysql%E4%B9%8B%E7%83%AD%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7xtrabackup/</link>
      <pubDate>Fri, 22 Nov 2019 19:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/1.mysql%E4%B9%8B%E7%83%AD%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7xtrabackup/</guid>
      <description>MySQL之热备份工具(xtrabackup) 1.原理 2.安装  进入xtrabackup官网选择Percona XtraBackup   3.实战 </description>
    </item>
    
    <item>
      <title>1.MySQL编译安装过程</title>
      <link>https://example.com/p/1.mysql%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Fri, 22 Nov 2019 19:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/1.mysql%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/</guid>
      <description>编译安装过程 1.预编译 cmake . -DCMAKE_INSTALL_PREFIX=/data/ops/mysql/ \ -DMYSQL_DATADIR=/data/ops/mysql/data \ -DWITH_BOOST=../boost_1_59_0 \ -DSYSCONFDIR=/etc \ -DWITH_INNOBASE_STORAGE_ENGINE=1 \ -DWITH_PARTITION_STORAGE_ENGINE=1 \ -DWITH_FEDERATED_STORAGE_ENGINE=1 \ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \ -DWITH_MYISAM_STORAGE_ENGINE=1 \ -DENABLED_LOCAL_INFILE=1 \ -DENABLE_DTRACE=0 \ -DDEFAULT_CHARSET=utf8mb4 \ -DDEFAULT_COLLATION=utf8mb4_general_ci \ -DWITH_EMBEDDED_SERVER=1 2.编译安装 make -j `grep processor /proc/cpuinfo | wc -l` #编译很消耗系统资源，小内存可能编译通不过make install make install 3.启动配置 ls -lrt /usr/local/mysql # 创建启动脚本，并增加可执行权限 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld # 开机自启动 systemctl enable mysqld 4.修改Mysql配置文件 5.添加环境变量 6.初始化数据库 7.启动数据库 </description>
    </item>
    
    <item>
      <title> [ Zookeeper ] 2. Zookeeper基础</title>
      <link>https://example.com/p/zookeeper-2.-zookeeper%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Tue, 12 Nov 2019 01:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/zookeeper-2.-zookeeper%E5%9F%BA%E7%A1%80/</guid>
      <description>Zookeeper基础 1. ZAB协议  ZAB协议是为分布式协调服务Zookeeper专有的一种协议，此协议是为了应对崩溃恢复的原子广播 崩溃恢复  整个zk集群刚启动或者Leader节点宕机、重启或者不可以正常提供服务时超出一半的情况下，所有节点将会进入崩溃恢复模式 首先通过选举产生Leader 然后集群中的Follwer节点与新产生的Leader节点进行数据同步 一旦集群中一半数量的节点与Leader节点完成了数据同步，集群就会退出崩溃恢复模式，进入到消息广播模式   消息广播  Leader节点开始接受客户端的事务请求，生成事务的提案进行事务请求处理。    </description>
    </item>
    
    <item>
      <title>1.zookeeper分布式部署</title>
      <link>https://example.com/p/1.zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Tue, 12 Nov 2019 01:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/1.zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/</guid>
      <description>zookeeper分布式部署 一.配置服务器IP地址映射 [root@localhost zk]~#: vim /etc/hosts
192.168.1.111 zoo1 192.168.1.112 zoo2 192.168.1.113 zoo3 192.168.1.114 zoo4 192.168.1.115 zoo5 二.修改配置ZK文件 1.下载Zookeeper
# 进入ZK路径 wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.5.6/apache-zookeeper-3.5.6-bin.tar.gz 2.修改配置文件 进入conf目录，在配置文件前，先cp zoo_sample.cfg zoo.cfg,然后vim zoo.cfg。配置如下：
tickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/ops/zk/zookeeper-3.5.6-master/conf clientPort=2181 server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 3.启动ZK ①.在每个节点的服务器依次启动服务： [root@localhost zk]~#: ./bin/zkServer.sh start 在启动过程中日志会出现异常，由于其他节点还未启动，所以属于正常情况（正常情况下，仅有最后一个节点启动不会出现异常）。待所有节点全部启动，集群会逐渐稳定下来。 ②.查询每一个节点角色 [root@localhost zk]~#: ./bin/zkServer.sh status
# LeaderNode ZooKeeper JMX enabled by default Using config: /data/ops/zk/zookeeper-3.5.6-follower/bin/../conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: leader # FollowerNode ZooKeeper JMX enabled by default Using config: /data/ops/zk/zookeeper-3.</description>
    </item>
    
    <item>
      <title>[Nginx] 1.Nginx入门</title>
      <link>https://example.com/p/nginx-1.nginx%E5%85%A5%E9%97%A8/</link>
      <pubDate>Tue, 12 Nov 2019 01:36:27 +0800</pubDate>
      
      <guid>https://example.com/p/nginx-1.nginx%E5%85%A5%E9%97%A8/</guid>
      <description>1.Nginx入门 一、Nginx为什么受青睐 ​	在介绍Nginx具体的安装、配置以及原理之前先聊聊概念常识问题。那就是目前为什么Nginx深受青睐？那我们先从Nginx是什么开始聊起。
1.Nginx是什么   简单介绍
 ***Nginx***来自于俄罗斯，是在**RamblerMedia**工作的**Igor Sysoev**使用***C***语言编写而成的跨平台轻量级高性能的*Web*服务器。***Nginx***可以运行在**Linux**、**FreeBSD**、**Solaris**(*Sun*公司的类*Unix OS*)、**MacOS**、以及**Windows**等操作系统。操作系统的不同，也给***Nginx***带来了一些好处，***Nginx***会使用当前操作系统中特有的一些高效**API**来提高自身的性能。    Nginx和它的对手们
Nginx的对手们有Apache、Lighttpd、Tomcat、Jetty、IIS，它们同为Web服务器：具备Web服务器的基本功能；基于Rest架构风格，以**统一资源描述符（URI）或统一资源定位符（URL）作为沟通依据，通过HTTP为浏览器等Client程序提供各种网络服务。
但是，这些Web服务器呢，都多多少少因为各自的定位与发展方向都不尽相同，使得每一款Web服务器都各有特色：
​	1.Tomcat、Jetty：都是面向Java语言设计的。但是它们在性能方面与Nginx没有什么可比性，因为这两款服务器都是重量级选手。可能有伙伴会很疑惑，我已经用Tomcat跑起服务，同样配置后可以直接访问为什么还要在加层外套Nginx，对于这个问题，在后边对这一点进行详细的分析。【】
​	2.IIS：这位选手呢，来自于微软家族。然后特点大家可能就很清楚了，它只能在Windows OS运行（不过网上也有工具可以把它运行在LinuxOS中，但是并不是很完美哦）。可能拉低它颜值的就是稳定性与性能了，Windows OS作为服务器的话，稳定性和部分性能都不能和类Unix OS进行媲美，所以呢，在高性能Web服务器的场合中，IIS可能就要被“淘汰”了。
​	3.Apache：这是一位压轴级选手，是发展周期最长的，毫无疑问是世界第一大Web服务器，在2012年遥遥领先其他选手。它毕竟有很多优秀的地方：稳定、开源、跨平台等。但是美中不足的是，它被设计成为了重量级、不支持高并发的Web服务器。如果有数以万计的HTTP请求同时访问，服务器就会面临大量内存消耗的问题，操作系统也会跟着收到牵连，毕竟Apache的进程做进程间切换时会给服务器的CPU带来重大压力，同时会伴随着响应效率降低，这致命的一击，导致这位来自“贵族世家”的选手在高性能Web服务器的舞台上没有了地位。
​	4.Lighttpd：与Nginx同样是轻量级、高性能的Web服务器。但是它并没有得到国内开发者的钟爱，而是被欧美的开发者们所追捧。
  恩宠&amp;ndash;Nginx
Nginx的代码也是开源的而且是最自由的2-clause BSD-like license许可证。Nginx使用的架构是基于事件驱动的，能够并发处理百万级别的TCP连接。由于Nginx的高度模块化和具有最自由的许可证，让Nginx的第三方模块扩展功能更加充实。优秀的设计还带来了极佳的稳定性体验。所以，Nginx大量应用于大流量的网站来高效处理大规模高并发连接。种种迹象表明，Nginx在性能方面很出色。
  2.Nginx的特点   更快
快主要体现在两方面：①在正常的情况下，单次请求会得到更快的响应；②在数以万计的并发请求中，Nginx可以比其他Web服务器更快的响应请求。
  高扩展性
Nginx的高度模块化决定了其具有高扩展性。它完全是由多个不同功能、不同层次、不同类型以及耦合度极低的模块组合而成。它的模块都是嵌入到二进制文件中执行，使得第三方开发的模块也一样完美支持性能。所以高并发的网站完全可以根据自身项目业务特性定制属于自己的模块。
  高可靠性
这个特点应该是选择Web服务器最基本的条件。Nginx的稳定性，大家有目共睹。国内多家高流量并发的网站在核心的服务器上大规模使用Nginx。官方提供的常用模块是非常稳定的，每一个Worker进程都相对独立，把耦合性降至最低。master进程在其中一个Worker进程出错时可以快速“拉起”新的Worker子进程提供相应的服务。
  低内存消耗
据数据测试，一般情况下，1W个不活跃的HTTP Keep-Alive连接在Nginx中消耗只有2.5MB的内存。（这也是Nginx能够支持高并发连接的基础）
  单机支持10W+的并发连接
由于现在是海量数据时代，高并发无疑成为大家青睐的对象。理论上，Nginx支持的并发连接数量取决于内存，10W+的并发连接并没有到极限。但是，能否及时处理更多的并发连接应该取决于项目业务的需求。
  热部署
master管理进程和Worker进程是相互隔离的，这使得Nginx能够彰显热部署的能力。通俗点来说，就是完全可以在7*24h不停止服务正常工作的情况下，可以升级Nginx的可执行文件、更新配置选项、更新日志文件等功能操作。
  最自由的BSD许可协议
俗话说**“众人拾柴火焰高”**。也正是BSD许可协议带来的极大优势，为**Nginx**提供更强劲的发展动力。
  综上所述，选择Nginx的核心理由还是由于它能在支持高并发请求的同时保持高效的服务。  二、Nginx的安装 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>三、Pod对象详解 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>4-1.K8s构建高可用Mysql集群 一、MySQL高可用架构图 1.主从复制+读写分离  此方案更适用于数据库读数据的场景(针对数据强一致性非严格的情况)，毕竟Replication存在一定的时延。 通过快速扩容Slave节点提高MySQL集群读取数据能力，不用过度依赖于Master节点。
 实现过程 ①.为其提供PV存储盘 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description> </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>1.Kuberbetes-dashboard(Web UI)  Kuberbetes-dashboard是基于web的Kubernetes用户界面。
 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>云原生 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>目录   云原生探索
  第一部分-Goland学习
 Go并发  协程      第二部分-Docker
 1.Docker命令 2.Docker安装 3.Docker之jdk最简镜像构建 4.Docker-SpringBoot构建 5.Docker-本地构建none包处理 6.Docker-Linux Namespace 7.Docker-Linux cgroup 8.Docker-Linux UFS    第三部分-Kubernetes
 1.初识K8s  1-1.K8s基础 1-2.Kubectl工具 1-3.Kubeadm工具 1-4.Kubenetes集群初始化 1-5.Kubenetes之Helm包管理工具   2.深入Pod  2-1.Pod对象 2-2.Pod示例 2-3.Pod详解   3.深入Service  3-1.Service对象   4.K8s服务构建  4-1.Mysql-K8s主从构建   K8s-PlugIn  1.Dashboard插件       第四部分-ServiceMesh</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>Go编程之指针 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>一、OpenCV-Java的入门  OpenCV的Java官方文档地址
 1.OpenCV的Java环境构建 首先，声明一下在本文中选用的环境配置如下：
  MacOS操作系统
  IntelliJ IDEA开发编译器
   MacOS的安装有两种方式：一种是靠强大的BrewHome安装器自动安装；另外一种就是相对麻烦的手动安装了。
在这里我选择的是BrewHome进行安装。（前提是MacOS已经安装了BrewHome）</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>一、相关概念的简介  在了解深度学习前应该还有两个专业名词大家也想必是耳熟能详，那么就是人工智能、机器学习。
  人工智能(Artificial Intelligence)：也就是我们经常听到的AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。但是在早期的时候，人工智能充满了局限性，只是在特定的环境范围下。 机器学习(Machine Learning)：简称ML。机器学习其实是人工智能的一个分支。如果一个程序可以在**任务*(T)上，随着经验(E)***的增加，*效果(P)***也可以随之增加，则就可以说这个程序可以从经验中得到学习。 深度学习(Deep Learning)：简称DL。深度学习也是机器学习的一个分支。主要是在机器学习的基础之上有所改进：它除了可以学习特征和任务之间的关联，还可以自动的将简单的特征组合成更加复杂的特征，并使用这些组合特征解决问题。   二、了解机器学习(ML)  1. 用例子认识机器学习的概念 其实，邮件系统中判断收到的邮件是否为垃圾邮件就可以看做是一个机器学习的过程。首先对垃圾邮件分类概念进行一个拆分、类比：
  一个程序 &amp;lt;======&amp;gt; 需要用到的机器学习算法，比如逻辑回归算法 任务(T) &amp;lt;======&amp;gt; 区分此邮件是否是垃圾邮件这个任务 经验(E) &amp;lt;======&amp;gt; 已经区分过是否为垃圾邮件的历史事件 效果(P) &amp;lt;======&amp;gt; 机器学习算法在区分此邮件是否是垃圾邮件这个任务的精确率   在整个过程中，首先会从每一封邮件中抽取出对分类结果可能有影响的因素（比如：发件人的地址、邮件的标题、收件人的数量、邮件正题内容，so on）。这样的每一个**因素**其实可以成为是一个**特征** ***(feature)***。然而机器学习算法中的**逻辑回归算法**可以从训练数据中计算出每个特征和预测结果的相关度。例如，在垃圾邮件分类过程中，可能会发现如果一个邮件的收件人越多，那么这封邮件是垃圾邮件的可能性越大。 在对一封完全未知的邮件进行区分时，**逻辑回归算法**会根据这封邮件中抽取到的每一个**特征**以及**这些特征**和垃圾邮件的**相关度**进行判断是否为垃圾邮件。 所以，从例子中不难看出：一般情况下，在训练数据达到一定数量之前，越多的训练数据可以使得逻辑回归算法对未知邮件做出的判断越精确。
 也就是说**逻辑回归算法可以根据训练数据【经验(E)】提高垃圾邮件分类问题【任务(T)】上的准确率【效果(P)】**
 2.机器学习的分类  有监督学习(Supervised Learning)   有监督学习可分为回归和分类问题。例如上述示例垃圾邮件分类就属于有监督学习。 1.在回归问题中，我们会预测一个连续值；也就是我们试图将输入变量和输出用一个连续函数对应起来。 2.在分类问题中，我们会预测一个离散值，我们试图将输入变量与离散的类别对应起来。
  无监督学习(Unsupervised Leanring)   这种学习方式，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。
  增强式学习(Reinforcement Learning)   输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。
 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description>一、关于神经网络  训练神经网络主要包含以下四部分：  层，多个层组合成网络(模型) 输入数据和相应的目标 损失函数，即用于学习的反馈信号 优化器，决定学习过程如何进行    </description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/p/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://example.com/p/</guid>
      <description> </description>
    </item>
    
  </channel>
</rss>
