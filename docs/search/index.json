[{"content":"Pulsar本地单机安装 1. OS要求  目前Pulsar仅支持操作系统 MacOS 与 Linux，使用Pulsar，需保证已安装 Oracle的 Java 8 运行环境。\n 2. 安装二进制版本 ","date":"2021-03-02T11:13:47+08:00","permalink":"https://example.com/p/pulsar-1.-pulsar%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85/","title":"[ Pulsar ] 1. Pulsar本地安装"},{"content":"关于Restful规范 1. Restful API Design定义 2. Action命名规范 3. 自定义方法 3.1 ","date":"2021-03-01T11:13:47+08:00","permalink":"https://example.com/p/standard-1.%E5%85%B3%E4%BA%8Erestful%E8%A7%84%E8%8C%83/","title":"[ Standard ] 1.关于Restful规范"},{"content":"JUC之AQS 1.基础知识 1_1. AQS原理 AQS(AbstractQueuedSynchronizer),是java.util.concurrent.locks下的一个普通类。用作构建 锁 和 同步器 框架。例如基于AQS构建的有：ReentrantLock, Semaphore, ReentrantReadWriteLock, SynchronousQueue, FutureTask 等等。\n核心思想：\n 如果被请求的共享资源处于 空闲状态 ，则将当前请求资源的线程设置为 有效的工作线程 ，并且将共享资源设置为 锁定状态。 如果被请求的共享资源处于 占用状态 ，则需要一套 线程阻塞等待 以及 被唤醒时锁分配 的流程机制。 AQS 通过 CLH (Craig, Landin, Hagersten) 队列锁实现：将暂时获取不到锁的线程加入至队列中。 AQS使用一个 int 成员变量来标识同步状态，通过内置的 FIFO 队列完成获取资源线程的排队工作，使用 CAS(compare and swap) 对改状态进行原子操作实现对其值的更改。  // 共享变量，使用volatile修饰符保证线程可见性 private volatile int state; /** 状态信息通过protected修饰符修饰 getState(), setState(), compareAndSetState()进行操作 */ // 返回同步状态的当前值 protected final int getState(){ return state; } // 设置同步状态当前值 protected final void setState(int newState){ this.state = newState; } // 原子操作(CAS操作)将同步状态值设置为给定值update，如果当前同步状态值等于expect(期望值) protected final boolean compareAndSetState(int expect, int update){ return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 1_2. AQS对资源的共享方式   Exclusive(独占)\n  Share(共享)\n  2.相关组件 ","date":"2021-01-10T11:10:47+08:00","permalink":"https://example.com/p/java-4-2.juc%E4%B9%8Baqs/","title":"[ Java ] 4-2.JUC之AQS"},{"content":"4-3.Synchronized关键字 一、 Synchronized的作用范围：适用于方法以及代码块中。    类型 具体类型 作用对象 代码示例     方法 实例方法 类的实例对象 public synchronized void method(){}   方法 静态方法 类对象 public static synchronized void method(){}   代码块 实例对象 类的实例对象 synchronized(this){//同步代码块，锁住的是此类的实例对象;}   代码块 Class对象 类对象 synchronized(SynchronizedDemo.class){//锁住的是此类的实例对象;}   代码块 任意实例对象 任意实例对象 String demo='synchronized';synchronized(demo){//锁住的为demo对象;}   Tips: 如果Synchronized锁作用于类对象,不管多少个new实例对象,它们终究属于此类,都会被锁住,即线程之间保证同步关系.       二、Synchronized锁原理分析 当一个线程访问同步代码块时，它首先是需要得到锁才能执行同步代码，当退出或者抛出异常时必须要释放锁。 1.通过javap命令查看生成的字节码文件进行分析Synchronized锁的实现: public class SynchronizedTest { public synchronized void demo(){ } public void demoTwo(){ synchronized (this){ } } } 将上述代码片段进行编译，使用javap -v SynchronizedTest.class命令进行\u0008详细信息查看（摘录部分信息如下）:\n{ public SynchronizedTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V  4: return LineNumberTable: line 1: 0 public synchronized void demo(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 4: 0 public void demoTwo(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //监视器进入，获取锁  4: aload_1 5: monitorexit //监视器退出，释放锁  6: goto 14 9: astore_2 10: aload_1 11: monitorexit 12: aload_2 13: athrow 14: return } 2.从以上信息中可以看出：   Synchronized锁作用于代码块时是通过monitorenter和monitorexit指令进行实现的，Monitor对象是同步的基本实现单元: ①.monitorenter指令插入在同步代码段开始的位置,monitorexit指令插入在同步代码段结束的位置。JVM需要保证每一个monitorenter与monitorexit都是一一对应的关系。 ②.任何对象都会存在一个对应的monitor,当这个monitor被占有,将进入锁定状态（即获取锁）使Synchronized锁进行同步，当线程获取monitor后才能继续往下执行，否则就只能等待(获取monitor的过程是互斥的，即同一时刻只有一个线程能够获取到monitor)。\n  Synchronized锁作用于方法时是通过在方法修饰符上的ACC_SYNCHRONIZED标志实现的: Synchronized作用于方法时，会被编译成普通方法的调用和返回指令，在VM字节码层并没有任何特别的指令来实现被synchronized修饰的方法，但是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1,表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。\n  三、关于Monitor和对象头 1.聊聊Monitor Monitor（内部锁），我们可以理解成为是一个同步工具,也可以描述成一种同步机制。与一切皆对象一样，所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。\n  在Java6版本以前，Monitor的实现完全是依赖于操作系统内部的互斥锁,犹豫需要进行用户态到系统内核态的切换，所以同步操作是一个无差别的重量级操作。\n  但是在目前版本的JDK中，JVM进行了调整，提供有三种不同的Monitor实现(即常见的三类锁):偏斜锁(Biased Locking)、轻量级锁和重量级锁。\n  锁升级 1、当没有被当做锁的时候，这就是个普通对象，锁标志位为01，是否偏向锁为0\n2、当对象被当做同步锁时，一个线程A抢到锁时，锁标志位依然是01，是否偏向锁为1，前23位记录A线程的线程ID，此时锁升级为偏向锁\n3、当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码，这也是偏向锁的意义\n4、当一个线程B尝试获取锁，JVM发现当前的锁处于偏向状态，并且现场ID不是B线程的ID，那么线程B会先用CAS将线程id改为自己的，这里是有可能成功的，因为A线程一般不会释放偏向锁。如果失败，则执行5\n5、偏向锁抢锁失败，则说明当前锁存在一定的竞争，偏向锁就升级为轻量级锁。JVM会在当前线程的现场栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁MarkWord中保存指向这片空间的指针。上面的保存都是CAS操作，如果竞争成功，代表线程B抢到了锁，可以执行同步代码。如果抢锁失败，则继续执行6\n6、轻量级锁抢锁失败，则JVM会使用自旋锁，自旋锁并非是一个锁，则是一个循环操作，不断的尝试获取锁。从JDK1.7开始，自旋锁默认开启，自旋次数由JVM决定。如果抢锁成功，则执行同步代码；如果抢锁失败，则执行7\n7、自旋锁重试之后仍然未抢到锁，同步锁会升级至重量级锁，锁标志位改为10，在这个状态下，未抢到锁的线程都会被阻塞，由Monitor来管理，并会有线程的park与unpark，因为这个存在用户态和内核态的转换，比较消耗资源，故名重量级锁\nthreadlocal的原理和应用   原理\n 线程中创建副本，访问自己内部的副本变量，内部实现是其内部类名叫ThreadLocalMap的成员变量threadLocals，key为本身，value为实际存值的变量副本    应用\n 用来解决数据库连接，存放connection对象，不同线程存放各自session； 解决simpleDateFormat线程安全问题； 会出现内存泄漏，显式remove..不要与线程池配合，因为worker往往是不会退出的；    threadlocal内存泄漏问题  如果是强引用，设置threadlocal=null，但是key的引用依然指向ThreadLocal对象，所以会有内存泄漏，而使用弱引用则不会； 但是还是会有内存泄漏存在，ThreadLocal被回收，key的值变成null，导致整个value再也无法被访问到； 解决办法：在使用结束时，调用ThreadLocal.remove来释放其value的引用；  ","date":"2021-01-10T11:10:47+08:00","permalink":"https://example.com/p/java-4-2.juc%E4%B9%8Bsynchronized/","title":"[ Java ] 4-2.JUC之Synchronized"},{"content":"面试之算法 1. 删除UserList中年龄大于20的User对象 // User实体类 public class User{ private Integer age; public Integet getAge(){ return this.age; } } 解题思路：\n此题按照最简单的lambda方式进行解答(JDK8才支持)\npublic class Main{ public static void remove(List\u0026lt;User\u0026gt; userList){ // removeIf(Predicate\u0026lt;? super E\u0026gt; filter)  userList.removeIf(x -\u0026gt; x != null \u0026amp;\u0026amp; x.getAge() != null \u0026amp;\u0026amp; x.getAge() \u0026gt; 20); } } 2. 从1000W个数中取出最小的10个数，并按照顺序打印。 解题思路： 首先应该想到堆排序(Top K堆问题)，大根堆(前k小)或小根堆(后k大)。在Java中有已经实现的PriorityQueue，解决此问题将最为简单，复杂度为O(NlogK)。\n本题是求前K小，因此选用一个容量为K的大根堆，每次poll出最大的数，则堆中保留的则是前K项小。(谨记：需要不可用小根堆，小根堆需把全部元素入堆，时间复杂度为O(NlogN),将不再是O(NlogK))，Java中PriorityQueue默认为小根堆，需作出调整重写比较器。\npublic class MaxHeap { public static void main(String[] args) { int[] arr = new int[]{10,1,0,9,22,77,12,883,99983,2772,848,3663,2626,737,2772,8388,266,83,72,7272,83883,27727,263,840,2740,884}; print(arr); } public static void print2(int[] arr) { int k = 10; int[] vec = new int[k]; // 重写PriorityQueue为大根堆  // PriorityQueue\u0026lt;Integer\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;();默认为小根堆  PriorityQueue\u0026lt;Integer\u0026gt; queue = new PriorityQueue\u0026lt;\u0026gt;((num1, num2) -\u0026gt; num2 - num1); for (int i = 0; i \u0026lt; k; ++i) { queue.offer(arr[i]); } for (int i = k; i \u0026lt; arr.length; ++i) { if (queue.peek() \u0026gt; arr[i]) { queue.poll(); queue.offer(arr[i]); } } for (int i = 0; i \u0026lt; k; ++i) { vec[i] = queue.poll(); } System.out.println(Arrays.toString(vec)); } } 3. 3个线程A、B、C存在依赖关系，B依赖A执行结束，C依赖B执行结束，请设计实现。 解题思路： 主要考察多线程Thread对象的wait()、notify()以及线程间共享的信号量。\npublic class Main { public static void main(String[] args) { Lock lockA = new Lock(); Lock lockB = new Lock(); new A(lockA).start(); new B(lockA, lockB).start(); new C(lockB).start(); } } class Lock{ private int flag = 0; public int getFlag() { return flag; } public void setFlag(int flag) { this.flag = flag; } } class A extends Thread{ private Lock lock; public A(Lock lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { System.out.println(\u0026#34;thread A starting \u0026#34;); if (lock.getFlag() \u0026gt; 0) { lock.notify(); } else { lock.setFlag(1); } } catch (Exception e) { e.printStackTrace(); } } } } class B extends Thread{ private Lock lockA; private Lock lockB; public B(Lock lockA,Lock lockB) { this.lockA = lockA; this.lockB = lockB; } @Override public void run() { synchronized (lockA) { try { if (lockA.getFlag() == 0) { lockA.setFlag(1); lockA.wait(); } System.out.println(\u0026#34;Thread B starting\u0026#34;); synchronized (lockB) { if (lockB.getFlag() \u0026gt; 0) { lockB.notify(); } else { lockB.setFlag(1); } } } catch (Exception e) { e.printStackTrace(); } } } } class C extends Thread { private Lock lock; public C(Lock lock) { this.lock = lock; } @Override public void run() { synchronized (lock) { try { if (lock.getFlag() == 0) { lock.setFlag(1); lock.wait(); } System.out.println(\u0026#34;Thread C starting\u0026#34;); } catch (Exception e){ e.printStackTrace(); } } } } /** * 给定一个二叉树, 检查它是否是镜像对称的 * 例如以下是镜像对称的 * 1 * / \\ * 2 2 * / \\ / \\ * 3 4 4 3 * * 下面这个则不是镜像对称的 * 1 * / \\ * 2 2 * \\ \\ * 3 3 * * TreeNode类的定义: * * @param TreeNode 一颗二叉树 * @return boolean 是否是对称的 */ // 以下给出TreeNode类, 请勿修改 static class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } 解题思路\n解答代码\n/** * 对任意一个Map\u0026lt;String, Object\u0026gt;, 其 key 为 String, * 其 value 为 Map\u0026lt;String, Object\u0026gt; Object[] Number String 中的任意一种, * 显然叶子节点是 value 类型为 Number 或 String的节点, * 将 Map 转为多条字符串, 每条字符串表达其中一个叶子节点, * 比如: * {\u0026#34;a\u0026#34;:{\u0026#34;b\u0026#34;:[\u0026#34;v\u0026#34;,2,{\u0026#34;c\u0026#34;:0}]},\u0026#34;d\u0026#34;:[1,null,3]} * 将转化为以下这些字符串 * a.b[0] = v * a.b[1] = 2 * a.b[2].c = 0 * d[0] = 1 * d[1] = null * d[2] = 3 * * @param map 上述的 map * @return 所有的字符串 */ 解题思路\n解答代码\n/** * 注意! 本题不要遍历二维数组. 要求时间复杂度严格低于n^2, 否则视为不得分 * * 现有一个n\\*n的二维正整数数组nums，每行元素保证递增，每列元素保证递增， 求某正整数x是否存在于该二维数组中，需要尽量优化时间和空间复杂度； * @param int[][] nums * @param int x 目标数 * @return boolean */ 解题思路\n解答代码\n","date":"2021-01-08T01:13:47+08:00","permalink":"https://example.com/p/interview-2.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E7%AE%97%E6%B3%95/","title":"[ Interview ] 2. 面试之算法"},{"content":"面试 X_Q 1.JVM垃圾回收机制 Java编程中，程序员不需要刻意显式进行垃圾回收去释放一个对象内存，而是JVM会进行自动垃圾回收。 JVM中存在一个 优先级较低 的线程，只有当 JVM处于空闲 或者 堆空间不足 的情况触发执行。此过程中，将扫描到 没有被引用的对象 防止垃圾回收集合中，进行垃圾回收。\n 判断对象是否可以被回收   引用计数器：\n 为每一个对象创建一个引用计数器，有引用此对象，计数器进行+1；引用释放后，计数器进行-1。当对象引用计数器 == 0时，说明此对象可以进行回收。(不能解决循环引用问题)    可达性分析算法\n 从GC Roots开始向下搜索，走过的搜索路径将形成引用链，当一个对象到 GC Roots不存在任何引用链式，说明此对象可以进行回收。      2.什么是Netty？  见 Netty\n 3.Netty粘包/拆包 3.Kubernetes工作原理 4.快排实现原理 B_D 1. Hash最终一致性算法   算法目标：\n当K个Key的请求时，后台增减节点，只会引起 K/N 的 Key发生重新映射。\n 在后台节点稳定时，同一个key的每次请求映射到的节点是一样的。 在后台节点增减时，此算法尽量将 K 个Key映射到之前相同的节点上。    Hash存在问题：\n 假定N为后台服务节点数，当前台携带关键字key发出请求时，我们通常将key进行Hash后采用 模运算(hash(key)%N) 来讲请求分发在不同的节点上。 对前台请求于后台无状态服务节点不敏感的场景而言，只要请求key具有一定的随机性，哪怕节点动态增删，该算法对于后台而言一样可以起到很好的负载均衡效果。 但在对于分布式缓存，或者分布式数据这样有状态服务的情况下，上述方式将存在问题。因为后台节点的增删会引起几乎所有的Key的重新映射：  针对分布式缓存而言，均发生cache miss； 针对分布式数据库而言，发生数据错乱的情况，影响都是灾难性的。      判断标准：\n 平衡性(Balance)：指哈希的结果能够尽可能分不到所有的缓冲中，这样可以使得所有缓冲空间都得到利用。 单调性(Monotonicity)：单调性是指如果已经有一些内容通过Hash算法分配到了缓冲中，又有新的缓冲加入到系统中，Hash的结果应该能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲。不同的终端可能通过Hash的过程将同样的缓冲内容应设在不同的缓冲中。应尽量降低分散性。 负载(Load)：实际上是另一个角度看待分散性。对于一个特定的缓冲区而言，可能被不同的用户映射到不同的内容。应尽量降低缓冲的负荷。    Hash一致性算法：\n 是一个2^32个点组成的Hash圆环 按照 顺时针方向 进行组织 将数据 Key 使用相同的 hash() 计算出Hash值，并确定在此 Hash环 上的位置，从此位置按照 顺时针方式 寻找，碰到的第一台节点将是定位到的节点。    Hash环发生数据倾斜\n 在服务节点太少的情况，数据容易发生倾斜 解决办法：  增加虚拟节点，形成均匀的Hash环避免数据倾斜。 通过 Hash(\u0026quot;${Node1}#1\u0026quot;) 的方式构造成虚拟节点。      2. TCP与UDP的区别  TCP  面向有连接  发送数据前两端必须进行连接。因 三次握手 建立连接，使得数据传输更加可靠     仅支持单播方式 面向字节流  不保留报文边界，通过字节流的方式进行传输   可靠传输  为保证可靠传输，每个包都拥有序号，同时保证包传输的顺序性也保证包的完整性。 接收端接收到数据后需要返回确认帧，如果在规定时延内发送端未收到确认帧，将视为丢包进行重传。   拥塞机制  在网络出现拥塞的情况下，TCP可以减小向网络注入数据的速率和数量，缓解拥塞   提供全双工通信  通讯双方的应用程序在任何时候都能发送数据     UDP  面向无连接 支持单播、多播、广播方式 面向报文  UDP对应用成交付的报文不合并不拆分，而是保留报文的边界，应用程序必须要控制合适的报文大小。   不可靠性  通信不需要建立连接。想发就发，并且不关心对方接收到的数据是否正确无误 没有拥塞控制，可能出现丢包情况。   头部数据小，数据传输高效。    3. TCP如何保证网络安全的   即TCP的特性\n 4. TCP三次握手  第一次握手  客户端 向 服务端 发出连接请求的报文，请求发送成功后，客户端进入 SYN-SENT 状态   第二次握手  服务端 收到 客户端 连接请求的报文后，如同意连接，发出一个应答，发送完成后进入 SYN-RECEIVED 状态   第三次握手  当 客户端 收到连接同意的应答后，需向服务端发送一个确认报文。发送完成后，客户端进入 ESTABLISHED 状态， 服务端 收到这个确认应答后也将进入 ESTABLISHED    5. TCP四次挥手 （1）：客户端发送终止命令FIN\n（2）：服务端收到后回复ACK，处于close_wait状态\n（3）：服务器将关闭前需要发送信息发送给客户端后处于last_ack状态\n（4）：客户端收到FIN后发送ack后处于tim-wait而后进入close状态\n5. Kubernetes中Pod间如何通讯的  通过 CNI(Container Network Interface) 进行网络通讯。\n 6. Mysql索引  Mysql索引\n 7. Mysql B+ Tree索引实现原理 8. Zookeeper在Kafka中的作用   Broker注册\n分布式下的Broker之间相互独立，需要一个注册中心将其Broker集群管理起来，Zookeeper将会对Broker集群列表进行记录。\n  Topic注册\n同一个Topic的消息会被分成多个分区分散在不同的Broker，Zookeeper将会维护分区信息以及与broker之间对应关系。\n  负责Producer、Consumer负载均衡\nZookeeper通过负载均衡，协助Producer、Consumer将消息合理的发送或消费到指定的Broker。\n  分区与Consumer的关系\n每一个消费者一旦确定一个消息分区的消费能力，需要将其对应信息写入至Zookeeper对应消息分区的临时节点上。\n  记录Consumer消费进度Offset\n在Consumer对指定消息分区进行消费的过程中，会定时将分区消息的Offset记录到Zookeeper上。以便此消费者重启或变更其他消费者消费时再次继续进行消费。\n  9. 有没有做过DockerImage精简 10. 服务是如何在服务器运行的，如何实现发布DockerImage发布的 ","date":"2021-01-08T01:13:47+08:00","permalink":"https://example.com/p/interview-3.-%E9%9D%A2%E8%AF%95%E4%B9%8Bjava/","title":"[ Interview ] 3. 面试之Java"},{"content":"面试准备 1. 什么是解耦 2. 什么是异步 3. 什么是消峰填谷 4. RocketMQ执行流程 5. 怎么理解Producer 6. 怎么理解Consumer 7. 消费者消费模式有哪些 8. 消费者获取消息有几种模式 9. 定时消息是什么样的？如何实现的？ 10. RocketMQ如何保证高可用的？ 11. 如何保证消息不被重复消费？或者说如何保证消息消费是的幂等性？ 12. 如何保证消息的可靠性传输？若消息出现丢失如何处理？ 13. 如何保证消息的顺序性？ 14. 如何解决消息队列的延时以及过期失效问题？ 15. 消息队列满了以后如何处理？有几百万消息持续挤压几小时，如何解决？ 16. 如何解决高性能读写数据问题？ ","date":"2021-01-08T01:13:47+08:00","permalink":"https://example.com/p/rocketmq-1.%E9%9D%A2%E8%AF%95/","title":"[ RocketMQ ] 1.面试"},{"content":"Spring 1. Spring BeanFactory与FactoryBean的区别   BeanFactory:\n BeanFactory 是一个工厂类(接口）。同时是IOC容器的核心接口，用于 管理Bean 的工厂。 职责包括：实例化、定位、配置应用程序中对象 以及 对象间的依赖关系。    FactoryBean:\n 为IOC容器中的Bean的实现提供更加灵活的方式。 FactoryBean在IOC容器的基础上为Bean的实现加上了一个简单工厂模式和装饰模式，可以通过在getObject()方法灵活配置。 当IOC容器中的Bean实现了FactoryBean接口后，通过getBean()获取到的Bean对象并不是FactoryBean的实现类对象，而是这个实现类中getObject()返回的对象。 如果想要获取FactoryBean的实现，需要在getBean()参数BeanName前添加\u0026amp;符号。    2. Bean的生命周期?  实例化Bean： Ioc容器通过获取BeanDefinition对象中的信息进行实例化，实例化对象被包装在BeanWrapper对象中 设置对象属性（DI）：通过BeanWrapper提供的设置属性的接口完成属性依赖注入； 注入Aware接口（BeanFactoryAware， 可以用这个方式来获取其它 Bean，ApplicationContextAware）：Spring会检测该对象是否实现了xxxAware接口，并将相关的xxxAware实例注入给bean BeanPostProcessor：自定义的处理（分前置处理和后置处理） InitializingBean和init-method：执行我们自己定义的初始化方法 使用 destroy：bean的销毁  IOC：控制反转：将对象的创建权，由Spring管理. DI（依赖注入）：在Spring创建对象的过程中，把对象依赖的属性注入到类中。\n4. SpringIOC 控制反转，通过依赖注入方式实现，IOC利用java反射机制，AOP利用代理模式。所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是耦合性太强，IOC则是统一交给spring来管理创建，将对象交给容器管理，你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类\n5. Spring容器加载Bean  BeanDefinitionReader读取Resource所执行的配置文件资源，解析配置文件，并将生成的BeanDefinition对象保存到BeanDefinitionRegistry中。 容器扫描Bean定义注册表中的BeanDefinition对象，调用InstantiationStrategy进行Bean实例化的工作；采用BeanWrapper完成Bean属性的设置工作。 若是单例的Bean，则将Bean缓存在Bean缓存器中。  6. Spring三级缓存  一级缓存：Map\u0026lt;String, Object\u0026gt; singletonObjects  作用  用于存储单例模式下创建的Bean实例（已经创建完毕）。 该缓存是对外使用的，指的就是使用Spring框架的程序员。   对象  K：bean的名称 V：bean的实例对象（有代理对象则指的是代理对象，已经创建完毕）     第二级缓存：Map\u0026lt;String, Object\u0026gt; earlySingletonObjects  作用：  用于存储单例模式下创建的Bean实例（该Bean被提前暴露的引用,该Bean还在创建中）。 该缓存是对内使用的，指的就是Spring框架内部逻辑使用该缓存。   对象：  K：bean的名称 V：bean的实例对象（有代理对象则指的是代理对象，该Bean还在创建中）     第三级缓存：Map\u0026lt;String, ObjectFactory\u0026lt;?\u0026raquo; singletonFactories  作用：  通过ObjectFactory对象来存储单例模式下提前暴露的Bean实例的引用（正在创建中）。 该缓存是对内使用的，指的就是Spring框架内部逻辑使用该缓存。 此缓存是解决循环依赖最大的功臣   对象：  K：bean的名称 V：ObjectFactory，该对象持有提前暴露的bean的引用      举例描述三级缓存\n 实例化 A，此时 A 还未完成属性填充和初始化方法（@PostConstruct）的执行，A 只是一个半成品。 为 A 创建一个 Bean 工厂，并放入到 singletonFactories 中。 发现 A 需要注入 B 对象，但是一级、二级、三级缓存均为发现对象 B。 实例化 B，此时 B 还未完成属性填充和初始化方法（@PostConstruct）的执行，B 只是一个半成品。 为 B 创建一个 Bean 工厂，并放入到 singletonFactories 中。 发现 B 需要注入 A 对象，此时在一级、二级未发现对象 A，但是在三级缓存中发现了对象 A，从三级缓存中得到对象 A，并将对象 A 放入二级缓存中，同时删除三级缓存中的对象 A。（注意，此时的 A 还是一个半成品，并没有完成属性填充和执行初始化方法） 将对象 A 注入到对象 B 中。 对象 B 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 B。（此时对象 B 已经是一个成品） 对象 A 得到对象 B，将对象 B 注入到对象 A 中。（对象 A 得到的是一个完整的对象 B） 对象 A 完成属性填充，执行初始化方法，并放入到一级缓存中，同时删除二级缓存中的对象 A。  7. Spring循环依赖  出现循环依赖的Bean必须要是单例 依赖注入的方式不能全是构造器注入的方式 Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects）,二级缓存为早期曝光对象earlySingletonObjects，三级缓存为早期曝光对象工厂（singletonFactories）  8. SpringAOP   代理创建\n 首先，需要创建代理工厂，代理工厂需要 3 个重要的信息：拦截器数组，目标对象接口数组，目标对象。 创建代理工厂时，默认会在拦截器数组尾部再增加一个默认拦截器 —— 用于最终的调用目标方法。 当调用 getProxy 方法的时候，会根据接口数量大余 0 条件返回一个代理对象（JDK or Cglib）。    代理调用\n 当对代理对象进行调用时，就会触发外层拦截器。   外层拦截器根据代理配置信息，创建内层拦截器链。创建的过程中，会根据表达式判断当前拦截是否匹配这个拦截器。而这个拦截器链设计模式就是职责链模式。 当整个链条执行到最后时，就会触发创建代理时那个尾部的默认拦截器，从而调用目标方法。最后返回    SpringAOP的关键点\n 切面（Aspect） @AspectJ 连接点 通知 切入点 引入 目标对象 织入    9. JDK动态代理和CGLIB动态代理的区别  JDK动态代理只提供接口的代理，不支持类的代理。核心InvocationHandler接口和Proxy类，InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy利用 InvocationHandler动态创建一个符合某一接口的的实例, 生成目标类的代理对象。 如果代理类没有实现 InvocationHandler 接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。 静态代理与动态代理区别在于生成AOP代理对象的时机不同，相对来说AspectJ的静态代理方式具有更好的性能，但是AspectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理。  10. 自动装配 在Spring框架中，在配置文件中设定bean的依赖关系是一个很好的机制，Spring 容器能够自动装配相互合作的bean，这意味着容器不需要和配置，能通过Bean工厂自动处理bean之间的协作。这意味着 Spring可以通过向Bean Factory中注入的方式自动搞定bean之间的依赖关系。自动装配可以设置在每个bean上，也可以设定在特定的bean上。\n11. Spring启动加载配置文件的流程 在Spring中的，如果一个Bean实现了ApplicationListener接口，并且已经发布到容器中去，每次ApplicationContext发布一个ApplicationEvent事件，这个Bean就会接到通知。Spring事件机制是观察者模式的实现。\n12. @Autowired与@Resource区别  @Autowired默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。@Autowired 注解提供了更细粒度的控制，包括在何处以及如何完成自动装配。它的用法和@Required一样，修饰setter方法、构造器、属性或者具有任意名称和/或多个参数的PN方法。 @Autowired默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。 @Resource默认是按照名称来装配注入的，只有当找不到与名称匹配的bean才会按照类型来装配注入。 @Autowired可用于：构造函数、成员变量、Setter方法  13. @Qualifier与@Autowired  当您创建多个相同类型的 bean 并希望仅使用属性装配其中一个 bean 时，您可以使用@Qualifier 注解和 @Autowired 通过指定应该装配哪个确切的 bean 来消除歧义。  14. SpringBoot启动流程  new springApplication对象，利用spi机制加载applicationContextInitializer， applicationLister接口实例（META-INF/spring.factories）； 调run方法准备Environment，加载应用上下文（applicationContext），发布事件 很多通过lister实现 创建spring容器， refreshContext（） ，实现starter自动化配置，spring.factories文件加载， bean实例化  SpringBoot自动配置的原理  @EnableAutoConfiguration找到META-INF/spring.factories（需要创建的bean在里面）配置文件 读取每个starter中的spring.factories文件  15. SpringAOP常用的切入点 16. SpringIOC常用注解 17. SpringBoot订阅发布模式。ApplicationEvent处于什么角色，如何实现的？ ","date":"2021-01-08T01:13:47+08:00","permalink":"https://example.com/p/spring-1.-spring/","title":"[ Spring ] 1. Spring"},{"content":"面试之清单  加粗加斜 : 为本人面试所遇到重复出现的点儿 加粗 : 为本人面试所遇到的点儿 正常 : 为本人面试刷的面经  Algorithm Sort  手撸插入排序 手撸二分查找 堆排序(Top K) 快素排序思想 反转单链表 合并二叉树(递归与非递归两种办法)  Java Basic  Object是所有对象的父类，那Object类中有哪些方法 hashCode()与equals()有什么关系 String、StringBuilder、StringBuffer区别 反射机制 方法(静态、一般方法)；代码块(this，ClassName.class)  Collections  List之ArrayList List之LinkedList List之Vector Map之HashMap Map之LinkedHashMap Map之ConcurrentHashMap Map之TreeMap HashTable Set之HashSet Set之TreeSet Queue之ArrayBlockingQueue Queue之ConcurrentLinkedQueue Queue之LinkedBlockingQueue  Thread  线程的几种状态以及如何转化的 三种线程初始化方法的区别(Thread,Callable,Runnable) 线程池几个重要参数 线程池四种拒绝策略 线程池四个类型 线程池(ThreadPoolExecutor)原理 关于锁 synchronized锁以及锁升级 ReentrantLock与synchronized区别 有界、无界任务队列，手写BlockingQueue ThreadLocal：底层数据结构、ThreadLocalMap、原理、应用场景 Atomic类：原理、应用场景 Volatile：原理、有序性、可见性  JVM   JVM内存结构\n  final修饰的常量处于JVM中哪部分内存\n  JVM垃圾回收机制\n  引用类型\n  JVM垃圾回收器，各有什么特点\n  垃圾回收算法\n  对象什么时间可以被回收\n  新生代垃圾回收器与老年代垃圾回收器有哪些？区别是什么？\n  CMS垃圾回收器\n  JVM中Survivor空间是做什么的\n  类加载器\n  双亲委派模型\n  Tomcat打破双亲委派\n  类加载机制\n  类加载\n  Java Framework Spring   SpringIOC原理\n  容器加载Bean流程\n  SpringAOP原理\n  FactoryBean 与 BeanFactory区别\n  Spring三级缓存\n  SpringBoot循环依赖\n  SpringBoot订阅发布模式。ApplicationEvent处于什么角色，如何实现的？\n  JDK动态代理和CGLIB动态代理的区别\n  SpringAOP常用的切入点\n  SpringIOC常用注解\n  @Autowired与@Resource区别\n  @Qualifier与@Autowired\n  SpringBoot上下文切换\n  SpringBoot编译打包后包的结构?通过main()函数作为主入口的程序打包后如何启动？\n  Spring启动加载配置文件的流程\n  自动装配\n  MyBatis   MyBatis二级缓存\n  Mybatis原理\n  Netty  聊聊Netty Netty中的拆包、粘包是为什么？如何解决？ Netty的线程模型 Netty的重要组件 Netty中EventLoopGroup与EventLoop什么区别  Dubbo  Dubbo中的SPI，为什么不适用JDK的SPI？ Dubbo中的SPI Dubbo服务注册与发现流程 Dubbo通信原理 Dubbo分层 Dubbo服务暴露流程 Dubbo服务引用流程 Dubbo的管理控制台能做什么 Dubbo集群容错方案 Dubbo支持什么协议 Dubbo如何做负载均衡 Dubbo如何实现异步调用 Dubbo在Provide上可以配置Consumer哪些属性 Zookeeper和Dubbo的关系 Dubbo分层  Zookeeper  一致性算法原理 选举流程 ZAB协议  Kafka  Zookeeper在Kafka中的作用  RocketMQ ElasticSearch Middleware Redis   什么是击穿？什么是雪崩？\n  Redis支持的几种数据结构\n  Redis跳表\n  Redis中的BitMap\n  MySQL   讲讲Mysql索引\n  Mysql中B+ Tree索引原理\n  Mysql索引失效的几种情况\n  Mysql强制索引\n  分库分表如何实现的\n  分库分表中间件\n  Distribution Base  一致性Hash算法  Kubernetes  Kubernetes中Pod间是如何通信的 Kubernetes中IngressController  操作系统 TCP/IP  TCP三次握手/四次挥手 TCP与UDP的区别  多线程与并发  说说进程、线程、协程 操作系统的互斥锁原理，阻塞过程中(抢锁失败)线程会做什么  设计模式  观察者模式 单例模式  ","date":"2021-01-07T01:13:47+08:00","permalink":"https://example.com/p/interview-1.-%E9%9D%A2%E8%AF%95%E4%B9%8B%E6%B8%85%E5%8D%95/","title":"[ Interview ] 1. 面试之清单"},{"content":"MyBatis 1. MyBatis二级缓存   一级缓存：\n 基于PrepetualCache的HashMap本地缓存，其作用域是Session。 当Session在flush()或者close()之后，此Session中所有Cache都将被清除。 默认情况下，一级缓存处于打开状态。    二级缓存：\n 二级缓存与一级缓存机制相同，一样基于PrepetualCache HashMap进行存储。 但其作用于是Mapper(Namespace)，而且可以采用自定义存储源， 例如Ehcache、Redis等。 默认情况下，二级缓存处于关闭状态。 二级缓存在使用中，其属性类型需要实现serialize序列化接口。 可在其映射配置文件中进行    对于缓存更新机制，当某一作用域(一级Session/二级Namespace)执行C/U/D后 默认情况下，此作用域下所有select中的缓存将被clear。\n  2. Mybatis工作原理   加载Mybatis全局配置文件mybatis-config.xml：\n 此配置文件用于配置数据库连接信息。    加载Mybatis映射配置文件xxx-mapper.xml:\n 此配置文件包含有操作数据库的SQL语句，需在mybatis-config.xml文件中进行配置。 mybatis-config.xml中可以配置多个xxx-mapper.xml文件 一个xxx-mapper.xml文件对应数据库中一张表。    构建会话工厂：\n 通过配置信心初始化构建SQLSessionFactory对象。    创建会话对象：\n 基于会话工厂创建SQLSession对象。 此Sqlsession对象中包含有执行SQL语句的所有方法。    Executor执行器\n Mybatis底层封装了一个Executor的接口用于操作数据库。 将根据SqlSession对象传递的参数动态生成所需要执行的SQL语句，同时负责缓存查询。    MappedStatement对象：\n 在Executor接口的执行方法中存在一个MappedStatement类型的参数， 该参数是对映射地址信息进行封装，用于存储要映射的SQL语句的id，参数等信息。    输入参数映射：\n 输入类型可以为Map、List等集合，也可为基本类型和POJO类型。 输入参数映射的过程类似于JDBC中preparedStatement对象设置参数的过程。    输出结果映射：\n 输出类型通输入类型一样。可为List、Map等集合，也可为基本类型和POJO类型。 输出结果映射的过程类似于JDBC的解析过程。    ","date":"2021-01-07T01:13:47+08:00","permalink":"https://example.com/p/mybatis-1.-mybatis/","title":"[ Mybatis ] 1. Mybatis"},{"content":"Netty基础 从一答一问开始Netty 1. 为什么用Netty？ a. Netty是一个基于JDK NIO的Client/Server架构的框架。可以快速进行网络开发; b. 相比JDK NIO，极大简化TCP、UDP套接字服务器网络变成，并且性能、安全性出色; c. 支持多种协议：FTP、SMTP、HTTP以及各种二进制和基于文本的传统协议; d. 统一的API、支持多种传输类型(阻塞、非阻塞I/O); e. 简单且强大的线程模型; f. 自带编解码器解决粘包、拆包问题; g. 自带各种协议栈; h. 安全性不错，支持完整的SSL/TLS及StartTLS协议; i. 相比JDK NIO，API具有更高吞吐量、更低延迟、更低资源消耗和更少的内存复制; j. 成熟项目很多：Dubbo、RocketMQ。 2. Netty应用场景 a. RPC框架的网络通信工具 b. 自实现HTTP服务器 c. 实现即时通信系统 d. 实现消息推送系统 3. Netty核心组件   Channel\n对网络操作的抽象类。除I/O基本操作之外，支持bind(),connect(),read(),write()操作。\n  EventLoop\nEventLoop是Netty的核心抽象，用于处理连接在生命周期中所发生的事件。 主要作用：负责监听网络事件并调用事件处理器进行相关的I/O操作。\nEventLoop 负责处理注册到其上的 Channel 处理I/O操作，两者配合参与I/O操作。\n  ChannelFuture\nNetty是异步非阻塞，所有的I/O操作都是异步。所以不可以立即得到操作结果。但是\n（1）通过 ChannelFuture 接口的 addListener() 注册一个 ChannelFutureListener 对象，操作执行成功或失败后，监听会自动触发返回结果；\n（2）也可以通过 ChannelFuture 的 channel() 获取关联的 Channel 对象；\n（3) 也可以通过 ChannelFuture 的 sync() 进行让异步的操作变成同步。\n  ChannelHandler与ChannelPipeline\n  ChannelHandler 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。\n  ChannelPipeline 为 ChannelHandler 链提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline 。\n  我们可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。\n    4. Netty线程模型   单线程模型\n一个线程需要执行处理所有的 accept、read、decode、process、encode、send 事件。对于高负载、高并发，并且对性能要求比较高的场景不适用。\n//1.eventGroup既用于处理客户端连接，又负责具体的处理。  EventLoopGroup eventGroup = new NioEventLoopGroup(1); //2.创建服务端启动引导/辅助类：ServerBootstrap  ServerBootstrap b = new ServerBootstrap(); boobtstrap.group(eventGroup, eventGroup) //......   多线程模型\n一个 Acceptor 线程只负责监听客户端的连接，一个 NIO 线程池负责具体处理 满足绝大部分应用场景，并发连接量不大的时候没啥问题，但是遇到并发连接大的时候就可能会出现问题，成为性能瓶颈。\n// 1.bossGroup 用于接收连接，workerGroup 用于具体的处理 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //2.创建服务端启动引导/辅助类：ServerBootstrap  ServerBootstrap b = new ServerBootstrap(); //3.给引导类配置两大线程组,确定了线程模型  b.group(bossGroup, workerGroup) //......   主从多线程模型\n从一个 主线程 NIO 线程池中选择一个线程作为 Acceptor 线程，绑定监听端口，接收客户端连接的连接，其他线程负责后续的接入认证等工作。连接建立完成后，Sub NIO 线程池负责具体处理 I/O 读写。如果多线程模型无法满足你的需求的时候，可以考虑使用主从多线程模型 。\n// 1.bossGroup 用于接收连接，workerGroup 用于具体的处理 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //2.创建服务端启动引导/辅助类：ServerBootstrap  ServerBootstrap b = new ServerBootstrap(); //3.给引导类配置两大线程组,确定了线程模型  b.group(bossGroup, workerGroup) //.....   5. EventLoopGroup是什么？与EventLoop关系。   EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。\n  EventLoopGroup 包含多个 EventLoop（每一个 EventLoop 通常内部包含一个线程）。 并且 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理，即 Thread 和 EventLoop 属于 1 : 1 的关系，从而保证线程安全。\n  BossEventLoopGroup 用于接收连接，WorkerEventLoopGroup 用于具体的处理（消息的读写以及其他逻辑处理）\n  当客户端通过 connect() 连接服务端时，BossEventLoopGroup 处理客户端连接请求。当客户端处理完成后，会将这个连接提交给 WorkerEventLoopGroup 来处理，然后 WorkerEventLoopGroup 负责处理其 IO 相关操作。\n  6. Netty中TCP粘包、拆包 TCP 粘包/拆包 就是基于 TCP 发送数据的时候，出现了多个字符串“粘”在了一起或者一个字符串被“拆”开的问题。\n解决办法：\n 使用 Netty 自带的解码器  LineBasedFrameDecoder : 发送端发送数据包的时候，每个数据包之间以换行符作为分隔，LineBasedFrameDecoder 的工作原理是它依次遍历 ByteBuf 中的可读字节，判断是否有换行符，然后进行相应的截取。 DelimiterBasedFrameDecoder : 可以自定义分隔符解码器，LineBasedFrameDecoder 实际上是一种特殊的 DelimiterBasedFrameDecoder 解码器。 FixedLengthFrameDecoder: 固定长度解码器，它能够按照指定的长度对消息进行相应的拆包。 LengthFieldBasedFrameDecoder + LengthFieldPrepender 配合使用: 处理粘拆包的主要思想是在生成的数据包中添加一个长度字段，用于记录当前数据包的长度。(分为有头部的拆包与粘包、长度字段在前且有头部的拆包与粘包、多扩展头部的拆包与粘包。)  LengthFieldBasedFrameDecoder会按照参数指定的包长度偏移量数据对接收到的数据进行解码，从而得到目标消息体数据 LengthFieldPrepender则会在响应的数据前面添加指定的字节数据，这个字节数据中保存了当前消息体的整体字节数据长度     自定义序列化编解码器  通过继承LengthFieldBasedFrameDecoder和LengthFieldPrepender来实现粘包和拆包的处理    7. Netty长连接、心跳机制 在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 心跳机制 。\n  心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.\n  Netty中的心跳机制实现： TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是 TCP 的选项：SO_KEEPALIVE。但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义心跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 IdleStateHandler\n  8. Netty零拷贝 在 OS 层面上的 Zero-copy 通常指避免在 用户态(User-space) 与 内核态(Kernel-space) 之间来回拷贝数据。而在 Netty 层面，零拷贝主要体现在对于数据操作的优化。\nNetty 中的零拷贝体现在以下几个方面：\n 使用 Netty 提供的 CompositeByteBuf 类， 可以将多个ByteBuffer 合并为一个逻辑上的 ByteBuffer， 避免了各个 ByteBuf 之间的拷贝。 ByteBuffer 支持 slice 操作， 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf， 避免了内存的拷贝。 通过 FileRegion 包装的FileChannel.tranferTo 实现文件传输， 可以直接将文件缓冲区的数据发送到目标 Channel， 避免了传统通过循环 write 方式导致的内存拷贝问题。  ","date":"2021-01-05T10:36:27+08:00","permalink":"https://example.com/p/netty-1.netty%E5%9F%BA%E7%A1%80/","title":"[ Netty ] 1.Netty基础"},{"content":"面试准备 一、学习路线 1.Java基础  面向对象特性：封装、继承、多态(动态绑定、向上转型) 泛型、类型擦除 反射、其原理及其优缺点 static,final关键字 String,StringBuffer,StringBuilder底层区别 BIO、NIO、AIO Object类的方法 自动拆箱与自动装箱  2.集合框架  List  ArrayList LinkedList Vector CopyOnWriteArrayList   Set  HashSet TreeSet LinkedHashSet   Queue  PriorityQueue   Map  HashMap TreeMap LinkedMap   fast-fail，fast-safe机制 源码分析(底层数据结构，插入、扩容过程)、线程安全分析  3.Java虚拟机  类加载机制、双亲委派模式、3种加载器(BootstrapClassLoader，ExtensionClassLoader，ApplicationClassLoader) 运行时内存分区(PC，Java虚拟机栈，本地方法栈，堆，方法区[永久代、元空间]) JMM: Java内存模型分析 引用计数、可达性分析 垃圾回收算法：标记-清除、标记-整理、复制 垃圾回收器：比较区别(Serial，ParNew，ParallelScavenge，CMS，G1) 强、软、弱、虚引用 内存溢出、内存泄漏排查 JVM调优、常用命令  4.Java并发  三种线程初始化方法的区别(Thread,Callable,Runnable) 线程池(ThreadPoolExecutor，7大参数、原理、四种拒绝策略、四个类型[Fixed、Single、Cached、Scheduled]) Synchronized 使用：方法(静态、一般方法)；代码块(this，ClassName.class) jdk1.6优化：锁粗化、锁消除、自适应自旋锁、偏向锁、轻量级锁 锁升级的过程与细节：无锁-\u0026gt;偏向锁-\u0026gt;轻量级锁-\u0026gt;重量级锁(不可逆) ReentrantLock:与Synchronized区别、公平锁、非公平锁、可中断锁、原理、用法 有界、无界任务队列，手写BlockingQueue 乐观锁：CAS(优缺点，ABA问题，DCAS) 悲观锁 ThreadLocal：底层数据结构、ThreadLocalMap、原理、应用场景 Atomic类：原理、应用场景 Volatile：原理、有序性、可见性  5.MySQL  架构：Server层、引擎层(缓存、连接器、分析器、优化器、处理器) 引擎：InnoDB、MyISAM、Memory的区别 聚簇索引、非聚簇索引区别(从二叉平衡搜索树复习[AVL，红黑树] -\u0026gt; B树 -\u0026gt; B+树) MySQL、SQL语句优化 覆盖索引、最左前缀匹配 当前读、快照读 MVCC原理(事务ID、隐藏字段、Undo、ReadView) Gap Lock、Next-Key Lock、Record Lock 三大范式 常用SQL 连接：自连接、内连接(等值、非等值、自然连接)、外连接(左、右、全) Group BY 与 Having Explain  5.Spring  AOP原理(JDK动态代理、CGLIB动态代理)、IOC原理 SpringBean生命周期 SpringMVC原理 SpringBoot常用注解  6.Unix Network  OSI模型、TCP/IP模型 TCP、UDP区别 TCP可靠性传输原理  重传 流量控制 拥塞控制 序列号、确认应答号 校验和   三次握手、四次挥手原理 timewait、closewait HTTP  报文格式 协议 状态码 无状态解决(Cookie、Session)   HTTPS  CA证书 对称、非对称加密   DNS解析过程原理 IP、ICMP、ARP、ROUTE协议 攻击手段：XSS、CSRF、SQL注入、DOS、DDOS  7.OS  进程、线程、协程区别 进程通信方式(管道、消息队列、共享内存、信号、信号量、socket) 进程调度算法：  先进先出 短作业优先 时间片轮换 多级反馈队列 优先级调度   内存管理  页面置换算法：手写LRU 分段 虚拟内存    二、面试题锦 1.算法\n 手写最大堆 一道 LeetCode 难问题：接雨水（动态规划解决） 手写 LRU（要求用泛型写）、手写 DCL 一道动态规划题目：不同路径 手写个归并排序 了解 A*算法吗？ 手写地杰斯特拉算法？ 说说深度优先搜索算法、回溯算法 一道算法题：一个走迷宫问题，DFS+回溯解决 一道算法题：最长公共子串 两个栈实现队列 最近公共祖先节点 一道算法题：完全平方数（动态规划） 手写一个堆排序。 手写快排 算法题：按 K 位反转链表 一百亿个数，n 个机器，怎么排序？（桶排序）  2.设计模式\n 设计模式了解吗？几大类型？谈谈工厂模式？  3.Java 集合\n 谈一下 Java 集合框架？HashMap 线程安全的吗？会出现什么问题？ 说说 fast-fail 和 fast-safe？ 讲讲 HashMap 的原理，put 过程？resize 过程？线程安全吗？死循环问题  4.Java 并发\n 知道哪些 Java 的锁？CAS 的缺点？Synchronized 优化内容？锁升级过程？ 线程池了解吗？原理？可以写个 BlockingQueue 吗？ 了解死锁吗？怎么解决？ 哪些对象可以作为 GC ROOTS 谈谈公平锁和非公平锁？ Synchronized 和 ReentrantLock 区别 ThreadLocal 了解吗？原理？  5.JVM\n 谈谈Java虚拟机你的认识？垃圾回收算法？垃圾回收器？ Java是怎么进行垃圾回收的？ 谈谈Java虚拟机？类加载机制？ 知道双亲委派模式吗？有什么好处？ Java运行时内存分区？ 讲一下CMS垃圾回收过程 OOM 怎么排查？  6.MySQL\n InnoDB 和 MyISAM 区别？谈谈 MySQL 的各种引擎？ 知道聚簇索引和非聚簇索引吗？B 树和 B+树区别？ 说说 MySQL 的架构 说说 MYSQL 优化策略？ 覆盖索引和非覆盖索引区别？ MYSQL 优化方法有哪些？ MySQL 的索引为什么快？有哪些索引？原理数据结构？ 谈谈各种索引？为什么用 B+树不用 B 树？ B+ Tree索引和Hash索引区别？  7. Redis\n Redis  8.Spring\n 谈谈 Spring AOP 和 IOC SpringBoot 常用哪些注解？  9.Mybatis\n Mybatis  10.ElasticSearch\n ES  11.Kafka\n Kafka  12.Dubbo\n13.Netty\n14.RocketMQ\n15.Zookeeper\n16.OS\n DNS 解析过程 进程间通信方式？哪种最高效？ ARP 过程？ 进程调度算法？  17.Network\n TCP 如何保证可靠性传输？（校验和，序列号和确认应答号，重传，流量控制，拥塞控制） TCP拥塞控制算法？ TCP 和 UDP 区别？ HTTP 的状态码记得哪些？ ICMP 是哪层的？有什么用？  18.分布式系统\n 谈谈你对分布式系统的认识？  ","date":"2021-01-05T01:13:47+08:00","permalink":"https://example.com/p/interview-2.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/","title":"[ Interview ] 2.面试准备"},{"content":"面试准备  Java线程池  JDK中JUC包  JVM调优：如果发现某个服务慢，如何排查，如何处理；发现某个服务器CPU100%了，应该如何处理 遵循六步走原则： 1）找到罪魁祸首的进程 2）分析进程对应的线程 3）生成JVM当前时刻线程快照 4）分析定位代码问题 5）  垃圾回收器G1与GC算法CMS  Tomcat 如何实现类隔离  Spring IOC原理  Spring AOP原理  Spring事务  Dubbo服务发现、注册流程  Dubbo通信原理  Dubbo SPI与Java SPI  Zookeeper选举协议  大数据量的排序如何处理  如何判断链表是回文链表、快排序、归并排序  MySQL调优：B+ Tree索引、Hash索引  Mybatis的一、二级缓存  Mybatis工作原理  Redis Bitmap  ","date":"2020-12-31T11:13:47+08:00","permalink":"https://example.com/p/interview-1.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/","title":"[ Interview ] 1.面试准备"},{"content":"HashMap虐杀，完败  HashMap内部实现是一个 桶数组 ，每个桶中存放着一个 单链表的头结点 。其中每个结点存储的是一个 键值对整体（Entry），HashMap采用 拉链法 解决哈希冲突。\n 1. HashMap的resize()流程 源码解析\n// 扩容 hashTable 大小的方法  final Node\u0026lt;K,V\u0026gt;[] resize() { // 扩容前 hashTable  Node\u0026lt;K,V\u0026gt;[] oldTab = table; // 扩容前 HashTable 的容量  int oldCap = (oldTab == null) ? 0 : oldTab.length; // 扩容前 扩容阈值  int oldThr = threshold; int newCap, newThr = 0; // 扩容前HashTable不为null  if (oldCap \u0026gt; 0) { // 如果扩容前容量已经大于HashMap最大容量阈值，将不再扩容，直接返回hashMap  if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 如果扩容一倍后容量 \u0026lt; 最大容量，并且 扩容前容量值 \u0026gt;= 初始化容量值 ，将 扩容阈值 也扩大一倍  else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold  } else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold  newCap = oldThr; else { // zero initial threshold signifies using defaults  // 如果 hashTable 为null 或者 长度 \u0026lt;= 0， 将重新初始化容量16、扩容阈值 12  newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { // 计算新的扩容阈值  float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) // 按照新的容量 创建新的hashTable  Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; // 把旧哈希表中的内容移动到新哈希表中  if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // preserve order  Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 2. HashMap的put()流程 先根据key确定其在Hash表中的下标，找到对应的bucket，遍历链表(或者红黑树)进行插入操作。\n 先判断Hash表是否为null或者长度是否为0，是则进行一次扩容； 根据 key 确定 Hash表 中的 index，在找到对应的 bucket，如果 bucket 上没有节点，直接新增一个节点； 如果当前 bucket 上存在链表，且头节点可以匹配上，直接进行替换； 如果当前 bucket 上是红黑树，则按照红黑树操作进行插入或替换； 如果以上情况都不满足，将开始遍历链表，如果匹配到就进行替换；如果未匹配到将在链表尾部添加一个节点，同时会判断链表长度是否大于 8 、Hash表数组是否大于 64，同时满足这两个条件，将链表会转化为红黑树；如果链表长度仅大于 8，将会进行扩容； 执行完成后，会判断 Map中 K-V对 数量是否大于 threshold ，是则进行扩容。  源码解析\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // n : 当前tab容量  // i : 根据 key 的 hash 值计算出的在存储数组上的下标  Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 当 hashTable 为null 或者 长度为0时，进行扩容  n = (tab = resize()).length; // 判断当前索引位置上是否存在节点  if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) // 不存在节点，直接在当前索引的位置创建一个新的节点  tab[i] = newNode(hash, key, value, null); else { // 存在节点的情况  Node\u0026lt;K,V\u0026gt; e; K k; // 如果 当前节点的key与待插入元素的key一直，直接进行替换  if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; // 如果当前索引位置上是红黑树，按照红黑树操作进行替换或插入  else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); else { // 剩下这种情况就是 当前索引位置上是链表的数据结构，进行链表上节点的遍历  for (int binCount = 0; ; ++binCount) { // 如果当前链表没有匹配到待插入元素key，在链表尾部新增一个节点  if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果当前链表长度 \u0026gt; 8 ，将 链表 转化为 树  if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st  treeifyBin(tab, hash); break; } // 在链表上匹配到与待插入元素key时，跳出循环  if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; // 将指针指向下一个节点，继续循环  p = e; } } // e 不为 null 说明匹配到了待插入元素一样的key，此时应该进行替换，并将旧值进行返回  if (e != null) { // existing mapping for key  V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 判断当前HashMap中存储的K-V对数量是否超出 扩容阈值  // threshold = DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY  if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); // 新插入的值，返回null  return null; } 3. ConcurrentHashMap.get()是否线程安全，是否有加锁？  安全，读操作不受影响。 不加锁。  4. ConcurrentHashMap如何保证线程安全  在JDK8以前，ConcurrentHashMap都是基于Segment分段锁来实现的， 在JDK8以后，就换成synchronized和CAS这套实现机制了。  使用 volatile 保证当Node中的值变化时对于其他线程是 可见的 使用 table数组的头结点 作为synchronized的锁来 保证写操作 的安全 当头结点为 null 时，使用 CAS操作 来保证数据能正确的 写入   和JDK1.8中的HashMap类似，对于hashCode相同的时候，在Node节点的数量少于8个时，这时的Node存储结构是链表形式，时间复杂度为O(N)，当Node节点的个数超过8个时，则会转换为红黑树，此时访问的时间复杂度为O(long(N))    5. HashMap、TreeMap、 LinkedHashMap区别   HashMap：\n  常用的一个Map，根据键的 HashCode 值存储数据，同时根据 键 直接获取对应的值\n  访问速度很快，通过遍历得到的数据是完全随机无需的。\n  只允许一条记录的 键 为 Null，允许多条记录的 值 为 Null\n  HashMap不支持线程同步(即同一时刻多个线程同时写HashMap)，可能会导致数据不一致\n  HashMap如果支持线程同步可以通过 Collections的synchronizedMap() 实现，或者使用 ConcurrentHashMap\n  HashMap 与 HashTable 类似，HashTable 继承自 Dictionary 类。不同是\n HashTable 不允许存在为Null的键值 支持线程同步。(所以要比HashMap要慢)      TreeMap：\n TreeMap是实现 SortMap接口 ，它能把保存的记录根据键值进行排序。 默认是按照键值升序进行排序，也可以指定排序比较器，使用Iterator进行排序，得到的记录是有序的。    LinkedHashMap：\n  是HashMap的子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的记录。\n  遍历的情况下，要比HashMap慢，不过存在例外的情况：当HashMap容量很大时，实际数据较少，遍历时可能会比LinkedHashMap慢：\nLinkedHashMap的遍历速度之和实际数据有关，与容量无关，但HashMap的遍历速度与容量相关。\n    List你使用过哪些 ArrayList和linkedList使用的最多，也最具代表性。\n你知道vector和ArrayList和linkedList的区别嘛 ArrayList实现是一个数组，可变数组，默认初始化长度为10，也可以我们设置容量，但是没有设置的时候是默认的空数组，只有在第一步add的时候会进行扩容至10（重新创建了数组），后续扩容按照3/2的大小进行扩容，是线程不安全的，适用多读取，少插入的情况\nlinkedList是基于双向链表的实现，使用了尾插法的方式，内部维护了链表的长度，以及头节点和尾节点，所以获取长度不需要遍历。适合一些插入/删除频繁的情况。\nVector是线程安全的，实现方式和ArrayList相似，也是基于数组，但是方法上面都有synchronized关键词修饰。其扩容方式是原来的两倍。\nhashMap和hashTable和ConcurrentHashMap的区别 hashMap是map类型的一种最常用的数据结构，其底部实现是数组+链表（在1.8版本后变为了数组+链表/红黑树的方式），其key是可以为null的，默认hash值为0。扩容以2的幂等次（为什么。。。因为只有是2的幂等次的时候（n-1）\u0026amp;x==x%n，当然不一定只有一个原因）。是线程不安全的\nhashTable的实现形式和hashMap差不多，它是线程安全的，是继承了Dictionary，也是key-value的模式，但是其key不能为null。\nConcurrentHashMap是JUC并发包的一种，在hashMap的基础上做了修改，因为hashmap其实是线程不安全的，那在并发情况下使用hashTable嘛，但是hashTable是全程加锁的，性能不好，所以采用分段的思想，把原本的一个数组分成默认16段，就可以最多容纳16个线程并发操作，16个段叫做Segment，是基于ReetrantLock来实现的\n说说你了解的hashmap吧 hashMap是Map的结构，内部用了数组+链表的方式，在1.8后，当链表长度达到8的时候，会变成红黑树，这样子就可以把查询的复杂度变成O（nlogn）了，默认负载因子是0.75，为什么是0.75呢？\n我们知道当负载因子太小，就很容易触发扩容，如果负载因子太大就容易出现碰撞。所以这个是空间和时间的一个均衡点，在1.8的hashmap介绍中，就有描述了，貌似是0.75的负载因子中，能让随机hash更加满足0.5的泊松分布。\n除此之外，1.7的时候是头插法，1.8后就变成了尾插法，主要是为了解决rehash出现的死循环问题，而且1.7的时候是先扩容后插入，1.8则是先插入后扩容(为什么？正常来说，如果先插入，就有可能节点变为树化，那么是不是多做一次树转化，比1.7要多损耗，个人猜测，因为读写问题，因为hashmap并不是线程安全的，如果说是先扩容，后写入，那么在扩容期间，是访问不到新放入的值的，是不是不太合适，所以会先放入值，这样子在扩容期间，那个值是在的）。\n1.7版本的时候用了9次扰动，5次异或，4次位移，减少hash冲突，但是1.8就只用了两次，觉得就足够了一次异或，一次位移。\nconcurrentHashMap呢 concurrentHashMap是线程安全的map结构，它的核心思想是分段锁。在1.7版本的时候，内部维护了segment数组，默认是16个，segment中有一个table数组（相当于一个segmeng存放着一个hashmap。。。），segment继承了reentrantlock，使用了互斥锁，map的size其实就是segment数组的count和。而在1.8的时候做了一个大改版，废除了segment，采用了cas加synchronize方式来进行分段锁（还有自旋锁的保证），而且节点对象改用了Node不是之前的HashEntity。\nNode可以支持链表和红黑树的转化，比如TreeBin就是继承了Node，这样子可以直接用instanceof来区分。1.8的put就很复杂来，会先计算出hash值，然后根据hash值选出Node数组的下标（默认数组是空的，所以一开始put的时候会初始化，指定负载因子是0.75，不可变），判断是否为空，如果为空，则用cas的操作来赋值首节点，如果失败，则因为自旋，会进入非空节点的逻辑，这个时候会用synchronize加锁头节点（保证整条链路锁定）这个时候还会进行二次判断，是否是同一个首节点，在分首节点到底是链表还是树结构，进行遍历判断。\nconcurrentHashMap的扩容方式 1.7版本的concurrentHashMap是基于了segment的，segment内部维护了HashEntity数组，所以扩容是在这个基础上的，类比hashmap的扩容，\n1.8版本的concurrentHashMap扩容方式比较复杂，利用了ForwardingNode,先会根据机器内核数来分配每个线程能分到的busket数，（最小是16），这样子可以做到多线程协助迁移，提升速度。然后根据自己分配的busket数来进行节点转移，如果为空，就放置ForwardingNode，代表已经迁移完成，如果是非空节点（判断是不是ForwardingNode，是就结束了），加锁，链路循环,进行迁移。\nhashMap的put方法的过程 判断key是否是null，如果是null对应的hash值就是0，获得hash值过后则进行扰动，（1.7是9次，5次异或，4次位移，1.8是2次），获取到的新hash值找出所在的index，（n-1）\u0026amp;hash，根据下标找到对应的Node/entity，然后遍历链表/红黑树，如果遇到hash值相同且equals相同，则覆盖值，如果不是则新增。如果节点数大于8了，则进行树化（1.8）。完成后，判断当前的长度是否大于阀值，是就扩容（1.7是先扩容在put）。\n为什么修改hashcode方法要修改equals 都是map惹的祸，我们知道在map中判断是否是同一个对象的时候，会先判断hash值，在判断equals的，如果我们只是重写了hashcode，没有顺便修改equals，比如Intger，hashcode就是value值，如果我们不改写equals，而是用了Object的equals，那么就是判断两者指针是否一致了，那就会出现valueOf和new出来的对象会对于map而言是两个对象，那就是个问题了\nTreeMap了解嘛 TreeMap是Map中的一种很特殊的map，我们知道Map基本是无序的，但是TreeMap是会自动进行排序的，也就是一个有序Map(使用了红黑树来实现），如果设置了Comparator比较器，则会根据比较器来对比两者的大小，如果没有则key需要是Comparable的子类（代码中没有事先check，会直接抛出转化异常，有点坑啊）。\nLinkedHashMap了解嘛 LinkedHashMap是HashMap的一种特殊分支，是某种有序的hashMap，和TreeMap是不一样的概念，是用了HashMap+链表的方式来构造的，有两者有序模式：访问有序，插入顺序，插入顺序是一直存在的，因为是调用了hashMap的put方法，并没有重载，但是重载了newNode方法，在这个方法中，会把节点插入链表中，访问有序默认是关闭的，如果打开，则在每次get的时候都会把链表的节点移除掉，放到链表的最后面。这样子就是一个LRU的一种实现方式。\n","date":"2020-12-31T11:13:47+08:00","permalink":"https://example.com/p/java-2.4-hashmap%E8%99%90%E6%9D%80%E5%AE%8C%E8%B4%A5/","title":"[ Java ] 2.4 HashMap虐杀，完败"},{"content":"手写LRU 1. 利用数组实现 2. 使用LinkedHashMap偷个懒 ","date":"2020-12-31T11:13:47+08:00","permalink":"https://example.com/p/java-2.5-%E6%89%8B%E5%86%99lru/","title":"[ Java ] 2.5 手写LRU"},{"content":"Mybatis源码中设计模式  Builder模式：例如SqlSessionFactoryBuilder、XMLConfigBuilder、XMLMapperBuilder、XMLStatementBuilder、CacheBuilder； 工厂模式：例如SqlSessionFactory、ObjectFactory、MapperProxyFactory； 单例模式：例如ErrorContext和LogFactory； 代理模式：Mybatis实现的核心，比如MapperProxy、ConnectionLogger，用的jdk的+ 动态代理；还有executor.loader包使用了cglib或者javassist达到延迟加载的效果； 组合模式：例如SqlNode和各个子类ChooseSqlNode等； 模板方法模式：例如BaseExecutor和SimpleExecutor，还有BaseTypeHandler和所有的子类例如IntegerTypeHandler； 适配器模式：例如Log的Mybatis接口和它对jdbc、log4j等各种日志框架的适配实现； 装饰者模式：例如Cache包中的cache.decorators子包中等各个装饰者的实现； +迭代器模式：例如迭代器模式PropertyTokenizer；  ","date":"2020-12-31T11:13:47+08:00","permalink":"https://example.com/p/mybatis-1.mybatis%E6%BA%90%E7%A0%81%E4%B8%AD%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"[ Mybatis ] 1.Mybatis源码中设计模式"},{"content":"Spring源码中设计模式   工程模式：Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象\n  单例模式：Spring依赖注入Bean实例默认是单例的。Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。\n  装饰器模式：Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。\n  代理模式：AOP底层，就是动态代理模式的实现\n  观察者模式：spring的事件驱动模型使用的是 观察者模式 ，Spring中Observer模式常用的地方是listener的实现。如：ApplicationContextEvent、ApplicationListener\n  策略模式：Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。\n UrlResource：访问网络资源的实现类。 ClassPathResource：访问类加载路径里资源的实现类。 FileSystemResource：访问文件系统里资源的实现类。 ServletContextResource：访问相对于 ServletContext 路径里的资源的实现类. InputStreamResource：访问输入流资源的实现类。 ByteArrayResource：访问字节数组资源的实现类。    ","date":"2020-12-31T11:13:47+08:00","permalink":"https://example.com/p/spring-1.spring%E6%BA%90%E7%A0%81%E4%B8%AD%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"[ Spring ] 1.Spring源码中设计模式"},{"content":"关于锁 1.自旋锁（SpinLock）  当一个线程在获取锁的时候，如果锁已经被其他线程获取，那么该线程将循环等待，然后不断的判断锁是否已经被其他线程释放，可以成功获取到锁，直到可以获取到锁才退出循环。\n 无论 自旋锁 ，还是 互斥锁 ， 在任何时刻，都最多只有一个执行单元获得锁。\n2.可重复锁/不可重复锁  可重复锁： 广义上定义为，可重复可递归调用的锁，在外层使用之后，在内层依旧可以使用，并且不会发生死锁(前提保证是同一个Obj或Class)。例如：ReentrantLock 和 synchronized 是可重复锁。\n Coding Demo One：\nsynchronized void setA() throw Exception{ Thread.sleep(1000); // 如果不是可重入锁，setB()将可能不会被当前线程执行，造成死锁。  setB(); } synchronized void setB() throw Exception{ Thread.sleep(1000); }  不可重复锁： 与 可重入锁刚好相反，不可重复进行递归调用，递归调用将造成死锁。\n Coding Demo One：\n// 通过 自旋锁 实现一个不可重入锁  public class UnreentrantLock{ private AtomicReference\u0026lt;Thread\u0026gt; owner = new AtomicReference\u0026lt;\u0026gt;(); public void lock(){ Thread curr = Thread.currentThread(); // 按照 自旋锁 原理进行实现  for(;;){ if(!owner.compareAndSet(null,curr)){ return; } } } public void unlock(){ Thread curr = Thread.currentThread(); owner.compareAndSet(curr,null); } } Coding Demo Two：\n// ReentrantLock中可重入锁实现； // 非公平锁的获取方式。 final boolean nonfairTryAcquire(int acquires){ final Thread curr = Thread.currentThread(); int c = getState(); if (c == 0){ if (compareAndSetState(0,acquires)){ setExclusiveOwnerThread(curr); return true; } }else if(curr == getExclusiveOwnerThread()){ int next = c + acquires; if(next \u0026lt; 0){ throw new Error(\u0026#34;Maximum lock count exceeded.\u0026#34;); } setState(next); return true; } return false; } 3.公平锁 4.共享锁 5.分段锁  ","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/java-4-1.%E5%85%B3%E4%BA%8E%E9%94%81/","title":"[ Java ] 4-1.关于锁"},{"content":"多线程问题 1. 如何保证多线程同时启动，主线程进行耗时统计。 CountDownLatch\n","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/java-4.0-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%97%AE%E9%A2%98/","title":"[ Java ] 4.0 多线程问题"},{"content":"关于JVM命令 一、命令列表  jps jmap jhat jstat jstack jcmd jinfo  二、命令使用 1. jps - JVM进程状态   用法\n$ jps -help usage: jps [-help] jps [-q] [-mlvV] [\u0026lt;hostid\u0026gt;] Definitions: \u0026lt;hostid\u0026gt;: \u0026lt;hostname\u0026gt;[:\u0026lt;port\u0026gt;] # 若不指定\u0026lt;hostid\u0026gt;,则表示当前默认主机或服务器 # -q 仅输出当前进程号 # -m 输出JVM启动时传递给main()的参数 # -l 输出主类名称；如果进程是jar，将输出jar路径 # -v 输出传递给JVM的参数 # -V 仅输出本地JVM标识符   实例讲解\n$ jps -ml 33270 org.jetbrains.idea.maven.server.RemoteMavenServer36 $ jps -v 33270 RemoteMavenServer36 -Djava.awt.headless=true -Dmaven.defaultProjectBuilder.disableGlobalModelCache=true -Didea.maven.embedder.version=3.6.3 -Xmx768m -Dmaven.ext.class.path=/Applications/IntelliJ IDEA.app/Contents/plugins/maven/lib/maven-event-listener.jar -Dfile.encoding=UTF-8   2. jmap - JVM堆内存分析工具  1.用于监控生成堆转储快照(heapdump或dump)；\n  2.用于查询finalize执行队列、Java堆和永久代的详细信息：当前使用率、当前使用什么类型垃圾回收器；\n  3.也可在启动时增加JVM参数 -XX:+HeapDumpOnOutOfMemoryError，在发生OOM时自动生成dump文件。\n   用法\n$ jmap -h Usage: jmap [option] \u0026lt;pid\u0026gt; (to connect to running process) jmap [option] \u0026lt;executable \u0026lt;core\u0026gt; (to connect to a core file) jmap [option] [server_id@]\u0026lt;remote server IP or hostname\u0026gt; (to connect to remote debug server) where \u0026lt;option\u0026gt; is one of: \u0026lt;none\u0026gt; to print same info as Solaris pmap -heap to print java heap summary -histo[:live] to print histogram of java object heap; if the \u0026#34;live\u0026#34; suboption is specified, only count live objects -clstats to print class loader statistics -finalizerinfo to print information on objects awaiting finalization -dump:\u0026lt;dump-options\u0026gt; to dump java heap in hprof binary format dump-options: live dump only live objects; if not specified, all objects in the heap are dumped. format=b binary format file=\u0026lt;file\u0026gt; dump heap to \u0026lt;file\u0026gt; Example: jmap -dump:live,format=b,file=heap.bin \u0026lt;pid\u0026gt; -F force. Use with -dump:\u0026lt;dump-options\u0026gt; \u0026lt;pid\u0026gt; or -histo to force a heap dump or histogram when \u0026lt;pid\u0026gt; does not respond. The \u0026#34;live\u0026#34; suboption is not supported in this mode. -h | -help to print this help message -J\u0026lt;flag\u0026gt; to pass \u0026lt;flag\u0026gt; directly to the runtime system  jmap [option] \u0026lt;pid\u0026gt;  none \u0026ndash; 打印共享参数对象，含有共享对象起始地址、映射大小以及共享对象文件的路径全称。 heap \u0026ndash; 展示\u0026lt;pid\u0026gt;整体堆信息，含有概要信息、GC所使用的的算法、Heap配置、wise heap使用情况。 histo \u0026ndash; 打印每个class的实例数目、内存占用、类全名信息(VM内部类都会以*作为前缀)。 histo:live \u0026ndash; 仅打印存活的对象数量 clstats \u0026ndash; 全称叫做class loader statistics，用输出类加载有关的统计信息 finalizerinfo \u0026ndash; 列出准备finalizerinfo对象信息 dump:[dump-options]  live \u0026ndash; 存活对象 file=\u0026lt;filename\u0026gt; \u0026ndash; dump到指定\u0026lt;filename\u0026gt;文件中 format=b \u0026ndash; 以二进制形式   F \u0026ndash; 强制 J\u0026lt;flag\u0026gt;      实例讲解\n jmap heap \u0026lt;pid\u0026gt;      3. jhat - 用于分析jmap所生成的dump文件 # 1.用法 ------ # 2.实例 4. jstat - JVM统计监控工具 # 1.用法 ------ # 2.实例 5. jstack - JVM栈查看工具 # 1.用法 ------ # 2.实例 6. jcmd - JVM命令行调试工具 # 1.用法 ------ # 2.实例 7. jinfo - JVM信息查看工具 # 1.用法 ------ # 2.实例 ","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/jvm-1.%E5%85%B3%E4%BA%8Ejvm%E5%91%BD%E4%BB%A4/","title":"[ JVM ] 1.关于JVM命令"},{"content":"JVM垃圾回收 1. 垃圾回收机制 在Java中，编写代码时不需要通过显式方式去释放一个对象的内存，而是通过JVM自行进行垃圾回收。JVM中，存在一个垃圾回收线程，它属于一个 低优先级线程 ，正常情况下是不会执行的，只有在 JVM空闲 或者 当前堆内存不足 时，才会触发执行，扫描那些 没有被任何引用的对象 ，并将它们添加到回收集合中，进行内存释放。\n2. 引用类型   强引用\n发生GC时，对象不会被回收。\n  软引用\n有用但不是必须的对象，在发生内存溢出之前会被回收\n  弱引用\n有用但不是必须的对象，在下一次GC时会被回收\n  虚引用\n无法通过虚引用获取到对象(通过 PhantomReference 实现虚引用)，作用是在GC时返回一个通知。\n  3. 如何判断对象是否可以被回收？ 垃圾收集器在做垃圾回收的时候，首先需要判定的就是 哪些对象内存需要被释放 ， 哪些对象依旧存活，不可释放 。\n一般通过两种方式进行判断：\n  引用计数器法：\n为每一个对象创建一个引用计数，有对象引用时计数器进行 ++ ，应用被释放时计数 \u0026ndash; ，当 计数器==0 时可以被回收。(不足： 无法解决循环引用问题)\n  可达性分析算法：\n从 GC Roots 开始向下搜索，搜索所走过的路径成为引用链。当一个对象到 GC Roots没有任何引用链是，则可以进行回收。\n  1：系统类加载器加载的对象\n  2：处于激活状态的线程\n  3：JNI栈中的对象\n  4：正在被用于同步的各种锁对象\n  5：JVM自身持有的对象，比如系统类加载器等。\n    4. 在Java中，对象什么时候可以被进行垃圾回收？  当对象对当前使用这个对象的应用程序 变得不可触及 的时候，这个对象就可以进行垃圾回收。 垃圾回收不会发生在永久代，如果 永久代满了 或者 超出了临界值，会触发完全垃圾回收(FGC)。 查看垃圾收集器的输出信息，可以发现永久代也是会被回收的，这就是为什么正确的永久代大小对避免FGC是非常重要的原因。  5. JVM中永久代会发生GC吗？ 垃圾回收不会发生在永久代。如果 永久代满了 或者 超出了临界值，会触发完全垃圾回收(FGC)。\nJDK8 中移除了永久代，新增加了元数据区的Native内存区\n6. 垃圾回收算法  标记-清除算法： 标记无用对象，然后进行清除回收。(缺点：效率低，无法清除垃圾碎片) 复制算法： 按照容量划分两个大小相等的内存区域，当一块用完之后将活着的对象移动至另外一块，然后再把已使用的内存空间一次性释放掉。(缺点：内存使用率低，只有原来的一半) 标记-整理算法： 标记无用对象，让所有存活的对象都向一端移动，然后直接清除掉边界以外的内存。 分代算法： 根据对象存活周期的不同将内存划分为几块(一般情况是新生代、老生代)，新生代采用复制，老年代采用标记-整理算法。  7. 垃圾回收器 用于新生代的收集器：Serial、PraNew、 ParallelScavenge 用于老年代的收集器：Serial Old、Parallel Old、CMS 用于回收整个堆的：G1\n Serial(复制算法)： 新生代单线程收集器，标记-清理都是单线程，简单高效 ParNew(复制算法)： 新生代并行收集器，实际上Serial收集器的多线程版本。在多核CPU下比Serial具有更好表现 ParallelScavenge(复制算法)： 新生代并行收集器，追求高吞吐量，高效利用CPU。 Serial Old(标记-整理)： 老年代单线程收集器 Parallel Old(标记-整理)： 老年代并行收集器，吞吐量优先，ParallelScavenge的老年代版本。 CMS(Concurrent Mask Sweep，标记-清除)： 老年代并行收集器，以获取最短回收停顿时间为目，具有高并发、低停顿的特点。追求最短GC回收停顿时间。 G1(Garbage First，标记-整理)： Java堆并行收集器，始于JDK1.7，G1是基于标记-整理算法实现，不会产生垃圾碎片。此外，重要的特点：G1回收的范围是整个Java堆，而前几种回收范围仅限于 新生代 或 老年代。  8. 关于CMS垃圾回收器 CMS垃圾回收器(Concurrent Mask Sweep) ，是以牺牲吞吐量为代价来获取最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用，此垃圾回收器很适合。 使用CMS回收器方法：\n# 在JVM启动参数增加此参数项： -XX:+UseConcMaskSweepGC 9. 新生代垃圾回收器与老年代垃圾回收器有哪些？区别是什么？  新生代垃圾回收器一般采用：复制算法。优点：效率高；缺点：使用率低。 老生代垃圾回收器一般采用：标记-整理。  10. 简述分代垃圾回收器是如何工作的。 ","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/jvm-2.jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","title":"[ JVM ] 2.JVM垃圾回收"},{"content":"JVM内存 1. JVM 内存结构  栈（JVM Stacks）  存放基本数据类型、对象的引用、方法出口等，线程私有 栈容量超过 Java 虚拟机栈的最大容量，会抛出 StackOverflowError 异常   堆  所有线程共享的，它在虚拟机启动时就会被创建 内存空间占据的最大一块区域 用来存放对象实例及数组，通过 new 关键字 new 出来的对象都存放在这里 垃圾回收器的主要回收对象 老年代 + 新生代 = 老年代 + Eden + S0 + S1   方法区 （Metaspace元空间）  都是各个线程共享的 类信息、常量、静态变量、即时编译器编译后的代码   本地方法区  只不过它服务于Native方法，线程私有 HotSpot虚拟机直接就把本地方法栈和虚拟机栈合二为一   程序计数器  当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址，线程私有 程序计数器是唯一一个在Java虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。    2. 简述Java堆内存分配策略  大对象：需要大量连续内存空间的Java对象，比如很长的字符串和大型数组， 对象优先在Eden分配，如果Eden内存空间不足，就会发生Minor GC 长期存活的对象将进入老年代，默认15岁，-XX:MaxTenuringThreshold 动态对象年龄判定 空间分配担保  3. Minor GC 与 Major GC   Minor GC： 又称 新生代GC\nJava对象大多数是朝生夕灭，所以 Minor GC 非常频繁，一般回收速度也比较快\n  Major GC： 又称 老年代GC\n指发生在 老年代 的GC。出现 FGC 经常会伴有 至少一次的 Minor GC(不是绝对，Parallel Scavenge收集器可以选择Major GC策略)。Major GC 一般比 Minor GC 慢上 10倍以上\n  4. Java中 堆 和 栈 的区别 JVM中 堆 和 栈 是不同的内存区域，使用目的也不同。\n 栈  用于 保存方法帧 和 局部变量 不会在多个线程之间进行共享，即 线程私有 栈不足，产生异常错误是、：java.lang.StackOverFlowError   堆：  Java 对象 始终在堆上分配 堆将会被整个JVM的所有线程进行共享，即 所有线程共有 堆不足，产生异常错误：java.lang.OutofMemoryError 空间上，堆 远远大于 栈    （1）：堆\u0026lt;对象，静态变量，共享\n（2）：方法区\u0026lt;存放类信息，常量池，共享\u0026gt;（java8移除了永久代（PermGen），替换为元空间（Metaspace））\n（3）：虚拟机栈\u0026lt;线程执行方法的时候内部存局部变量会存堆中对象的地址等等数据\u0026gt;\n（4）：本地方法栈\u0026lt;存放各种native方法的局部变量表之类的信息\u0026gt;\n（5）：程序计数器\u0026lt;记录当前线程执行到哪一条字节码指令位置\u0026gt;\n","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/jvm-3.jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","title":"[ JVM ] 3.JVM内存模型"},{"content":"JVM类加载机制 1. Java类加载机制 JVM中类的装载是由\n2. 描述JVM加载Class文件的原理机制 3. 什么是类加载器？类加载器又有哪些？   启动类加载器(Bootstrap ClassLoader)：\n负责加载${JAVA_HOME}/lib目录下或通过-Xbootclasspath参数指定路径中被JVM认可的类\n  扩展类加载器(Extension ClassLoader)：\n负责加载${JAVA_HOME}/lib/ext目录中或通过java.ext.dirs系统变量指定路径中的类库\n  应用程序类加载器(Application ClassLoader)：\n负责加载用户路径classpath下的类库。JVM通过 双亲委派模型 进行类的加载，也可通过 继承 java.lang.ClassLoader 实现自定义的类加载器。\n  4. 类装载的执行过程。   加载 获取类的二进制字节流，将其静态存储结构转化为方法区的运行时数据结构\n  校验 文件格式验证，元数据验证，字节码验证，符号引用验证\n  准备 在方法区中对类的static变量分配内存并设置类变量数据类型默认的初始值，不包括实例变量，实例变量将会在对象实例化的时候随着对象一起分配在Java堆中\n  解析 将常量池内的符号引用替换为直接引用的过程\n  初始化 为类的静态变量赋予正确的初始值（Java代码中被显式地赋予的值）\n  5. 什么是双亲委派模型？  当一个类收到 类加载请求 ，首先不去尝试自己加载此类，而是把此请求 委派 父类去完成； 每一个层次类加载器都是如此，因此所有的加载请求都应该传送到 启动类加载器 中； 只有当 父类加载器 反馈无法完成此请求是，子类加载器 才会尝试自己加载。   采用双亲委派的一个好处： 加载位于rt.jar包中的类 java.lang.Object，不管是哪个类加载器加载的这个类，最终都将委托给顶层的 启动类加载器 进行加载，即可以保证使用不同的类加载器，也能保证加载的都是同一个Object对象。\n 6. Tomcat打破双亲委派 tomcat有着特殊性，它需要容纳多个应用，需要做到应用级别的隔离，而且需要减少重复性加载，所以划分为：\n /common 容器和应用共享的类信息， /server容器本身的类信息， /share应用通用的类信息, /WEB-INF/lib应用级别的类信息。  整体可以分为：\nboostrapClassLoader-\u0026gt;\nExtensionClassLoader-\u0026gt;\nApplicationClassLoader-\u0026gt;\nCommonClassLoader-\u0026gt;\nCatalinaClassLoader（容器本身的加载器）/ShareClassLoader（共享的）-\u0026gt;\nWebAppClassLoader。\n虽然第一眼是满足双亲委派模型的，但是不是的，因为双亲委派模型是要先提交给父类装载，而tomcat是优先判断是否是自己负责的文件位置，进行加载的。\n","date":"2020-12-27T21:10:47+08:00","permalink":"https://example.com/p/jvm-4.jvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","title":"[ JVM ] 4.JVM类加载机制"},{"content":"Dubbo中的SPI 1. Dubbo SPI与Java SPI  SPI(Service Provider Interface)，主要用于框架，框架定义接口。   不同使用者将存在不同需求，也必然出现不同实现方式。\n  而SP\u0008I就是通过定义一个特定的位置，Java SPI约定在Classpath下的META-INF/services/路径下创建一个以服务接口命名的文件，然后文件中记录的是此jar包提供的具体实现类的全限定名，并由服务加载器读取配置文件，加载实现类，这样可以在运行时动态为接口替换实现类。\n  Dubbo SPI\n 并非是Java原生的SPI，而是重新实现的SPI。   Java SPI通过ServiceLoader进行加载； Dubbo SPI通过ExtensionLoader进行拓展加载。  支持的注解：  @SPI(标记为拓展接口) @Adaptive(自适应拓展实现类标志) @Activate(自动激活条件标记)   配置文件放在classpath下的META-INF/dubbo/以及 META-INF/dubbo/internal下 Dubbo SPI增加了对拓展点IOC和AOP的支持，一个拓展点可以直接通过Setter注入其他拓展点。 Java SPI会一次性实例化拓展点所有实现，如果有拓展实现初始化过程很耗时，并且用不上，将会造成资源浪费。    Dubbo中SPI的具体实现\n 协议扩展(Protocol)：RPC协议扩展，用于封装远程调用细节 调用拦截扩展(Filter)：服务提供方和服务消费方调用过程拦截，Dubbo本身大多数功能都是基于此扩展点实现，每次远程方法执行，该拦截都会被执行 引用监听扩展(InvokerListener)：当有服务被引用时触发此事件 暴露监听扩展(ExporterListener)：当有服务被暴露时触发此事件 集群扩展(Cluster)：当存在多个服务提供方时，将多个服务提供方组成一个集群，并伪装成一个服务提供方 路由扩展(RouterFactory)：从多个服务提供方中选择一个进行调用 负载均衡(LoadBalance)：从多个服务提供方中选择一个进行调用 合并扩展(Merger)：合并返回结果，用于分组聚合 注册中心扩展(Registry)：负责服务的注册与发现 监控扩展(Monitor) ：负责服务调用次数以及调用时间的监控 扩展点加载扩展(ExtensionFactory)：扩展本身的加载容器，可从不同容器加载扩展点 动态代理扩展(ProxyFactory)：将Invoker接口转换成业务接口 编译器扩展(Compiler)： Java代码编译器，用于动态生成字节码，加速调用 配置中心扩展(DynamicConfiguration)：作为Key-Value存储 消息派发扩展(Dispatcher)：通道信息派发器，用于指定线程池模型 线程池扩展(ThreadPool)：服务提供方线程池的实现策略 序列化扩展(Serialization)：将对象转化成字节流，用于网络传输，以及将字节流转为对象，用于接收到字节流数据时还原成对象 网络传输扩展(Transporter)：远程通信的服务器以及客户端传输实现 信息交换扩展(Exchange)：`` 组网扩展(Networker)：对等网络节点组网器 Telnet命令扩展(TelnetHandler)：所有服务器均支持telnet访问，用于人工干预 状态检查扩展(StatusChecker)：检查服务依赖各种资源的状态，此状态检查可同时用于telnet的status命令和hosting的status页面 容器扩展(Container)：服务容器扩展，用于自定义加载内容 缓存扩展(CacheFactory)：用于请求参数作为Key，缓存返回结果 验证扩展(Validation)：参数验证扩展点 日志适配扩展(LoggerAdapter)：日志输出适配扩展点      2. 详细了解Dubbo SPI a. SPI注解  使用@SPI仅能配置一种实现类，但是可以根据@SPI(\u0026quot;dubbo\u0026quot;)指定不同的实现类，再调用ExtensionLoader获取实现类的时候，会加载配置文件中key所对应的实现类。 多个模块编译后会将META-INF/dubbo/或META-INFO/dubbo/internal/下的统一拓展点的配置文件中的配置合并在一起。  b. Activate注解  被@Activate注解注释的扩展点默认被激活启用，还可以通过注解的value属性指定此扩展点在什么情况下被自动激活 被@Activate注解注释的扩展点，在获取实现类是不能再使用ExtensionLoader.getExtension(String name)，而应该使用ExtensionLoader.getActivateExtension(URL url, String[] values) 目的也是为了支持一个扩展点存在多个实现类需要同时启用的场景。 主要是用扩展点(接口)的实现类上，所以此扩展点被@Activate注解的实现类都会在指定条件下自动激活  c. Adaptive注解  @Adaptive注解是Dubbo自适应拓展机制，最重要的三个字应该就是自适应 目的： 拓展点在方法被调用的时候，根据运行时参数进行加载 实现： Dubbo使用javassist为拓展接口生成具有代理功能的代码，然后通过JDK编译这段代码得到Class类，最后在通过反射创建代理类。 应用：  在RPC远程调用过程中，会在url上携带参数，比如调用的目标是XxxService的yy()，而服务提供者XxxService具有多个实现类，那么可以在url上指定使用哪个实现类(配置文件中该实现类的key)，然后在通过SPI获取到此实现类的实例。 javassist生成的代码，就是拿到方法的url参数，从url中动态获取配置的参数，然后通过SPI加载具体的实现类，最后调用实现类的方法 所以，先判断方法url参数是否为Null，如果为Null则抛出异常，否则从url中获取参数，如果没有获取到也抛出异常，如果获取到就通过SPI获取实例。    ","date":"2020-12-25T15:36:27+08:00","permalink":"https://example.com/p/dubbo-2.-dubbo%E4%B8%AD%E7%9A%84spi/","title":"[ Dubbo ] 2. Dubbo中的SPI"},{"content":"Dubbo SPI中的Protocol扩展点 ","date":"2020-12-25T15:36:27+08:00","permalink":"https://example.com/p/dubbo-3-1.-dubbo-spi%E4%B8%AD%E7%9A%84protocol%E6%89%A9%E5%B1%95%E7%82%B9/","title":"[ Dubbo ] 3-1. Dubbo SPI中的Protocol扩展点"},{"content":"Dubbo SPI中的Filter扩展点 ","date":"2020-12-25T15:36:27+08:00","permalink":"https://example.com/p/dubbo-3-2.-dubbo-spi%E4%B8%AD%E7%9A%84filter%E6%89%A9%E5%B1%95%E7%82%B9/","title":"[ Dubbo ] 3-2. Dubbo SPI中的Filter扩展点"},{"content":"Dubbo通信原理 1. Dubbo多线程通信原理  获取DubboInvoker对象； 将请求体信息封装在一个Request对象中，Request中会包括一个自增的id； 然后将Request存到一个ConcurrentHashMap中（key=id，value= DefaultFuture）,将request数据写入Channel Consumer Thread执行Defaultfuture#get()方法等待返回结果 服务提供方创建多线程处理用户请求，并将放回结果封装在Response中（包括Request#id）将response写入Channel 消费方从Channel中收到数据以后，解析出id，从Map中解析出DefaultFuture唤醒Consumer Thread，返回结果 DefaultFuture也会启动一个定时程序，检查在timeout内，结果是否返回，如果未返回，将DefaultFuture从map中移除，并抛出超时异常  ","date":"2020-12-25T15:36:27+08:00","permalink":"https://example.com/p/dubbo-3.-dubbo%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/","title":"[ Dubbo ] 3. Dubbo通信原理"},{"content":"Dubbo基础概念 1.Dubbo核心组件  Provider： 暴露服务的服务提供方 Consumer： 调用远程服务的消费方 Register： 服务注册与发现注册中心 Monitor： 监控中心和访问调用统计 Container：服务运行时容器   Dubbo分层主要为业务层、RPC层和Remote层，如果把每层进行详细划分的话，整体划分为：\n  业务层：  service: 包含各业务代码的接口与实现；   RPC层：  config: 配置层，主要围绕ServiceConfig(暴露的服务配置)和ReferenceConfig(引用的服务配置)两个类展开，初始化配置信息； proxy: 服务代理层，不论生产者还是消费者，Dubbo都会生成一个代理类，在调用远程接口时，就可以像本地接口一样，代理层自动做远程调用并返回结果； registry: 注册层，负责Dubbo框架的服务注册与发现； cluster: 集群容错层，主要负责远程调用失败时的集群容错策略(如快速失败、快速重试等)； monitor: 监控层，负责监控统计调用次数和调用时间等； protocol: 远程调用层，封装RPC调用具体过程，是Invoker暴露和引用的主要功能入口，负责管理Invoker的整个生命周期；   Remote层：  exchange: 信息交换层，封装请求相应模式，如同步请求转换为异步请求； transport: 网络传输层，把网络传输抽象为统一接口； serialize: 序列化层，将需要网络传输的数据极性序列化，转为二进制流。    2.Dubbo服务注册与发现流程  Container负责启动，加载，运行服务提供者 Provider启动时，向注册中心注册自己并提供服务 Consumer启动时，向注册中心订阅自已需调用服务 Register返回服务提供者地址列表给服务消费者，如运行期间，服务提供者发生变动，将通过长连接推送至服务消费者 Consumer通过负载均衡算法(软方式)，选取注册中心所返回的服务提供者列表中的一个节点进行调用，如果调用失败将尝试其他节点进行调用 Consumer、Provider将调用次数、时间记录于内存中，并定时每分钟发送至Monitor监控中心  3-1. Dubbo服务暴露过程  Dubbo 会在 Spring 实例化完 bean 之后， 在刷新容器最后一步发布 ContextRefreshEvent 事件的时候，通知实现了 ApplicationListener 的 ServiceBean 类进行回调 onApplicationEvent 事件方法。 Dubbo 会在这个方法中调用 ServiceBean 父类 ServiceConfig 的 export 方法，而该方法真正实现了服务的发布。  3-2. Dubbo服务引用过程  服务暴露之后，客户端就要引用服务，然后才是调用的过程。 首先客户端根据配置文件信息从注册中心订阅服务 之后DubboProtocol根据订阅的得到provider地址和接口信息连接到服务端server，开启客户端client，然后创建invoker invoker创建完成之后，通过invoker为服务接口生成代理对象，这个代理对象用于远程调用provider，服务的引用就完成了  4. Dubbo的管理控制台能做什么  路由规则 动态配置 服务降级 访问控制 权重调整 负载均衡等管理功能  5. Dubbo集群容错方案  Failover Cluster(默认方案)  失败后自动切换，出现失败将会重试其他服务节点(retries重试次数) 通常用于读操作，但重试会带来很重的延迟   Failfast Cluster  快速失败 只发起一次调用，失败后立即抛出异常 用于写操作   Failsafe Cluster  失败安全机制 出现异常时，将进行忽略 通常用于写入审计日志   Failback Cluster  失败自动恢复 后台记录下失败请求，通过定时回调进行重试 常用于消息通知   Forking Cluster  并行调用 只要存在一个成功就返回 通常用于实时性较高的读操作，但浪费资源 可通过设定forks的值为2，限制最大并行数   Broadcast Cluster  广播调用 任意一台报错则报错，通常用于通知所有提供者更新缓存或者日志等资源。    6. Dubbo支持什么协议  dubbo：单一长连接、NIO异步通讯，适用于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况 hessian：短连接，http，适合页面传输、文件传输。与原生hessian服务互操作 http：适用于同时给应用程序和浏览器使用时 webservice：适用于系统集成，跨语言使用 rmi：适用于常规的远程服务方法调用，与原生RMI服务互操作  7. Dubbo如何做负载均衡 \u0026lt;dubbo:service interface=\u0026#34;...\u0026#34;loadbalance=\u0026#34;random\u0026#34;/\u0026gt; \u0026lt;dubbo:reference interface=\u0026#34;...\u0026#34;loadbalance=\u0026#34; random \u0026#34;/\u0026gt;  RandomLoadBalance: 随机负载均衡(默认方式) RoundRobinLoadBalance: 轮询负载均衡 LeastActiveLoadBalance: 最少活跃调用数(相同活跃数的随机)  活跃数指调用前后计数差 使响应慢的Provider收到更少的请求，因为越慢的provider的调用前后计数差越大   ConsistentHashLoadBalance: 一致性Hash负载均衡，相同参数的请求总是落在同一台机器上  8. Dubbo如何实现异步调用  API注入时添加异步调用标识  @Reference(interfaceClass=xxx.class,async-true)   启动类开启异步调用  @EnableAsync   异步调用接口添加异步调用代码  RpcContext.getContext.future()    9. 在Provider上可以配置Consumer端的属性有哪些  timeout：调用超时 retries：重试次数(默认是2次) LoadBalance：负载均衡算法 actives：消费者端最大并发调用限制  \u0026lt;dubbo:service interface=\u0026#34;com.alibaba.hello.api.HelloService\u0026#34; version=\u0026#34;1.0.0\u0026#34; ref=\u0026#34;helloService\u0026#34; timeout=\u0026#34;300\u0026#34; retry=\u0026#34;2\u0026#34; loadbalance=\u0026#34;random\u0026#34; actives=\u0026#34;0\u0026#34; /\u0026gt; \u0026lt;dubbo:service interface=\u0026#34;com.alibaba.hello.api.WorldService\u0026#34; version=\u0026#34;1.0.0\u0026#34; ref=\u0026#34;helloService\u0026#34; timeout=\u0026#34;300\u0026#34; retry=\u0026#34;2\u0026#34; loadbalance=\u0026#34;random\u0026#34; actives=\u0026#34;0\u0026#34; \u0026gt; \u0026lt;dubbo:method name=\u0026#34;findAllPerson\u0026#34; timeout=\u0026#34;10000\u0026#34; retries=\u0026#34;9\u0026#34; loadbalance=\u0026#34;leastactive\u0026#34; actives=\u0026#34;5\u0026#34; /\u0026gt; \u0026lt;dubbo:service/\u0026gt; 10. Zookeeper和Dubbo的关系  Dubbo将注册中心进行抽象，使得它可以外接不同的存储媒介给注册中心提供服务 使用Zookeeper作为存储媒介   负载均衡：\n 单注册中心的承载能力是有限的，在流量达到一定程度的时候就需要分流，负载均衡就是为了分流而存在的，一个 ZooKeeper 群配合相应的 Web 应用就可以很容易达到负载均衡    资源同步：\n 节点之间的数据和资源需要同步，ZooKeeper集群就天然具备有这样的功能    命名服务：\n 通过树状结构用于维护全局的服务地址列表 服务提供者在启动的时候，向 ZooKeeper上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这样就可以完成服务发布    Master选举：\n  分布式锁：\n 独占锁  即一次只能有一个线程使用资源   共享锁  读锁共享，读写互斥，即可以有多线线程同时读同一个资源，如果要使用写锁也只能有一个线程使用        11. Dubbo分层   分为三层：\n business层：(业务逻辑层)自己提供接口进行实现、以及一些配置 RPC层：(RPC调用核心层)封装了调用过程、负载均衡、集群容错、代理功能 remoting层：对网络传输协议和数据转换的封装    分为十层：\n service：业务逻辑层 config：配置层，初始化配置信息 proxy：代理层，为Provider和Consumer提供代理 register：服务注册层，封装服务注册与发现 cluster：路由层，封装provider路由与负载均衡 monitor：监控统计层，提供rpc调用时间、次数监控与统计 protocol：远程调用层，封装rpc调用 exchange：信息交换层，封装请求响应模式，同步转异步 transport：网络传输层，对Netty的封装 serialize：序列化层，对数据进行序列化、反序列化    x. Dubbo项目结构 $ tree -L 1 . ├── dubbo-all ├── dubbo-bom ├── dubbo-build-tools ├── dubbo-cluster # 集群容错模块，涵盖负载均衡策略、集群容错策略及路由 ├── dubbo-common # 通用逻辑模块，提供工具类和通用类型 ├── dubbo-compatible # 兼容性模块 ├── dubbo-config # 配置模块，主要实现API配置、属性配置、XML配置等 ├── dubbo-configcenter # 动态配置中心模块 ├── dubbo-container # 容器运行时，采用Main方法加载Spring容器 ├── dubbo-demo # 三种远程调用方式实例 ├── dubbo-dependencies #  ├── dubbo-dependencies-bom ├── dubbo-distribution ├── dubbo-filter # 过滤器 ├── dubbo-metadata # 元数据信息 ├── dubbo-monitor # 监控模块，主要监控接口调用次数及时间等信息 ├── dubbo-plugin # 插件拓展模块 ├── dubbo-registry # 服务发现与注册中心模块 ├── dubbo-remoting # 远程通信模块，为消费者、生产者间提供远程调用能力 ├── dubbo-rpc # 抽象各种通信协议以及动态代理(易混淆remoting) ├── dubbo-serialization ","date":"2020-12-22T15:36:27+08:00","permalink":"https://example.com/p/dubbo-1.dubbo%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","title":"[ Dubbo ] 1.Dubbo基础概念"},{"content":"深入Service  Service是Kubernetes最为核心的概念。Service可以为一组具有相同功能的容器应用提供一个统一的入口地址，并且将请求负载分发至后端的各个容器应用上。\n 1.Service参数定义 # 必填，版本号apiVersion:v1# 必填kind:Service# 必填，元数据metadata:# 必填，Service名称(符合RFC 1035规范)name:string# 必填，命名空间(默认default)namespace:string# 自定义标签属性列表labels:- name:string# 自定义注解属性列表annotations:- name:string# 必填，配置内容详细描述 spec:# 必填，LabelSelector配置，将选择具有特定Label标签的Pod对象作为管理对象selector:[]# 必填，可选值[ClusterIP | NodePort | LoadBalancer]## ClusterIP:虚拟服务IP地址，该地址用于Kubernetes集群内部Pod对象访问，#在Node节点上Kube-proxy通过设置的Iptables规则进行转发## NodePort:使用宿主机端口，使能够访问各Node的外部客户端通过Node的#IP地址和端口号即可访问到应用。## LoadBalancer:使用外接负载均衡器完成到服务的负载分发，需要#spec.status.loadBalaner字段指定外部负载均衡器的IP地址，并同时定义#nodePort和clusterIP，用于公有云环境。type:string# 虚拟服务IP地址：当type为ClusterIP时，如果不指定将自动进行分配；也可手动指定。#当type为LoadBalancer时，必须指定clusterIP:string# 是否支持Session，可选值为ClientIP，默认值为空。#ClientIP表示将同一个客户端(有客户端IP地址决定)的访问请求都转发到同一个后端#Pod对象sessionAffinity:string# Service需要暴露的端口列表ports:- name:string# 端口协议：TCP/UDP(默认TCP)protocol:string# 服务监听端口号port:int# 需要转发到后端Pod对象的端口号targetPort:int# type为NodePort时，指定映射到物理机的端口号nodePort:int# type为LoadBalancer时，设置外部负载均衡器的地址，用于公有云环境。status:# 外部负载均衡器loadBalancer:ingress:ip:stringhostname:string","date":"2020-09-18T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-3-1.%E6%B7%B1%E5%85%A5service/","title":"[ Kubernetes ] 3-1.深入Service"},{"content":"了解Pod对象 1.Pod参数定义 # 必填,版本号apiVersion:stringkind:Pod# 必填,元数据metadata:# 必填,Pod对象的名称(命名规范需要符合RFC 1035规范)name:string# 必填,Pod对象所属的命名空间,默认值为defaultnamespace:string# 自定义标签列表(取值类型:List)labels:- name:string# 自定义标签注解(取值类型:List)annotations:- name:string# 必填,Pod对象中容器的详细定义 spec:# 必填,Pod对象容器列表(取值类型:List)containers:# 必填,容器的名称(需要符合RFC 1035规范)- name:string# 必填,容器镜像名称image:string# 获取镜像的策略，默认值为:Always# Always: 每次都尝试重新下载镜像# Never: 仅使用本地镜像# IfNotPresent: 如果本地不存在，就下载镜像imagePullPolicy:[Always | Never | IfNotPresent]# 容器启动命令列表，若不指定则使用镜像打包时使用的启动命令command:[string]# 容器的启动命令参数列表args:[string]# 容器的工作目录workingDir:string# 挂载到容器内部的存储卷配置(取值类型:List)volumeMounts:# 引用Pod定义的共享存储卷的名称，需使用镜像volumes[]部分定义的共享卷名称- name:string# 存储卷在容器内Mount的绝对路径(应少于512个字符)mountPath:string# 是否只读模式,默认false(读写模式)readOnly:boolean# 容器需要暴露的端口号(取值类型:List) ports:# 端口的名称- name:string# 容器需要监听的端口号containerPort:int# 容器所在主机需要监听的端口号，默认与containerPort相同# (设置hostPort时，同一台宿主机将无法启动该容器的第二副本，由于端口占用问题)hostPort:int# 端口协议[TCP/UDP],默认为TCPprotocol:string# 容器运行前需要设置的环境变量列表env:# 环境变量的名称- name:string# 环境变量的值value:string# 资源限制和资源请求的设置resource:# 资源限制设置limits:# CPU限制(单位为：core)将用于docker run --cpu-shares参数cpu:string# 内存限制(单位为：MiB/GiB)将用于docker run --memory参数memory:string# 资源限制设置(请求)requests:# CPU请求(单位为：core)将用于容器启动的初始化可用数量cpu:string# 内存请求(单位为：MiB/GiB)将用于容器启动的初始化可用数量memory:string# 对Pod对象内各个容器进行安全检查的设置，当探测无响应几次后，将自动重启该容器# 包含[exec | httpGet | TcpSocket]三种方式，任选其一即可livenessProbe:exec:# 需要执行的脚本command:[string]httpGet:# 请求路径path:string# 请求端口port:numberhost:stringscheme:stringhttpHeader:- name:stringvalue:stringtcpSocket:port:number# 完成容器启动后首次进行探测的时间(单位为：s)initialDelaySeconds:0# 对容器健康检查探测等待超时时间(单位为：s)，默认值为1timeoutSeconds:0# 对容器健康检查的探测时间周期(单位为：s)，默认值为10periodSeconds:0successThreshold:0failureThreshold:0securityContext:privileged:boolean## Pod对象的重启策略，可选值[Always | Never | OnFailure]## Always: Pod对象一旦终止，则不关心容器是如何停止的，kubelet都将重器容器## Never: Pod对象终止后，kubelet将退出码返回给Master，不再重启该容器## OnFailure: 只有当Pod对象以非零退出码终止时，kubelet才会重启该容器# (容器正常结束的退出码为零)#restartPolicy:[Always | Never | OnFailure]# 表示将Pod对象调度到包含这些label的Node上(以key:value形式指定)nodeSelector:object# Pull镜像时使用的secret名称(以name:secretValue形式指定)imagePullSecrets:- name:string# 是否使用主机模式(默认值为:false)## 如果设置为true，表示容器使用宿主机网络，不再使用Docker网桥# 该Pod对象将无法在同一台宿主机上启动第二个副本hostNetwork:boolean# 在该Pod对象上定义的共享储存卷列表volumes:# 共享储存卷名称，一个Pod对象中每个储存卷定义一个名称(命名应按照RFC 1035规范)- name:string# Pod对象同生命周期的一个临时目录，值为{}空对象emptyDir:{}# 挂载Pod对象所在宿主机的目录hostPath:# 将用于容器中mount的目录path:string# 挂载集群中预定义的secret对象到容器内部secret:secretName:stringitems:- key:stringpath:string# 挂载集群预定义的configMap对象到容器内部configMap:name:stringitems:- key:stringpath:string2.Pod的基本用法 Pod对象可以由1个或者多个容器组合而成。当两个或者多个容器应用为紧耦合关系，应该组合成一个整体对外提供服务，即将这两个容器打包为一个Pod对象。\n2.1 静态Pod对象  静态Pod对象是由Kubelet进行管理的仅存在于特定Node上的Pod对象。他们不可以通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet也无法对他们进行健康检查。静态Pod对象总是由kubelet进行创建，并且总是运行在kubelet所在的Node上运行。\n 创建静态Pod对象的两种方式：\n  配置文件\na.设置kubelet的启动参数**[\u0026ndash;config]**: 指定kubelet需要监控的配置文件所在的目录，kubelet将会定期扫描该目录，并根据该目录下的*.yaml或者*.json进行创建. b.重启kubelet服务\n  HTTP方式\n设置kubelet启动参数**[\u0026ndash;manifest-url]**: kubelet将会定期请求此URL下载Pod对象的定义文件，并以*.yaml或*.json文件格式解析，创建Pod对象。\n  2.2 Pod对象容器共享卷  在同一个Pod对象中的多个容器能够共享Pod对象级别的存储卷。Volume可以被定义为各种类型，容器各自进行挂载操作，将一个Volume挂载为容器内容存储卷。\n 配置文件示例：\napiVersion:v1kind:Podmetadata:name:volume-podspec:containers:- name:tomcatimage:tomcatports:- containerPort:8080volumeMounts:- name:app-logsmountPath:/usr/local/tomcat/log- name:logreaderimage:busyboxcommand:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/catalina*.log\u0026#34;]volumeMounts:- name:app-logsmountPath:/logsvolumes:app-logs - name:app-logsemptyDir:{}2.3 Pod对象的配置管理  为了提高应用部署的复用能力以及灵活性，可以将应用所需要的配置文件与程序进行分离。将应用打包为容器镜像后，可以通过环境变量配置、挂载外部文件的方式在创建容器时进行配置注入，但唯一的缺点维护性与复杂性将会在大规模容器集群中所体现。但在Kubernetes中可以通过ConfigMap进行管理。\n 1）ConfigMap的概念\n 生成为容器内的环境变量 设置容器的启动命令参数 通过Volume的形式挂载到容器内部  ConfigMap以一个或者多个[Key:Value]的形式保存在Kubernetes系统中。可以通过*.yaml配置文件或者kubelet create [-f configmap.yaml]命令进行创建配置管理内容。\n2）创建ConfigMap资源对象\na) *.yaml实例\napiVersion:v1kind:ConfigMapmetadata:name:cm-appvarsdata:apploglevel:infoappdatadir:/var/data b) kubelet命令\n# 1.创建configmap.yaml配置文件 kubelet create -f cm-appvars.yaml \u0026gt; configmap \u0026#34;cm-appvars\u0026#34; created # 2.查看创建完成的配置文件 kubelet get configmap # NAME DATA AGE # cm-appvars 2 3s # 3.查看指定配置的详细内容 kubelet get configmap cm-appvars -o yaml ","date":"2020-09-17T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-2-1.%E4%BA%86%E8%A7%A3pod%E5%AF%B9%E8%B1%A1/","title":"[ Kubernetes ] 2-1.了解Pod对象"},{"content":"SpringBoot\u0026ndash;Pods项目初体验  在SpringBoot项目中通过fabric8打包插件构建docker镜像\n 通过Kubernetes的接口请求Pod对象，相信信息如下：\n{ \u0026#34;kind\u0026#34;: \u0026#34;Pod\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kubernetes-hello-world-779c4c748b-2rv27\u0026#34;, \u0026#34;generateName\u0026#34;: \u0026#34;kubernetes-hello-world-779c4c748b-\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/default/pods/kubernetes-hello-world-779c4c748b-2rv27\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;dea46f9f-cd4b-11e9-b38e-025000000001\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;34209\u0026#34;, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2019-09-02T06:35:35Z\u0026#34;, \u0026#34;labels\u0026#34;: { \u0026#34;app\u0026#34;: \u0026#34;kubernetes-hello-world\u0026#34;, \u0026#34;group\u0026#34;: \u0026#34;org.springframework.cloud\u0026#34;, \u0026#34;pod-template-hash\u0026#34;: \u0026#34;779c4c748b\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;fabric8\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.1.0.M2\u0026#34; }, \u0026#34;annotations\u0026#34;: { \u0026#34;fabric8.io/docs-url\u0026#34;: \u0026#34;scp://static.springframework.org/var/www/domains/springframework.org/static/htdocs/spring-cloud/docs/kubernetes-hello-world/1.1.0.M2/spring-cloud-kubernetes/spring-cloud-kubernetes-examples/kubernetes-hello-world\u0026#34;, \u0026#34;fabric8.io/iconUrl\u0026#34;: \u0026#34;img/icons/spring-boot.svg\u0026#34;, \u0026#34;fabric8.io/metrics-path\u0026#34;: \u0026#34;dashboard/file/kubernetes-pods.json/?var-project=kubernetes-hello-world\\u0026var-version=1.1.0.M2\u0026#34;, \u0026#34;fabric8.io/scm-con-url\u0026#34;: \u0026#34;scm:git:git://github.com/spring-cloud-incubator/spring-cloud-kubernetes.git/spring-cloud-kubernetes-examples/kubernetes-hello-world\u0026#34;, \u0026#34;fabric8.io/scm-devcon-url\u0026#34;: \u0026#34;scm:git:ssh://git@github.com/spring-cloud-incubator/spring-cloud-kubernetes.git/spring-cloud-kubernetes-examples/kubernetes-hello-world\u0026#34;, \u0026#34;fabric8.io/scm-tag\u0026#34;: \u0026#34;HEAD\u0026#34;, \u0026#34;fabric8.io/scm-url\u0026#34;: \u0026#34;https://github.com/spring-cloud-incubator/spring-cloud-kubernetes/spring-cloud-kubernetes-examples/kubernetes-hello-world\u0026#34; }, \u0026#34;ownerReferences\u0026#34;: [ { \u0026#34;apiVersion\u0026#34;: \u0026#34;apps/v1\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;ReplicaSet\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;kubernetes-hello-world-779c4c748b\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;dea3c6a5-cd4b-11e9-b38e-025000000001\u0026#34;, \u0026#34;controller\u0026#34;: true, \u0026#34;blockOwnerDeletion\u0026#34;: true } ] }, \u0026#34;spec\u0026#34;: { \u0026#34;volumes\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;default-token-b4crd\u0026#34;, \u0026#34;secret\u0026#34;: { \u0026#34;secretName\u0026#34;: \u0026#34;default-token-b4crd\u0026#34;, \u0026#34;defaultMode\u0026#34;: 420 } } ], \u0026#34;containers\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;spring-boot\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;cloud/kubernetes-hello-world:1.1.0.M2\u0026#34;, \u0026#34;ports\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;containerPort\u0026#34;: 8080, \u0026#34;protocol\u0026#34;: \u0026#34;TCP\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;prometheus\u0026#34;, \u0026#34;containerPort\u0026#34;: 9779, \u0026#34;protocol\u0026#34;: \u0026#34;TCP\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;jolokia\u0026#34;, \u0026#34;containerPort\u0026#34;: 8778, \u0026#34;protocol\u0026#34;: \u0026#34;TCP\u0026#34; } ], \u0026#34;env\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;KUBERNETES_NAMESPACE\u0026#34;, \u0026#34;valueFrom\u0026#34;: { \u0026#34;fieldRef\u0026#34;: { \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;fieldPath\u0026#34;: \u0026#34;metadata.namespace\u0026#34; } } } ], \u0026#34;resources\u0026#34;: { }, \u0026#34;volumeMounts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;default-token-b4crd\u0026#34;, \u0026#34;readOnly\u0026#34;: true, \u0026#34;mountPath\u0026#34;: \u0026#34;/var/run/secrets/kubernetes.io/serviceaccount\u0026#34; } ], \u0026#34;livenessProbe\u0026#34;: { \u0026#34;httpGet\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;port\u0026#34;: 8080, \u0026#34;scheme\u0026#34;: \u0026#34;HTTP\u0026#34; }, \u0026#34;initialDelaySeconds\u0026#34;: 180, \u0026#34;timeoutSeconds\u0026#34;: 1, \u0026#34;periodSeconds\u0026#34;: 10, \u0026#34;successThreshold\u0026#34;: 1, \u0026#34;failureThreshold\u0026#34;: 3 }, \u0026#34;readinessProbe\u0026#34;: { \u0026#34;httpGet\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/\u0026#34;, \u0026#34;port\u0026#34;: 8080, \u0026#34;scheme\u0026#34;: \u0026#34;HTTP\u0026#34; }, \u0026#34;initialDelaySeconds\u0026#34;: 10, \u0026#34;timeoutSeconds\u0026#34;: 1, \u0026#34;periodSeconds\u0026#34;: 10, \u0026#34;successThreshold\u0026#34;: 1, \u0026#34;failureThreshold\u0026#34;: 3 }, \u0026#34;terminationMessagePath\u0026#34;: \u0026#34;/dev/termination-log\u0026#34;, \u0026#34;terminationMessagePolicy\u0026#34;: \u0026#34;File\u0026#34;, \u0026#34;imagePullPolicy\u0026#34;: \u0026#34;IfNotPresent\u0026#34;, \u0026#34;securityContext\u0026#34;: { \u0026#34;privileged\u0026#34;: false, \u0026#34;procMount\u0026#34;: \u0026#34;Default\u0026#34; } } ], \u0026#34;restartPolicy\u0026#34;: \u0026#34;Always\u0026#34;, \u0026#34;terminationGracePeriodSeconds\u0026#34;: 30, \u0026#34;dnsPolicy\u0026#34;: \u0026#34;ClusterFirst\u0026#34;, \u0026#34;serviceAccountName\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;serviceAccount\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;nodeName\u0026#34;: \u0026#34;docker-desktop\u0026#34;, \u0026#34;securityContext\u0026#34;: { }, \u0026#34;schedulerName\u0026#34;: \u0026#34;default-scheduler\u0026#34;, \u0026#34;tolerations\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;node.kubernetes.io/not-ready\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;Exists\u0026#34;, \u0026#34;effect\u0026#34;: \u0026#34;NoExecute\u0026#34;, \u0026#34;tolerationSeconds\u0026#34;: 300 }, { \u0026#34;key\u0026#34;: \u0026#34;node.kubernetes.io/unreachable\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;Exists\u0026#34;, \u0026#34;effect\u0026#34;: \u0026#34;NoExecute\u0026#34;, \u0026#34;tolerationSeconds\u0026#34;: 300 } ], \u0026#34;priority\u0026#34;: 0, \u0026#34;enableServiceLinks\u0026#34;: true }, \u0026#34;status\u0026#34;: { \u0026#34;phase\u0026#34;: \u0026#34;Running\u0026#34;, \u0026#34;conditions\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;Initialized\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;lastProbeTime\u0026#34;: null, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2019-09-02T06:35:35Z\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;Ready\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;lastProbeTime\u0026#34;: null, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2020-01-17T01:47:07Z\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;ContainersReady\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;lastProbeTime\u0026#34;: null, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2020-01-17T01:47:07Z\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;PodScheduled\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;lastProbeTime\u0026#34;: null, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2019-09-02T06:35:35Z\u0026#34; } ], \u0026#34;hostIP\u0026#34;: \u0026#34;192.168.65.3\u0026#34;, \u0026#34;podIP\u0026#34;: \u0026#34;10.1.0.49\u0026#34;, \u0026#34;startTime\u0026#34;: \u0026#34;2019-09-02T06:35:35Z\u0026#34;, \u0026#34;containerStatuses\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;spring-boot\u0026#34;, \u0026#34;state\u0026#34;: { \u0026#34;running\u0026#34;: { \u0026#34;startedAt\u0026#34;: \u0026#34;2020-01-17T01:46:50Z\u0026#34; } }, \u0026#34;lastState\u0026#34;: { \u0026#34;terminated\u0026#34;: { \u0026#34;exitCode\u0026#34;: 255, \u0026#34;reason\u0026#34;: \u0026#34;Error\u0026#34;, \u0026#34;startedAt\u0026#34;: \u0026#34;2020-01-16T09:29:52Z\u0026#34;, \u0026#34;finishedAt\u0026#34;: \u0026#34;2020-01-17T01:46:30Z\u0026#34;, \u0026#34;containerID\u0026#34;: \u0026#34;docker://ec8892c9949c0f226636d68c0f0f9b675b60693011d510f3a218e579fe43f992\u0026#34; } }, \u0026#34;ready\u0026#34;: true, \u0026#34;restartCount\u0026#34;: 8, \u0026#34;image\u0026#34;: \u0026#34;cloud/kubernetes-hello-world:1.1.0.M2\u0026#34;, \u0026#34;imageID\u0026#34;: \u0026#34;docker://sha256:559a7fbc5858f9b3ca2bb9ada10235dbc169846e988a46a80c8ab123560ea168\u0026#34;, \u0026#34;containerID\u0026#34;: \u0026#34;docker://af0de58af170361c986110e79eeca49b85c0eef23ae688f52b23b5e95111fbe0\u0026#34; } ], \u0026#34;qosClass\u0026#34;: \u0026#34;BestEffort\u0026#34; } } ","date":"2020-09-17T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-2-2.springboot-pods%E9%A1%B9%E7%9B%AE%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"[ Kubernetes ] 2-2.SpringBoot--Pods项目初体验"},{"content":"安装初始化K8s集群 1.安装K8s 1.1CentOS安装   预先准备工作\n# 修改设置主机名称 hostnamectl set-hostname master # 绑定主机各节点hosts 192.168.0.1 master 192.168.0.2 node1 192.168.0.3 node2 # 验证每节点的Mac地址与UUID是否唯一 # mac地址注意查看网卡 cat /sys/class/net/eth1/address cat /sys/class/dmi/id/product_uuid # 关闭缓存交换swap swapoff -a # 临时关闭 sed -i.bak \u0026#39;/swap/s/^/#/\u0026#39; /etc/fstab #永久关闭   安装Kubernetes\n# 设置K8s安装源，由于防火墙问题使用阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo   [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 更新源缓存 yum clean all yum -y makecache\n# 查看k8s版本 yum list kubelet --showduplicates | sort -r # 默认安装最新版本 yum install -y kubelet kubeadm kubectl # 选择指定版本进行安装 yum install -y kubelet-\u0026lt;version\u0026gt; kubeadm-\u0026lt;version\u0026gt; kubectl-\u0026lt;version\u0026gt; ```  1.2MacOS安装 Docker-Desktop版内置(需要访问科学上网) 2.准备Kubernetes依赖镜像 k8s.gcr.io/kube-apiserver:v1.17.1 k8s.gcr.io/kube-controller-manager:v1.17.1 k8s.gcr.io/kube-proxy:v1.17.1 k8s.gcr.io/kube-scheduler:v1.17.1 k8s.gcr.io/coredns:v1.17.1 k8s.gcr.io/etcd:v1.17.1 由于国外站点问题，需要科学上网，或者通过其他镜像仓库拉去，然后通过docker tag打标签的形式保存在docker仓库\n# 通过科学上网拉去官网仓库镜像 docker pull k8s.gcr.io/kube-apiserver:v1.17.1 ... k8s.gcr.io/etcd:v1.17.1 ## 然后通过本地惊醒仓库打包导出tar的形式 docker save k8s.gcr.io/kube-apiserver:v1.17.1 \u0026gt; k8s.tar.gz ## 导入目标服务器的本地镜像仓库 docker load \u0026lt; k8s.tar.gz 3.使用kubeadm初始化集群主节点   初始化主节点\nkubeadm init –apiserver-advertise-address=192.168.66.176 --kubernetes-version=v1.17.1 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap # 增加Kubernetes本地全局变量配置 ### 非root用户 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ### root用户 echo \u0026#34;export KUBECONFIG=/etc/kubernetes/admin.conf\u0026#34; \u0026gt;\u0026gt; ~/.bash_profile source .bash_profile   初始化主节点网络\n# 使用flannel配置网络 kubectl apply -f kube-flannel.yml   关于节点污点问题\n taint:污点的意思.如果某节点设置为污点，那么pod将不允许在此节点上运行。\n # 查看污点信息 kubectl describe node master|grep -i taints # 删除默认污点 kubectl taint nodes master node-role.kubernetes.io/master- # 设置污点 kubectl taint node master key1=value1:NoSchedule # 删除污点 kubectl taint nodes master key1- ### 关于污点语法 kubectl taint node [node] key=value[effect] 其中[effect] 可取值: [ NoSchedule | PreferNoSchedule | NoExecute ] NoSchedule: 一定不能被调度 PreferNoSchedule: 尽量不要调度 NoExecute: 不仅不会调度, 还会驱逐Node上已有的Pod   Node节点加入集群\n  查看令牌\nkubeadm token list 如果令牌过期可以重新生成令牌\n  初始化令牌\nkubeadm token create   生成新的加密串\nopenssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u0026gt;/dev/null | openssl dgst -sha256 -hex | sed \u0026#39;s/^.* //\u0026#39;   node加入master\nkubeadm join 192.168.66.175:6443 --token uirohl.1auw4f6ebu1c1etc \\   \u0026ndash;discovery-token-ca-cert-hash sha256:f0d231c5a175c4f84d94cf0d7df2efc96e4ac396482ed9e04880a9d2c9b6a84e ```\n  集群移除Node节点\n### 已验证 # 设置节点不可调度 kubectl cordon ${Node} # 恢复节点调度 kubectl uncordon ${Node} # 驱逐节点上运行的业务容器 kubectl drain --ignore-daemonsets ${Node} # 移除节点 kubectl delete node ${Node} ### master剔除node（待验证） etcdctl --cacert=/etc/etcd/pki/ca.pem --cert=/etc/etcd/pki/server.pem --key=/etc/etcd/pki/server-key.pem --endpoints=https://210.74.13.8:2379 del /registry --prefix   ","date":"2020-09-14T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-1-4.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","title":"[ Kubernetes ] 1-4.kubeadm命令使用"},{"content":"Kubectl命令行工具 1.kubectl用法  $~: kubectl [command] [TYPE] [NAME] [flags]\n   [command] 子命令。用于操作Kubernetes集群资源对象。\n可取值：[create | delete | describe | get | apply]\n  [TYPE] 资源对象的类型。区分大小写\n备注：可以通过单数形式、复数形式、简写形式表示。\n# 例：不同写法的Type,但是效果一致 kubectl get pod pod1 kubectl get pods pod1 kubectl get po pod1   [NAME] 资源对象名称。区分大小写 备注： 如果不指定名称，将返回属于TYPE的所有对象列表。\n# 例：返回所有对象列表 kubectl get pods   [flags] kubectl子命令的可选参数\n  2.kubectl操作实例   创建资源对象\n# 由配置文件(*.yaml)创建一次性对象 # 创建一个对象 kubectl create -f service.yaml # 创建对个对象 kubectl create -f service.yaml -f pod.yaml   查看资源对象\n# 查看所有Pod列表 kubectl get pods # 查看指定对象 kubectl get service,pod   资源对象详情\n# 显示Node的详细信息 kubectl describe nodes node1 # 显示Pod的详细信息 kubectl describe pods/service # 显示由node1管理的pod对象 kubectl describe pods node1-service   删除资源对象\n# 基于配置文件(*.yaml)定义中名称的Pod对象 kubectl delete -f service.yaml # 删除包含指定label的所有Pod和Service对象 kubectl delete pods,services -l name=label-obj # 删除所有Pod对象 kubectl delete pods --all   运行资源对象\n# 指定Pod对象的date命令，默认情况下在Pod对象的第一个容器中执行 kubectl exec \u0026lt;pod-name\u0026gt; date # 指定Pod对象在某个特定容器中执行 kubectl exec \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; date # 通过bash获取Pod对象中特定容器的TTY(可以理解为登录容器) kubectl exec -ti \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt;   查看容器日志\n# 查看容器输出到stdout日志 kubectl logs \u0026lt;pod-name\u0026gt; # 跟踪查看容器日志(与tail -f命令具有相同效果) kubectl logs -f \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt;   ","date":"2020-09-12T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-1-2.kubectl%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/","title":"[ Kubernetes ] 1-2.Kubectl命令行工具"},{"content":"kubeadm命令使用 一、kubeadm概述 $~:kubeadm --help # kubeadm [command] |———— alpha [command] |———— completion |———— config |———— images |———— list 列出所有依赖镜像 |———— pull |———— help 查看命令详细描述 |———— init 初始化Kubernetes集群Master |———— join 在Kubernetes集群中增加Node |———— reset 重置Kubernetes集群 |———— token |———— upgrade |———— version ","date":"2020-09-12T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-1-3.kubeadm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","title":"[ Kubernetes ] 1-3.kubeadm命令使用"},{"content":"K8s之Helm包管理工具  Helm 是 Deis 开发的一个用于 Kubernetes 应用的包管理工具，主要用来管理 Charts。有点类似于 Ubuntu 中的 APT 或 CentOS 中的 YUM。\n 一、安装 Helm Release Link\n1.OS-CentOS 当前使用版本为Helm v3.1.2 linux\n# 下载二进制可执行文件压缩包 wget -O /data/helm.tar.gz https://get.helm.sh/helm-v3.1.2-linux-amd64.tar.gz # 解压 tar -xzvf /data/helm.tar.gz # 移动helm二进制文件，方便全局访问 mv linux-amd64/helm /usr/local/bin/helm 2.OS-MacOS ①.自动安装 PS：操作系统已安装brew工具\nbrew install helm ②.手动安装 当前使用版本为Helm v3.1.2 darwin\n# 下载二进制可执行文件压缩包 wget -O ~/helm.tar.gz https://get.helm.sh/helm-v3.1.2-darwin-amd64.tar.gz # 解压缩 tar -xzvf ~/helm.tar.gz # 移动helm二进制文件，方便全局访问 mv darwin-amd64/helm /usr/local/bin/helm 二、入门 1.调整helm源 # 查看源 helm repo list # 设置国内镜像源(选用阿里云源) helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts 2.搜索应用 搜索Nginx-Ingress\nhelm search repo nginx-ingress ### 搜索结果如下 ### # NAME CHART VERSION APP VERSION DESCRIPTION  #stable/nginx-ingress 0.9.5 0.10.2 An nginx Ingress controller that uses ConfigMap... #stable/nginx-lego 0.3.1 Chart for nginx-ingress-controller and kube-lego  3.安装应用 # 开启rbac权限，并通过externalIP方式进行工作 helm install --name nginx-ingress --set \u0026#34;rbac.create=true,controller.service.externalIPs[0]=192.168.100.211,controller.service.externalIPs[1]=192.168.100.212,controller.service.externalIPs[2]=192.168.100.213\u0026#34; stable/nginx-ingress ","date":"2020-09-12T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-1-5.k8s%E4%B9%8Bhelm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","title":"[ Kubernetes ] 1-5.K8s之Helm包管理工具"},{"content":"Kubernetes Kubernetes(K8s)，译文成为【舵手】。从官网的Logo可以看出是轮船上的舵。结合container(集装箱，容器)的概念，Kubernetes看起来则是管理这些容器的。是一个自动化的容器编排平台，负责应用的部署、应用的弹性以及应用的管理，前提则是这些应用都是基于容器的。\n核心功能   服务的发现与负载均衡\n附属组件KubeDNS为系统内置了服务发现功能，可以将每一个Service增加DNS名称，使得集群内节点直接通过此名称访问到；同时Service通过iptables、ipvs支持了负载均衡。\n  自动装箱\n构建于容器之上，基于资源依赖及其他约束在不影响其可用性的情况下自动完成容器的部署工作。\n  自我修复\n容器故障后自动重启、节点故障后自动重新进行容器调度、节点健康状态检查异常后会关闭容器进行重新创建。\n  水平扩展\n通过命令、UI手动水平扩展、基于CPU等资源负载率进行自动水平扩展。\n  自动发布与回滚\n使用灰度方式更新应用或其配置，过程中的应用健康状态将得到监控，以保证不在同一时刻kill掉所有实例；同时，过程中健康状态出现异常情况，将会立即自动执行回滚。\n  存储编排\nPod对象自动挂载不同类型的存储系统。\n  批量处理\n支持批处理作业、CI持续集成。\n  秘钥与配置管理\nK8s的configMap将配置与Docker镜像解耦，更新配置时，无需重新构建Docker镜像。同时，敏感数据将通过Secret对象进行解耦，以保障一定程度上的最大安全。\n  ","date":"2020-09-11T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-0.kubernetes/","title":"[ Kubernetes ] 0.Kubernetes"},{"content":"初识K8s 术语及原理   Master(主节点:control plane) 集群中的神经中枢网关。负责整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控、纠错等管理功能。\n  ApiServer\n集群的网关。\n 负责输出RESTful风格K8s接口，则是通往集群所有REST操作命令的入口，并负责接收、校验、相应所有的REST请求，最终结果状态存储在etcd中。\n   Controller Manager\n负责生命周期功能及API业务逻辑。\n **a.生命周期功能：**Namespace创建和生命周期、Event垃圾回收、Pod对象终止相关的垃圾回收、级联垃圾回收、Node的垃圾回收 **b.API业务逻辑：**由ReplicaSet执行的Pod对象扩展\n   Scheduler\n在API Server确认Pod对象之后，由调度器(Scheduler)根据集群中各节点的可用资源状态、目标运行容器的资源需求做出调度策略。\n  Etcd\n基于Raft协议开发的分布式键值存储，用于服务发现、共享配置、保证一致性(数据库的主从节点选择，分布式锁等)。\n a.etcd是独立的组件，并不属于K8s集群。 b.生产环境etcd应该按照集群方式部署运行，以提升高可用。\n     Node(从节点:worker node)\n工作节点。负责接收来自Master节点的工作指令并根据指令相应的创建或者销毁Pod对象，以及调整网络规则以合理的路由转发流量。\n  Pod\nKubernetes并不会直接运行容器，而是使用一个抽象的资源对象封装一个或者多个容器，此对象就是Pod对象。 是K8s最小的调度单元。 **一个Pod对象可以拥有多个Container容器应用。**通常情况下，这些在同一个Pod对象中的Container容器是高耦合。因为其共用同一个Pod对象下的网络名称空间、存储资源、UTS命名空间(同一个主机名称)、PID命名空间(不同应用程序可以看到其他应用程序的PID)\n  Pod Controller(Pod 控制器)\n虽说Pod对象是最小的调度单元，但实际应用中，并不会直接部署、管理Pod对象，而是借助Pod Controller对其进行管理。\n  Replication Controller(复制控制器)\nK8s的核心概念，用于管理Pod的声明周期。在主节点中，控制管理器进程同RC的定义完成Pod的创建、监控、启停等操作。\n  Replica Set\n保证在某个时间点儿上，一定数量的Pod对象在运行。是Replication Controller的升级版本。\n 主要区别在于Selector选择器 Replica Set:支持集合级别的选择器。 Replication Controller:支持在等号描述的选择器。\n   Deployment\n为保证指定的Pod对象的副本数量精确符合定义，否则将会按照「多退少补」原则进行自动管理。\n    Label(标签)\n将资源进行分类的标识符，一组附加在对象上的键值对类型数据。主要为了解决Pod对象与Service之间的关联关系。\n 一个对象可以拥有多个标签，一个标签也可以附加在多个对象。\n   Service\n建立在Pod对象之上的资源抽象，通过标签选择器选定一组Pod对象，并设定统一且固定的访问入口(通常情况下表现形式是IP地址)。\n 拥有唯一指定的名字 拥有一个虚拟IP地址和端口号 能够提供某种远程能力 被映射到提供服务能力的一组容器之上 Service的服务进程目前通过Socket方式对外提供服务  如果Kubernetes集群存在DNS附件，将会在Service对象创建时为其自动指定一个DNS名称用于客户端服务发现。\n  Volume(容器共享存储卷)\n独立于容器文件系统之外的存储空间，常用在扩展容器的存储空间并为其提供持久化存储能力。临时卷与本地卷一般位于Node本地，一旦Pod对象被调度至其他Node节点，此类型的存储卷将无法正常访问，所以此类存储卷用于数据缓存。持久数据将存放在Persistent Volume(持久卷)。\n Persistent Volume(持久卷) Persistent Volume Claims    Annotation\n另外一种附加在对象之上的键值类型数据，但拥有更大的数据量。常用于将各种**非标识型元数据(metadata)**附加到对象，但不能标识和选择对象。K8s将不会直接使用，仅当方便工具或用户查找等用途。\n a.build信息、release信息、Docker镜像信息等 b.日志库、监控库、分析库资源等资源库地址信息 c.程序调试工具信息 d.团队信息\n   Namespace\n使用Namespace来组织kubernetes的各种对象，可以实现用户的分组(多租户)，对不同的租户还可以进行单独的资源设置和管理，是的整个集群的资源配置非常灵活。\n a.在同一命名空间中，同一类型资源对象的名称必须具有唯一性 b.名称空间空间通常用于实现租户或项目的资源隔离，以达到逻辑分组目的。\n   Ingress\n解决Pod对象与外部网络隔离无法访问的组件。\n 由于K8s将Pod对象与外网进行隔离，同时Pod与Service等对象间的通信全是由K8s内部网络进行。\n     ","date":"2020-09-11T15:36:27+08:00","permalink":"https://example.com/p/kubernetes-1-1.%E5%88%9D%E8%AF%86k8s/","title":"[ Kubernetes ] 1-1.初识K8s"},{"content":"ETCD  其中ETCD是一个用于存储关键数据的键值存储，ZK是一个用于管理配置等信息的中心化服务 ETCD包括 Raft 协议、存储两大模块. etcd 的使用其实非常简单，它对外提供了 gRPC 接口，我们可以通过 Protobuf 和 gRPC 直接对 etcd 中存储的数据进行管理，也可以使用官方提供的 etcdctl 操作存储的数据。\n raft协议  每一个 Raft 集群中都包含多个服务器，在任意时刻，每一台服务器只可能处于 Leader、Follower 以及 Candidate 三种状态；在处于正常的状态时，集群中只会存在一个 Leader，其余的服务器都是 Follower。\n 节点选举  使用 Raft 协议的 etcd 集群在启动节点时，会遵循 Raft 协议的规则，所有节点一开始都被初始化为 Follower 状态，新加入的节点会在 NewNode 中做一些配置的初始化，包括用于接收各种信息的 Channel\n 竞选流程 如果集群中的某一个 Follower 节点长时间内没有收到来自 Leader 的心跳请求，当前节点就会通过 MsgHup 消息进入预选举或者选举的流程。 如果收到 MsgHup 消息的节点不是 Leader 状态，就会根据当前集群的配置选择进入 PreElection 或者 Election 阶段，PreElection 阶段并不会真正增加当前节点的 Term，它的主要作用是得到当前集群能否成功选举出一个 Leader 的答案，如果当前集群中只有两个节点而且没有预选举阶段，那么这两个节点的 Term 会无休止的增加，预选举阶段就是为了解决这一问题而出现的。 当前节点会立刻调用 becomeCandidate 将当前节点的 Raft 状态变成候选人；在这之后，它会将票投给自己，如果当前集群只有一个节点，该节点就会直接成为集群中的 Leader 节点。\n如果集群中存在了多个节点，就会向集群中的其他节点发出 MsgVote 消息，请求其他节点投票，在 Step 函数中包含不同状态的节点接收到消息时的响应 如果当前节点投的票就是消息的来源或者当前节点没有投票也没有 Leader，那么就会向来源的节点投票，否则就会通知该节点当前节点拒绝投票。 每当收到一个 MsgVoteResp 类型的消息时，就会设置当前节点持有的 votes 数组，更新其中存储的节点投票状态并返回投『同意』票的人数，如果获得的票数大于法定人数 quorum，当前节点就会成为集群的 Leader 并向其他的节点发送当前节点当选的消息，通知其余节点更新 Raft 结构体中的 Term 等信息\n存储\netcd 目前支持 V2 和 V3 两个大版本，这两个版本在实现上有比较大的不同，一方面是对外提供接口的方式，另一方面就是底层的存储引擎，V2 版本的实例是一个纯内存的实现，所有的数据都没有存储在磁盘上，而 V3 版本的实例就支持了数据的持久化。 在 V3 版本的设计中，etcd 通过 backend 后端这一设计，很好地封装了存储引擎的实现细节，为上层提供一个更一致的接口.\n","date":"2020-08-30T00:00:00Z","permalink":"https://example.com/p/etcd-1.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A81/","title":"[ Etcd ] 1.基础入门(1)"},{"content":"Etcd源码阅读与分析①-raft demo Etcd 与 Zookeeper 对比  一致性协议:配置共享\u0026amp;服务发现组件的核心基础。  Zookeeper采用ZAB协议(一种类Paxos协议)实现一致性 Etcd采用Raft协议，相比Paxos协议更容易理解，工程化。   API接口: 包含有两个版本V2、V3  V2: 提供HTTP+Json方式调用 V3: 提供grpc方式调用   性能  官方测试数据显示：10000+/s写入(优于Zookeeper性能)   安全  Etcd支持TSL(权限控制优于Zookeeper)    Etcd是一个基于Raft协议的简单内存KV项目\n源码分析 本文档将以etcd作者在项目中所提供的demo程序进行源码试读。demo名称为raftexample。 路径在\n1.项目结构 (base) {11:45}~/etcd:master ✗ ➭ tree -d -L 1 . . ├── Documentation # 项目文档 ├── auth # 认证授权 ├── client # 客户端相关(v2) ├── clientv3 # 客户端相关(v3) ├── contrib # (待验证) ├── default.etcd # 已编译完成的etcd ├── embed # 封装的etcd函数 ├── etcdctl # etcd操作命令，命令行客户端 ├── etcdmain # main函数入口这里 ├── etcdserver # 服务端相关 ├── functional # 目测验证功能测试套件 ├── hack # 开发者相关 ├── integration # (待验证) ├── lease # 实现etcd租约 ├── logos # 日志相关 ├── mvcc # MVCC存储相关 ├── pkg # 通用依赖库 ├── proxy # 代理相关Http、Https、Socks ├── raft # raft一致性协议实现 ├── scripts # 各类脚本 ├── security # 安全相关 ├── tests # (待验证) ├── tools # 工具 ├── vendor # go vendor依赖环境 ├── version # 版本信息 └── wal # Write-Ahead-Log实现 ","date":"2020-08-30T00:00:00Z","permalink":"https://example.com/p/etcd-2.%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A82/","title":"[ Etcd ] 2.基础入门(2)"},{"content":"文件系统之UFS UFS 联合文件系统[Union File System]，把其他文件系统联合到一个联合挂载点的文件系统服务(适用于Linux、FreeBSD、NetBSD OS)。\n 原理： 使用branch把不同文件系统的文件、目录「透明的」进行覆盖，形成一个单一一直的文件系统。branch具有要么read-only,要么read-write的特点。\n  思想： 写时复制(copy-on-write),如果一个资源重复，但并未被修改，将不被立即创建出新的资源，直接为新旧实例提供共享。创建新资源将发生在第一次被修改写入时。该资源共享方式，可以明显降低未修改资源复制时的消耗，但同样的，也会在写入修改是增加部分开销。\n  AFUS(Advanced Multi-Layered Unification FileSystem)  ","date":"2020-08-23T15:36:27+08:00","permalink":"https://example.com/p/docker-8.%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B9%8Bufs/","title":"[ Docker ] 8.文件系统之UFS"},{"content":"关于Linux的Cgroups 概念  Linux Cgroups(Control Groups)在Linux Namespace为进程隔离出一定空间的基础上为此进行的资源限制、控制以及统计的能力。资源包含有：CPU、内存、存储、网络等。通过Cgroups可以限制某个进程的资源占用、并且可以实时监控进程以及统计信息。\n cgroups各模块   cgroup: 针对进程进行分组的一种策略机制。\n 每一个cgroup中包含有一组进程。并且可以使用subsystem模块进行参数控制作用于此cgroup上的进程。\n   subsystem: 此模块对资源进行控制。\n Ubuntu OS可以通过apt install cgroup-bin安装命令行工具，使用lssubsys查看Kernel所支持的subsystem list。\n  blkio: 设置对块设备输入输出进行控制 cpu: 设置cgroup中进程的CPU调度策略 cpuacct: 统计cgroup中进程CPU占用情况 cpuset: 在多核机器上设置cgroup中进程可以使用的CPU和内存(内存仅适用于NUMA架构) devices: 控制cgroup中进程对设备的访问 freezer: 用于挂起(suspend)和恢复(resume)cgroup中的进程 memory: 限制cgroup中进程的内存占用 net_cls: 将cgroup中进程的网络包进行分类，以至于通过分类区区分不同cgroup中进程的网络包，并进行监控、限流等。 net_prio: 设置cgroup中进程产生的网络流量的优先级 ns: 使cgroup中进程在新的Namespace中fork出新进程(NEWNS)，同时创建出新的cgroup，并且此cgroup包含有新Namespace中的进程。    hierarchy: cgroup进程的继承关系。\n 例如： 系统通过cgroup1针对一组定时任务进程进行CPU使用限制，同时其中一个进程还需要限制磁盘IO，这时候将可以通过cgroup2继承cgroup1限制CPU的同时增加磁盘IO限制。即cgroup2同时具有CPU、IO限制，并且不影响cgroup1组中其他进程的IO限制。\n   cgroup各模块间关系  系统创建hierarchy后，系统下所有进程都将被加入cgroup中，cgroup为根节点，被hierarchy创建的cgroup将被作为此cgroup根节点下的子节点; subsystem与hierarchy是1:1关系(即，一个subsystem只能作用于一个hierarchy之上); hierarchy与subsystem是1:n关系(即，一个hierarchy可以作用于多个subsystem之上); 一个进程可以分布在不同的cgroup中，但需满足cgroup分布在不同的hierarchy中; 一个进程fork出一个子进程的同时，子进程与父进程在同一cgroup中，但可以根据需求调整到其他cgroup中。  ","date":"2020-08-22T15:36:27+08:00","permalink":"https://example.com/p/docker-7.%E5%85%B3%E4%BA%8Elinux%E7%9A%84cgroups/","title":"[ Docker ] 7.关于Linux的Cgroups"},{"content":"Docker-本地构建none包处理 踩坑①.打包构建Dockerfile镜像 每次本地打包构建Dockerfile镜像，如果更新镜像版本号会出现none的镜像在仓库中\n# 停掉none相关的镜像进程占用 docker rm $(docker ps -a | grep \u0026#34;Exited\u0026#34; | awk \u0026#39;{print $1 }\u0026#39;) # 递归依次从仓库移除这些镜像 docker rmi $(docker images | grep \u0026#34;^\u0026lt;none\u0026gt;\u0026#34; | awk \u0026#34;{print $3}\u0026#34;) # 或者，使用一下命令进行移除 docker image prune # (此命令用于删除未使用的映像) # docker image prune [options] # -- options可选值： # -a 显示所有映像(默认隐藏中间映像) # -f 不提示确认，强制直接执行删除 ","date":"2020-08-21T15:36:27+08:00","permalink":"https://example.com/p/docker-5.docker-%E6%9C%AC%E5%9C%B0%E6%9E%84%E5%BB%BAnone%E5%8C%85%E5%A4%84%E7%90%86/","title":"[ Docker ] 5.Docker-本地构建none包处理"},{"content":"关于命名空间(Linux Namespace) 概念  1.Linux Namespace 是Kernel的一个功能，可以针对一系列的系统资源进行隔离。例如：PID(process id)、UID(User id)、Network so on.\n  2.就像chroot允许把当前目录变成根目录一样进行隔离。\n  3.Namespace进行隔离用户，当前用户将在特定的Namespace中具有root权限。但在真是物理机层面，此用户仍然是以UID运行的那个用户。\n Linux包含的Namespace类型    Type Params Kernel Effect Information     Mount CLONE_NEWNS 2.4.19 隔离Namespace下的文件系统   UTS CLONE_NEWUTS 2.6.19 用作隔离nodename和domainname   IPC CLONE_NEWIPC 2.6.19 隔离System V IPC 和POSIX Message queues   PID CLONE_NEWPID 2.6.24 针对进程ID进行隔离   Network CLONE_NEWNET 2.6.29 用于隔离网络设备、IP地址端口等网络栈   User CLONE_NEWUSER 3.8 用于隔离用户及用户组    #Demo Coding ","date":"2020-08-21T15:36:27+08:00","permalink":"https://example.com/p/docker-6.%E5%85%B3%E4%BA%8E%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4linux-namespace/","title":"[ Docker ] 6.关于命名空间(Linux Namespace)"},{"content":"SpringBoot项目Docker化 一 ","date":"2020-08-20T15:36:27+08:00","permalink":"https://example.com/p/docker-4.springboot%E9%A1%B9%E7%9B%AEdocker%E5%8C%96/","title":"[ Docker ] 4.SpringBoot项目Docker化"},{"content":"Docker安装  存储库安装   安装yum-config-manager所需依赖包\n$~:sudo yum install -y yum-utils \\  device-mapper-persistent-data \\  lvm2   通过yum-config-manager添加存储库\n$~:sudo yum-config-manager \\  --add-repo \\  https://download.docker.com/linux/centos/docker-ce.repo   列出存储库中排序后可用的全部版本\nyum list docker-ce --showduplicates | sort -r   进行安装\n# 指定版本号安装 sudo yum install docker-ce-\u0026lt;VERSION_STRING\u0026gt; docker-ce-cli-\u0026lt;VERSION_STRING\u0026gt; containerd.io # 安装最新版本（不指定版本号默认为最新） sudo yum install docker-ce docker-ce-cli containerd.io   安装docker-compose\n# 下载二进制可执行文件，并保存在指定路径 sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose # 修改文件权限 sudo chmod +x /usr/local/bin/docker-compose # 创建软链到全局可执行路径 sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose    软件包安装  ","date":"2020-08-18T15:36:27+08:00","permalink":"https://example.com/p/docker-2.docker%E5%AE%89%E8%A3%85/","title":"[ Docker ] 2.Docker安装"},{"content":"Docker之jdk1.8最简镜像构建 1.准备JRE 在Java下载网站下载JRE。 Tips:此JRE为Oracle作品，而非Openjdk\n2.精简JRE中无关文件 # 进入已经下载jre压缩包的路径,执行解压 tar xzvf ~/Downloads/jre-8u241-linux-x64.tar.gz\u0026amp;\u0026amp;cd jre1.8.0_241 # 删除说明、其他文档 rm -rf COPYRIGHT LICENSE README \\ THIRDPARTYLICENSEREADME-JAVAFX.txt \\ THIRDPARTYLICENSEREADME.txt \\ Welcome.html # 删除非必要依赖文件 rm -rf lib/plugin.jar \\  lib/ext/jfxrt.jar \\  bin/javaws \\  lib/javaws.jar \\  lib/desktop \\  plugin \\  lib/deploy* \\  lib/*javafx* \\  lib/*jfx* \\  lib/amd64/libdecora_sse.so \\  lib/amd64/libprism_*.so \\  lib/amd64/libfxplugins.so \\  lib/amd64/libglass.so \\  lib/amd64/libgstreamer-lite.so \\  lib/amd64/libjavafx*.so \\  lib/amd64/libjfx*.so # 移除完成后文件大小共111M，然后进行压缩;压缩后大小为44M tar czvf jre8.tar.gz * 3.编写DockerFile FROMdocker.io/jeanblanchard/alpine-glibcMAINTAINERcheneyin xy410257@163.comADD jre8.tar.gz /usr/local/java/jdk8/ENV JAVA_HOME /usr/local/java/jdk8ENV PATH ${PATH}:${JAVA_HOME}/binWORKDIR/optTips:由于Java依赖于glibc，基础镜像选择alpine-glibc并非alpine\n4.构建打包 docker build -t touch_star/java8:1.0 . 5.测试运行 docker run -it touch_star/java8:1.0 #### Print #### /opt # java -version java version \u0026#34;1.8.0_241\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_241-b07) Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode) /opt #  ","date":"2020-08-18T15:36:27+08:00","permalink":"https://example.com/p/docker-3.docker%E4%B9%8Bjdk1.8%E6%9C%80%E7%AE%80%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/","title":"[ Docker ] 3.Docker之jdk1.8最简镜像构建"},{"content":"Docker命令  docker [option] command\n   option\n \u0026ndash;config string: 客户端配置文件的位置 \u0026ndash;context string[-c]: 用于连接到守护程序的上下文的名称 \u0026ndash;debug[-D]: 调试模式 \u0026ndash;host list[-H]: 要连接的守护程序套接字 \u0026ndash;log-level string[-l]: 日志等级[ debug | info | warn | error | fatal ]默认为info \u0026ndash;tls: 使用加密模式 \u0026ndash;tlscacert string: 签名证书文件路径 \u0026ndash;tlscert string: 密钥文件路径 \u0026ndash;tlskey string: key文件路径 \u0026ndash;tlsverify: 使用加密并验证远程连接 \u0026ndash;version[-v]: 版本信息    Management Commands(管理命令)\n builder: 管理构建 config: 管理Docker配置 container: 管理容器 context: 管理镜像构建上下文 image: 管理镜像 network: 管理网络 node: 管理Swarm节点 plugin: 管理插件 secret: 管理Docker secrets service: 管理服务 stack: 管理Docker stacks swarm: 管理Swarm集群 system: 查看系统信息 trust: 管理对Docker映像的信任 volume: 管理卷    Commands(命令)\n attach: 将本地标准输入，输出和错误流附加到正在运行的容器 build: 从Dockerfile构建镜像 commit: 根据容器的更改创建新镜像 cp: 在容器和本地文件系统之间复制文件/文件夹 create: 创建一个新的容器 deploy: 部署新堆栈或更新现有堆栈 diff: 检查容器文件系统上文件或目录的更改 events: 从服务器获取实时事件 exec: 在正在运行的容器中运行命令 export: 将容器的文件系统导出为tar存档 history: 显示镜像的历史记录 images: 显示镜像列表 import: 从tarball导入内容以创建文件系统映像 info: 显示系统范围的信息 inspect: 返回有关Docker对象的低级信息 kill: 杀死一个或多个正在运行的容器 load: 从tar存档或STDIN加载镜像 login: 登录Docker镜像仓库 logout: 退出Docker镜像仓库 logs: 提取容器的日志 pause: 暂停一个或多个容器中的所有进程 port: 列出端口映射或容器的特定映射 ps: 显示所有容器 pull: 从镜像仓库中提取镜像或存储库 push: 提交镜像或存储库到镜像仓库 rename: 为容器重新命名 restart: 重启一个或多个容器 rm: 移除一个或者多个容器 rmi: 移除一个或者多个镜像 run: 在新容器中执行命令 save: 保存一个或多个镜像到tar存档（默认情况下流式传输到STDOUT） search: 从Docker Hub中搜索镜像 start: 运行一个或者多个停止状态的容器 stats: 显示实时的容器资源使用情况统计流 stop: 停止一个或者多个运行状态的容器 tag: 创建一个引用了SOURCE_IMAGE的标签TARGET_IMAGE top: 显示某个容器的运行进程 unpause: 取消暂停一个或多个容器中的所有进程 update: 更新一个或多个容器的配置 version: 显示docker的版本信息 wait: 阻塞一个或多个容器直到停止，然后打印其退出代码    ","date":"2020-08-16T15:36:27+08:00","permalink":"https://example.com/p/docker-1.docker%E5%91%BD%E4%BB%A4/","title":"[ Docker ] 1.Docker命令"},{"content":"关于Guava增强包异步回调 1.概述 Guava针对Java异步回调做出以下两点增强功能：\n 1.引入新接口ListenableFuture。此接口继承于Java的Future接口，可监控、获取非阻塞异步执行结果。 2.引入新接口FutureCallback。此接口是新增独立接口，在异步任务完成后，根据异步结果，完成不同的回调事件，并处理异步结果。  ","date":"2020-06-30T21:10:47+08:00","permalink":"https://example.com/p/tools-1.%E5%85%B3%E4%BA%8Eguava%E5%A2%9E%E5%BC%BA%E5%8C%85%E5%BC%82%E6%AD%A5%E5%9B%9E%E8%B0%83/","title":"[ Tools ] 1.关于Guava增强包异步回调"},{"content":"排序 1.排序算法说明 1.1排序算法指标  稳定性：如果a==b且a在b前，排序后a仍保持在b前，则稳定，否则不稳定 内排序：算法程序的所有排序完全是在内存中执行的 外排序：由于数据量问题，需要把数据放置磁盘中，排序需要通过磁盘与内存间传输才可以进行 时间复杂度：运行一个算法程序所需要消耗的时长 空间复杂度：运行一个算法程序所需要消耗的内存大小  1.2各排序算法总结表    排序算法 最优情况 最差情况 时间复杂度 空间复杂度 排序方式 稳定性     冒泡排序 O(n²) O(n) O(n²) O(1) 内排序 稳定   选择排序 O(n²) O(n²) O(n²) O(1) 内排序 不稳定   插入排序 O(n) O(n²) O(n²) O(1) 内排序 稳定   希尔排序 O(n log² n) O(n log² n) O(n log n) O(1) 内排序 不稳定   归并排序 O(n log n) O(n log n) O(n log n) O(n) 外排序 稳定   快速排序 O(n log n) O(n²) O(n log n) O(log n) 内排序 不稳定   堆排序 O(n log n) O(n log n) O(n log n) O(1) 内排序 不稳定   计数排序 O(n+k) O(n+k) O(n+k) O(k) 外排序 不稳定   桶排序 O(n+k) O(n²) O(n+k) O(n+k) 外排序 稳定   基数排序 O(n*k) O(n*k) O(n*k) O(n+k) 外排序 稳定     n:数据量 k:桶的数量\n 2.算法具体实现   比较排序 (适用于一切需要排序的情况)\n 在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。\n  冒泡排序   快速排序 归并排序 堆排序    非比较排序 (对数据规模和数据分布有一定的要求)\n 通过确定每个元素之前，应该有多少个元素来排序。针对数组arr，计算arr[i]之前有多少个元素，则唯一确定了arr[i]在排序后数组中的位置。\n  计数排序 基数排序 桶排序    2.1冒泡排序(Bubble Sort) 2.1.1定义  比较相邻两个数的大小，按照要求进行位置交换。\n 2.1.2图示 2.1.3代码实现 /** * 冒泡排序 * * @param array * @return */ public static int[] bubbleSort(int[] array) { if (array.length == 0) return array; for (int i = 0; i \u0026lt; array.length; i++) for (int j = 0; j \u0026lt; array.length - 1 - i; j++) if (array[j + 1] \u0026lt; array[j]) { int tem = array[j + 1]; array[j + 1] = array[j]; array[j] = tem; } return array; } ","date":"2020-06-30T21:10:47+08:00","permalink":"https://example.com/p/%E7%AE%97%E6%B3%95-12.5-%E6%8E%92%E5%BA%8F/","title":"[ 算法 ] 12.5 排序"},{"content":"动态规划  动态规划(Dynamic Programming),每次决策依赖于当前决策状态，随即又伴随着状态偏移。决策序列就是在变化的状态中生成的(适用于多阶段优化问题)。\n 1 算法原理 1.1 基本思想   基本思想是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的最优解。\n  通过保存下子问题的解到表中，从而避免重叠子问题的重复计算，优化计算过程时间。\n  动态规划类似但不同于分治算法。\n 一句话概述：动态规划\u0026ndash;\u0026gt;各子问题重叠。分治算法\u0026ndash;\u0026gt;各子问题独立。 算法导论： 动态规划要求其子问题既要独立又要重叠。如果同一个问题的两个子问题不共享资源，则它们就是独立的。对两个子问题来说，如果它们确实是相同的子问题，只是作为不同问题的子问题出现的话，则是重叠的。\n   动态规划算法具有很多种，但是计算子问题值的填表形式是同一种。\n  1.2 算法策略 2 算法实现 2.1 适用场景  适用于求解具有某种最优性质的问题。\n 2.2 动图演示 2.3 代码实现 ","date":"2020-06-30T21:10:47+08:00","permalink":"https://example.com/p/%E7%AE%97%E6%B3%95-12.6-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","title":"[ 算法 ] 12.6 动态规划"},{"content":"Go并发之协程 首先需要了解几个概念：  channel(通道) select  1.协程、线程与进程 进程，属于操作系统，是系统资源分配的最小单位。充分利用CPU资源实现并发。\n线程，所属于进程，是进程的内部实现，大大降低了上下文切换的消耗，突破一个进程只可以处理一件事的缺陷，从而提高了系统的并发性。\n协程，粒度更细，属于线程中的调度。填补了线程在IO上性能的缺陷，避免陷入内核级上下文切换所导致的性能损耗。\n2.协程实现原理 线程实现原理\n线程是操作系统的内核对象，多线程情况下，线程达到一定数量，将会导致上下文频繁切换，CPU的额外消耗会提升。 高并发的网络编程如果一个线程对应一个socket连接将不是最好的处理方式，所以操作系统提供基于事件模式的异步编程模型。 协程实现原理\n ","date":"2020-04-22T21:36:27+08:00","permalink":"https://example.com/p/1.go%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%8D%8F%E7%A8%8B/","title":"1.Go并发之协程"},{"content":"Mysql基础 Mysql引擎   MyISAM\n  InnoDB\n  Memory\n  Archive\n     功能点 MyISAM InnoDB Memory Archive      存储限制 256TB RAM 64TB -    事务 N N Y N    全文检索 Y N N N    B+ Tree索引        哈希索引        数据缓存        外键         ","date":"2020-01-06T01:13:47+08:00","permalink":"https://example.com/p/mysql-2-1.mysql%E5%9F%BA%E7%A1%80/","title":"[ MySQL ] 2-1.MySQL基础"},{"content":"MySQL索引  Index(索引)，在存储引擎中用于快速找到记录的一种数据结构。索引用来快速寻找特定值的记录。\n 如果没有索引，执行查询时，MySQL必须从第一个记录开始扫描整个表的所有记录，知道找到符合要求的记录。如果存在索引，MySQL无需扫描全表即可迅速查找到目标记录所在的位置。\n1. 索引类型   Hash索引：\n 底层实现是基于哈希表，是一种以Key-Value形式存储数据的结构。 多个数据在存储关系上是没有任何顺序关系的。对于区间查询是无法通过索引查询的， 只能通过全表扫描的方式进行。Hash索引适用于等值查询场景。    B+ Tree索引：(MySQL引擎Innodb实现方式)\n B+ Tree索引是一种多路平衡查询树。 其节点是天然有序的(左节点 \u0026lt; 父节点 \u0026lt; 右节点)。 对于范围查询时候不需要做全表扫描。    相比Hash索引，B+ Tree的优点：\n Hash索引适合等值查询，但是无法进行范围查询 Hash索引没办法利用索引完成排序 Hash索引不支持多列联合索引的最左匹配规则 如果有大量重复键值的情况下，Hash索引的效率会很低，因为存在Hash碰撞问题    2. MySQL索引失效的几种情况  如果条件中有or，即使其中有条件带索引也不会使用 对于多列索引，不是使用的第一部分(第一个)，则不会使用索引 like查询是以%开头 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 not in ,not exist. 范围查询  索引的底层实现是B+树，为何不采用红黑树，B树? （1）：B+Tree非叶子节点只存储键值信息，降低B+Tree的高度，所有叶子节点之间都有一个链指针，数据记录都存放在叶子节点中\n（2）： 红黑树这种结构，h明显要深的多，效率明显比B-Tree差很多\n（3）：B+树也存在劣势，由于键会重复出现，因此会占用更多的空间。但是与带来的性能优势相比，空间劣势往往可以接受，因此B+树的在数据库中的使用比B树更加广泛\n七种事务传播行为 （1）Propagation.REQUIRED\u0026lt;默认\u0026gt; 如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。\n（2）Propagation.SUPPORTS 如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。\n（3）Propagation.MANDATORY 如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。\n（4）Propagation.REQUIRES_NEW 重新创建一个新的事务，如果当前存在事务，延缓当前的事务。\n（5）Propagation.NOT_SUPPORTED 以非事务的方式运行，如果当前存在事务，暂停当前的事务。\n（6）Propagation.NEVER 以非事务的方式运行，如果当前存在事务，则抛出异常。\n（7）Propagation.NESTED 如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。\n3. 强制索引 # 强制索引 select * from table force index(PRI) limit 2; # 禁止索引 select * from table ignore index(PRI) limit 2; ","date":"2020-01-06T01:13:47+08:00","permalink":"https://example.com/p/mysql-2.mysql%E7%B4%A2%E5%BC%95/","title":"[ MySQL ] 2.MySQL索引"},{"content":"Redis 1. 什么是跳表  跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他的几点指针，从而达到快速访问队尾目的。跳跃表的效率可以和平衡树想媲美了，最关键是它的实现相对于平衡树来说，代码的实现上简单很多 跳跃表 level 层级完全是随机的。一般来说，层级越多，访问节点的速度越快。 一是实现有序集合键，二是集群节点中用作内部数据结构。 相比于红黑树、平衡二叉树，跳表不仅查找、插入、删除时间复杂度都是O(logN)，并且实现简单很多。  2. Redis中BitMap   Bitmap并不是一种独立的数据结构，而是基于String数据结构进行的位图操作。\n 最大空间即为String数据结构所支持的512MB， 所以bitmap所支持的最大offset为2^32-1.    一般使用场景用于大数据签到、日活统计、在线统计等等。\n 其主要优点可以节省大量空间。 例如： 进行日活统计：  使用日期作为key，用户ID作为偏移量，1为当日活跃，0为不活跃      ### 基本操作演示(以下为Redis-cli命令) # 设置一个字符串 1Aa  # 存储在redis中的二进制为 0b001100010100000101100001 set testkey 1Aa # 进行bitmap操作 setbit testkey 10 1 setbit testkey 18 0 # testkey对象index为10的bit值为1 getbit testkey 10 # testkey对象index为18的bit值为1 getbit testkey 18 # 进行位统计 ,结果为bit上为1的和， # testkey输出结果为 8 bitcount testkey # testkey输出结果为 3 bitcount testkey 0 0 3. redis事务   Multi开启事务\n  Exec执行事务块内命令\n  Discard 取消事务\n  Watch 监视一个或多个key，如果事务执行前key被改动，事务将打断\n  4. Redis的同步机制  全量拷贝，  1.slave第一次启动时，连接Master，发送PSYNC命令， 2.master会执行bgsave命令来生成rdb文件，期间的所有写命令将被写入缓冲区。  master bgsave执行完毕，向slave发送rdb文件 slave收到rdb文件，丢弃所有旧数据，开始载入rdb文件 rdb文件同步结束之后，slave执行从master缓冲区发送过来的所以写命令。   此后 master 每执行一个写命令，就向slave发送相同的写命令。   增量拷贝  如果出现网络闪断或者命令丢失等异常情况，从节点之前保存了自身已复制的偏移量和主节点的运行ID 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。    5. 缓存淘汰策略 （1）：先进先出算法（FIFO）\n（2）：最近使用最少Least Frequently Used（LFU）\n（3）：最长时间未被使用的Least Recently Used（LRU）\n当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重\n6.redis过期key删除策略 （1）：惰性删除，cpu友好，但是浪费cpu资源\n（2）：定时删除（不常用）\n（3）：定期删除，cpu友好，节省空间\n7.缓存击穿原因以及处理办法 频繁请求查询系统中不存在的数据导致；\n 处理方法：  cache null策略，查询反馈结果为null仍然缓存这个null结果，设置不超过5分钟过期时间 布隆过滤器，所有可能存在的数据映射到足够大的bitmap中 google布隆过滤器：基于内存，重启失效不支持大数据量，无法在分布式场景 redis布隆过滤器：可扩展性，不存在重启失效问题，需要网络io，性能低于google    8.缓存雪崩以及处理办法 同一时刻大量缓存失效；\n处理方法：\n（1）：缓存数据增加过期标记\n（2）：设置不同的缓存失效时间\n（3）：双层缓存策略C1为短期，C2为长期\n（4）：定时更新策略\n9.Redis如何做持久化 bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据 ，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来 实 现完整恢复重启之前的状态。\nbgsave的原理是什么？ fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写进的页面数据会逐渐和子进程分离开来。\nRDB与AOF区别 （1）：R文件格式紧凑，方便数据恢复，保存rdb文件时父进程会fork出子进程由其完成具体持久化工作，最大化redis性能，恢复大数据集速度更快，只有手动提交save命令或关闭命令时才触发备份操作；\n（2）：A记录对服务器的每次写操作（默认1s写入一次），保存数据更完整，在redis重启是会重放这些命令来恢复数据，操作效率高，故障丢失数据更少，但是文件体积更大；\nredis如何实现延时队列？ 使用sortedset，想要执行时间的时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。\n为啥redis zset使用跳跃链表而不用红黑树实现? （1）：skiplist的复杂度和红黑树一样，而且实现起来更简单。\n（2）：在并发环境下红黑树在插入和删除时需要rebalance，性能不如跳表。\n","date":"2020-01-06T01:13:47+08:00","permalink":"https://example.com/p/redis-1.-redis/","title":"[ Redis ] 1. Redis"},{"content":"ElasticSearch集群搭建 注： #A:修改/etc/security/limits.conf #\u0026lt;domain\u0026gt; \u0026lt;type\u0026gt; \u0026lt;item\u0026gt; \u0026lt;value\u0026gt; * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 4096 #B:修改/etc/sysctl.conf vm.max_map_count=262144 # 保存执行： sysctl -p # 或者 sysctl -w vm.max_map_count=262144 ","date":"2019-12-22T15:36:27+08:00","permalink":"https://example.com/p/1.elasticsearch%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","title":"1.ElasticSearch集群搭建"},{"content":"ElasticSearch集群原理 一、关于ES集群需要思考几个问题  需要多大规模的集群？  # 首先从两个方面考虑 ①.数据量有多大？数据增长情况如何？ ②.服务器硬件设施配置：CPU、Memory、Disk # 推算依据 ES Jvm heap 最大设置为32G。 30G heap大约可以存储数据量10T；服务器memory若为128G，可运行多个实例节点。 # 应用场景 A:用于构建业务搜索模块，且多是垂直领域搜索。（数据量级几千万至十亿级,一般需要2-4台机器） B:用于大规模数据的实时联机处理分析(OLAP),例如ELK，数据规模可达上千亿乃至更多，需要几十甚至上百实例节点。  集群中节点角色如何分配？  # 一个节点可以充当一个或多个角色，默认三个角色都有 # 节点角色 ①.Master node.master: true # 实例节点为主节点 ②.DataNode node.data: true # 默认是数据节点。 ③.CoordinateNode # 以上两项置为false，则此节点为协调节点； # 协调节点：一个节点只作为接收请求、转发请求到其他节点、汇总各个节点返回数据等功能的节点。 # 具体分配 A:小规模集群不需要具体区分； B:中、大规模集群(十个节点以上)，并发查询量大，查询的合并量大，可以增加独立的协调节点。角色分开的好处是分工分开，不互影响。如不会因协调角色负载过高而影响数据节点的能力。  如何避免脑裂问题发生？   索引应该设置多少个分片？ 分片应该设置多少个副本？  ","date":"2019-12-22T15:36:27+08:00","permalink":"https://example.com/p/2.elasticsearch%E9%9B%86%E7%BE%A4%E5%8E%9F%E7%90%86/","title":"2.ElasticSearch集群原理"},{"content":"MySQL之热备份工具(xtrabackup) 1.原理 2.安装  进入xtrabackup官网选择Percona XtraBackup   3.实战 ","date":"2019-11-22T19:36:27+08:00","permalink":"https://example.com/p/1.mysql%E4%B9%8B%E7%83%AD%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7xtrabackup/","title":"1.MySQL之热备份工具(xtrabackup)"},{"content":"编译安装过程 1.预编译 cmake . -DCMAKE_INSTALL_PREFIX=/data/ops/mysql/ \\ -DMYSQL_DATADIR=/data/ops/mysql/data \\ -DWITH_BOOST=../boost_1_59_0 \\ -DSYSCONFDIR=/etc \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DENABLED_LOCAL_INFILE=1 \\ -DENABLE_DTRACE=0 \\ -DDEFAULT_CHARSET=utf8mb4 \\ -DDEFAULT_COLLATION=utf8mb4_general_ci \\ -DWITH_EMBEDDED_SERVER=1 2.编译安装 make -j `grep processor /proc/cpuinfo | wc -l` #编译很消耗系统资源，小内存可能编译通不过make install make install 3.启动配置 ls -lrt /usr/local/mysql # 创建启动脚本，并增加可执行权限 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld # 开机自启动 systemctl enable mysqld 4.修改Mysql配置文件 5.添加环境变量 6.初始化数据库 7.启动数据库 ","date":"2019-11-22T19:36:27+08:00","permalink":"https://example.com/p/1.mysql%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/","title":"1.MySQL编译安装过程"},{"content":"Zookeeper 1. ZAB协议  ZAB协议是为分布式协调服务Zookeeper专有的一种协议，此协议是为了应对崩溃恢复的原子广播 崩溃恢复  整个zk集群刚启动或者Leader节点宕机、重启或者不可以正常提供服务时超出一半的情况下，所有节点将会进入崩溃恢复模式 首先通过选举产生Leader 然后集群中的Follwer节点与新产生的Leader节点进行数据同步 一旦集群中一半数量的节点与Leader节点完成了数据同步，集群就会退出崩溃恢复模式，进入到消息广播模式   消息广播  Leader节点开始接受客户端的事务请求，生成事务的提案进行事务请求处理。    ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/zookeeper-2.-zookeeper%E5%9F%BA%E7%A1%80/","title":" [ Zookeeper ] 2. Zookeeper基础"},{"content":"Zookeeper作为注册中心的缺馅 一、 关于服务发现中心 1.CAP原理   C(Consistency)：一致性\n在更新操作成功后，所有节点在同一时间的数据保证一致。\n  A(Availability)：可用性\n服务提供正常服务，并且保证都是正常响应时间。\n  P(Partition Tolerance)：分区容错性\n在分布式系统中，由于某一个节点出现或者网络分区出现异常情况，仍可以提供满足一致性或者用性 的服务。\n  2.Zookeeper保证CP  当向注册中心查询服务列表时，可以容忍注册中心返回的是在此之前已经注册的信息，但不能接受服务直接不可用的现象 服务注册功能对可用性的标准要高于一致性 在ZK中，存在这样一种情况，如果master节点因为网络故障与其他节点失去联系，剩余节点将会重新进行Leader选举。 在ZK leader选举过程中，是一个耗时操作（大概30-120s，耗时未经实际生产验证），并且选举过程中，ZK集群是处于不可用状态，这时候将会导致服务发现、服务注册处于不可用 云部署环境下，因网络问题导致ZK集群丢失Master节点是大概率事件，虽说服务可以通过重新选举恢复到可用状态，但是漫长的选举过程耗时是不可容忍的。  二、Alibaba为什么不使用ZK作为注册中心 1. 借助一篇文章示例了解CAP选择  网上存在一篇文章阿里巴巴为什么不用 ZooKeeper 做服务发现?。文中提到一个示例，三个机房进行异地容灾部署，在机房3中存在一个zk节点5，但是由于网络问题，导致机房3在网络上成为孤岛。这时，ZK集群还是可用的，但是会导致与 zk节点5 无法通信，此节点就会无法写入。\n 此时的状况就是对 CAP 三种特性的一个选择。但是在现实中场景下，是不允许因为防止分区容错 条件下保证 数据的强一致性而舍弃掉可用性。\n 在设计注册中心时应该考虑一点，不能因为注册中心的任何原因导致服务间调用出现异常。 其实，在注册中心(服务发现)这个应用场景下，进行CAP的选择，更加注重可用性。毕竟数据不一致在一定时间范围内是可以容忍的。 如果在保证分区容错(P)的情况下，不能保证可用性(A)，就违反了注册中心(服务发现)的设计原则，以及实际生产环境的要求。  2. 随时间推移ZK的能力有所下降  在注册中心(服务发现)的场景下，随着大量的服务注册到ZK集群中，频繁的写请求、服务健康检查的心跳机制都会给ZK集群带来压力。 如果通过不同业务使用不同的ZK集群进行服务发现，就会破坏注册中心一开始的设计初衷：不得以自身任何原因破坏掉服务间的互通性。  3. ZK自身保证事务的特性  ZAB协议处理每一个写请求的同时，会在ZK集群的每一个节点上进行事务日志写入 定期通过内存数据快照同步到磁盘，保证数据一致性、数据持久性、宕机数据可恢复性。注册中心保存的数据信息包含有：注册成功的服务的可用服务地址信息。但是在 注册中心(服务发现) 的应用场景下，仅是为了保证每次可以正常调用到下游服务，并不关心下游服务的历史信息，所以说一定程度上，持久化这些数据是没有必要的。 但是从另外一个角度，注册中心还是要持久元数据信息的，譬如：服务版本、所在数据中心、服务路由权重、鉴权策略信息等等。 不单单需要提供持久性，同时还需要满足持久化数据的搜索能力。  4. 例如Dubbo服务间调用采用ZK作为注册中心  在实际环境中，不能因为ZK集群挂掉，导致服务间调用出现异常。 Dubbo服务间调用：Dubbo服务在注册到注册中心后，会将必要的数据信息在本地环境下进行持久化，也就是说，在ZK集群处于瘫痪，并且没有新服务注册进来提供被调用能力时，原有服务间的调用不能收到影响。 注册中心最关键的是在 新服务注册、节点上下线等情况下提供支持。  5. 关于异常处理 ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/zookeeper-3.-zookeeper%E4%BD%9C%E4%B8%BA%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E7%9A%84%E7%BC%BA%E9%A6%85/","title":" [ Zookeeper ] 3. Zookeeper作为注册中心的缺馅"},{"content":"vim 1.基本操作命令 普通模式(Normal)  a: append current location i: insert current location o: open a line below A: append after line I: insert before line O: open a line above y: copy p: parse ^: 光标移至行首 $: 光标移至行末 G: 光标移至末行 1G: 光标移至首行 H: 光标移至当前窗口首行 M: 光标移至当前窗口中间位置  命令行模式(Command)  % s/string1/string2/g  可视化模式(Visual)  v:  插入编辑模式(Insert) 2.快速纠错 编辑模式下：  ctrl+w: 删除上一个单词 ctrl+u: 删除当前行  ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/1.linux-vim/","title":"1.Linux-Vim"},{"content":"zookeeper分布式部署 一.配置服务器IP地址映射 [root@localhost zk]~#: vim /etc/hosts\n192.168.1.111 zoo1 192.168.1.112 zoo2 192.168.1.113 zoo3 192.168.1.114 zoo4 192.168.1.115 zoo5 二.修改配置ZK文件 1.下载Zookeeper\n# 进入ZK路径 wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.5.6/apache-zookeeper-3.5.6-bin.tar.gz 2.修改配置文件 进入conf目录，在配置文件前，先cp zoo_sample.cfg zoo.cfg,然后vim zoo.cfg。配置如下：\ntickTime=2000 initLimit=10 syncLimit=5 dataDir=/data/ops/zk/zookeeper-3.5.6-master/conf clientPort=2181 server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 3.启动ZK ①.在每个节点的服务器依次启动服务： [root@localhost zk]~#: ./bin/zkServer.sh start 在启动过程中日志会出现异常，由于其他节点还未启动，所以属于正常情况（正常情况下，仅有最后一个节点启动不会出现异常）。待所有节点全部启动，集群会逐渐稳定下来。 ②.查询每一个节点角色 [root@localhost zk]~#: ./bin/zkServer.sh status\n# LeaderNode ZooKeeper JMX enabled by default Using config: /data/ops/zk/zookeeper-3.5.6-follower/bin/../conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: leader # FollowerNode ZooKeeper JMX enabled by default Using config: /data/ops/zk/zookeeper-3.5.6-master/bin/../conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: follower ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/1.zookeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2/","title":"1.zookeeper分布式部署"},{"content":"1.Nginx入门 一、Nginx为什么受青睐 ​\t在介绍Nginx具体的安装、配置以及原理之前先聊聊概念常识问题。那就是目前为什么Nginx深受青睐？那我们先从Nginx是什么开始聊起。\n1.Nginx是什么   简单介绍\n ***Nginx***来自于俄罗斯，是在**RamblerMedia**工作的**Igor Sysoev**使用***C***语言编写而成的跨平台轻量级高性能的*Web*服务器。***Nginx***可以运行在**Linux**、**FreeBSD**、**Solaris**(*Sun*公司的类*Unix OS*)、**MacOS**、以及**Windows**等操作系统。操作系统的不同，也给***Nginx***带来了一些好处，***Nginx***会使用当前操作系统中特有的一些高效**API**来提高自身的性能。    Nginx和它的对手们\nNginx的对手们有Apache、Lighttpd、Tomcat、Jetty、IIS，它们同为Web服务器：具备Web服务器的基本功能；基于Rest架构风格，以**统一资源描述符（URI）或统一资源定位符（URL）作为沟通依据，通过HTTP为浏览器等Client程序提供各种网络服务。\n但是，这些Web服务器呢，都多多少少因为各自的定位与发展方向都不尽相同，使得每一款Web服务器都各有特色：\n​\t1.Tomcat、Jetty：都是面向Java语言设计的。但是它们在性能方面与Nginx没有什么可比性，因为这两款服务器都是重量级选手。可能有伙伴会很疑惑，我已经用Tomcat跑起服务，同样配置后可以直接访问为什么还要在加层外套Nginx，对于这个问题，在后边对这一点进行详细的分析。【】\n​\t2.IIS：这位选手呢，来自于微软家族。然后特点大家可能就很清楚了，它只能在Windows OS运行（不过网上也有工具可以把它运行在LinuxOS中，但是并不是很完美哦）。可能拉低它颜值的就是稳定性与性能了，Windows OS作为服务器的话，稳定性和部分性能都不能和类Unix OS进行媲美，所以呢，在高性能Web服务器的场合中，IIS可能就要被“淘汰”了。\n​\t3.Apache：这是一位压轴级选手，是发展周期最长的，毫无疑问是世界第一大Web服务器，在2012年遥遥领先其他选手。它毕竟有很多优秀的地方：稳定、开源、跨平台等。但是美中不足的是，它被设计成为了重量级、不支持高并发的Web服务器。如果有数以万计的HTTP请求同时访问，服务器就会面临大量内存消耗的问题，操作系统也会跟着收到牵连，毕竟Apache的进程做进程间切换时会给服务器的CPU带来重大压力，同时会伴随着响应效率降低，这致命的一击，导致这位来自“贵族世家”的选手在高性能Web服务器的舞台上没有了地位。\n​\t4.Lighttpd：与Nginx同样是轻量级、高性能的Web服务器。但是它并没有得到国内开发者的钟爱，而是被欧美的开发者们所追捧。\n  恩宠\u0026ndash;Nginx\nNginx的代码也是开源的而且是最自由的2-clause BSD-like license许可证。Nginx使用的架构是基于事件驱动的，能够并发处理百万级别的TCP连接。由于Nginx的高度模块化和具有最自由的许可证，让Nginx的第三方模块扩展功能更加充实。优秀的设计还带来了极佳的稳定性体验。所以，Nginx大量应用于大流量的网站来高效处理大规模高并发连接。种种迹象表明，Nginx在性能方面很出色。\n  2.Nginx的特点   更快\n快主要体现在两方面：①在正常的情况下，单次请求会得到更快的响应；②在数以万计的并发请求中，Nginx可以比其他Web服务器更快的响应请求。\n  高扩展性\nNginx的高度模块化决定了其具有高扩展性。它完全是由多个不同功能、不同层次、不同类型以及耦合度极低的模块组合而成。它的模块都是嵌入到二进制文件中执行，使得第三方开发的模块也一样完美支持性能。所以高并发的网站完全可以根据自身项目业务特性定制属于自己的模块。\n  高可靠性\n这个特点应该是选择Web服务器最基本的条件。Nginx的稳定性，大家有目共睹。国内多家高流量并发的网站在核心的服务器上大规模使用Nginx。官方提供的常用模块是非常稳定的，每一个Worker进程都相对独立，把耦合性降至最低。master进程在其中一个Worker进程出错时可以快速“拉起”新的Worker子进程提供相应的服务。\n  低内存消耗\n据数据测试，一般情况下，1W个不活跃的HTTP Keep-Alive连接在Nginx中消耗只有2.5MB的内存。（这也是Nginx能够支持高并发连接的基础）\n  单机支持10W+的并发连接\n由于现在是海量数据时代，高并发无疑成为大家青睐的对象。理论上，Nginx支持的并发连接数量取决于内存，10W+的并发连接并没有到极限。但是，能否及时处理更多的并发连接应该取决于项目业务的需求。\n  热部署\nmaster管理进程和Worker进程是相互隔离的，这使得Nginx能够彰显热部署的能力。通俗点来说，就是完全可以在7*24h不停止服务正常工作的情况下，可以升级Nginx的可执行文件、更新配置选项、更新日志文件等功能操作。\n  最自由的BSD许可协议\n俗话说**“众人拾柴火焰高”**。也正是BSD许可协议带来的极大优势，为**Nginx**提供更强劲的发展动力。\n  综上所述，选择Nginx的核心理由还是由于它能在支持高并发请求的同时保持高效的服务。  二、Nginx的安装 1.源码安装 在正式安装Nginx前需要保证服务器主机已经安装有编译环境GCC开发库之类的环境。\n GCC编译环境工具安装  ①Ubuntu OS编译环境使用如下命令：\napt-get install build-essential apt-get install libtool ②CentOS编译环境使用如下命令：\nyum install -y gcc automake autoconf libtool make yum install -y gcc -c++ 安装完成编译环境，就可以着手准备Nginx所需要的类库PCRE库、zlib库、OpenSSL开发库。\n PCRE库安装  首先介绍一下PCRE库的作用，为Nginx的HTTP模块提供解析正则表达式的基础。这里直接通过下载源码的方式进行编译安装。根据需要的版本在PCRE源码中选择URL然后用下边命令进行下载\nwget https://ftp.pcre.org/pub/pcre/pcre-8.42.tar.gz ## 现在完成后，对源码包进行解压 tar -xzvf pcre-8.42.tar.gz ## 解压完成进入pcre-8.42目录 cd pcre-8.42 ## 执行配置 ./configure ## 进行编译并安装 make make install  Zlib库安装  Zlib库主要是针对HTTP包的内容做gzip格式的压缩。例如，Nginx的配置nginx.conf文件中配置gzip on。Zlib-1.2.11下载\n## 使用Wget命令下载源码 wget http://zlib.net/zlib-1.2.11.tar.gz ## 进行解压 tar -xzvf zlib-1.2.11.tar.gz ## 进入zlib目录进行配置编译安装操作 cd zlib-1.2.11 ./configure make make install  Openssl安装  如果对版本没有特殊要求，OpenSSL我们采用命令安装\n## CentOS 安装命令 yum install openssl openssl-devel ## Ubuntu/Debian 安装命令 sudo apt-get install openssl sudo apt-get install libssl-devel  Nginx安装  首先去Nginx官网下载合适版本的源码。同时我们可以直接在服务器使用wget命令进行下载。\nwget http://nginx.org/download/nginx-1.14.0.tar.gz ## 解压Nginx源码 tar -xzvf nginx-1.14.0.tar.gz cd nginx-1.14.0 ## 进行配置项的配置:(以下只是选择了编译Nginx源码时的部分配置选项) # --sbin-path: 指定了可执行文件的放置路径,默认路径在\u0026lt;prefix\u0026gt;/sbin/nginx # --conf-path: 指定了配置选项文件的放置路径,默认路径在\u0026lt;prefix\u0026gt;/conf/nginx.conf # --pid-path: 指定了pid文件的放置路径,默认路径在\u0026lt;prefix\u0026gt;/logs\u0026gt;nginx.pid # --with-http_ssl_module:安装http_ssl_module，使得Nginx支持SSL协议，保证HTTPS服务。 # --with-pcre: 指定PCRE库源码的路径，编译Nginx时会进入此路径对源码进行编译。 # --with-zlib: 指定Zlib库源码的路径，编译Nginx时会进入此路径对源码进行编译。 ./configure \\ --sbin-path=/usr/local/nginx/nginx \\  --conf-path=/usr/local/nginx/nginx.conf \\ --pid-path=/usr/local/nginx/nginx.pid \\ --with-http_ssl_module \\ --with-pcre=/opt/app/openet/oetal1/cheney/pcre-8.42 \\ --with-zlib=/opt/app/openet/oetal1/cheney/zlib-1.2.11 ## 配置完成后进行编译安装 make make install 安装完成之后可以进行简单的测试，进入配置的**${\u0026ndash;sbin-path}**路径下启动Nginx。\n## 直接使用默认配置执行nginx可执行文件启动服务 /usr/local/nginx/sbin/nginx 在保证服务器主机端口可以访问的情况下，使用浏览器访问主机IP地址，例如http://127.0.0.1，可以看到Nginx服务的默认主页。这就说明Nginx服务正常启动了。然后可以根据项目具体的业务需求，对Nginx进行特殊配置进行详细定制。\n Nginx的具体配值问题，下篇文章进行详细介绍。 ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/nginx-1.nginx%E5%85%A5%E9%97%A8/","title":"[Nginx] 1.Nginx入门"},{"content":"CentOS修改系统镜像源 一.备份当前源 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 二、切换阿里云镜像源  CentOS7 切换源  # 进入源所在路径 cd /etc/yum.repos.d/ # 下载阿里云镜像源并保存为源文件 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo  CentOS6 切换源  # 进入源所在路径 cd /etc/yum.repos.d/ # 下载网易163镜像源并保存为源文件 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS6-Base-163.repo ","date":"2019-11-12T01:36:27+08:00","permalink":"https://example.com/p/centos%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E9%95%9C%E5%83%8F%E6%BA%90/","title":"CentOS修改系统镜像源"},{"content":"KVM入门  1.基础操作 ①.创建虚拟机 virt-install --name=centos-node1-0113 \\ --ram=4096 --vcpus=2 \\ --disk /data/virtualdisk\\centos-node1-0113.img,sparse=false,bus=virtio,size=100 \\ --cdrom=/root/Download/CentOS-7-x86_64-Minimal-1810.iso\\ --network bridge=br2 \\ --vnc --vncport=5921 --vnclisten=0.0.0.0 \\ --noautoconsole --force --autostart ②.虚拟机相关操作 # 显示所有虚拟机列表 virsh list --all # 启动指定虚拟机 virsh start \u0026lt;name\u0026gt;/\u0026lt;id\u0026gt; # 停止指定虚拟机 virsh shutdown \u0026lt;name\u0026gt;/\u0026lt;id\u0026gt; # 销毁指定虚拟机(强制断电) virsh destory \u0026lt;name\u0026gt;/\u0026lt;id\u0026gt; # 登入指定虚拟机 virsh console \u0026lt;name\u0026gt;/\u0026lt;id\u0026gt; # 为虚拟机添加网卡绑定 virsh attach-interface \\ --domain centos_node2-142-5922 \\  --type bridge \\ --source br0 \\ --model virtio \\ --config # 分离虚拟机网卡绑定 virsh detach-interface \\ centos_node2-142-5922 \\ bridge \\ 52:54:00:aa:9c:18 # 查看虚拟机网卡绑定详细信息 virsh domiflist centos_node2-142-5922 # 查看网桥信息(brctl:网桥管理工具) brctl show # 虚拟机管理工具(virt-*) ③.网桥模式(Bridge)下的网卡配置   宿主机虚拟网桥配置文件详情：\n\u0026lt;!-- 配置文件在kvm-qeum下：/etc/libvirt/qemu/networks/default.xml --\u0026gt; \u0026lt;network\u0026gt; \u0026lt;name\u0026gt;default\u0026lt;/name\u0026gt; \u0026lt;uuid\u0026gt;9698a2c1-c8a1-4ec3-8cc3-0a8edebab6c4\u0026lt;/uuid\u0026gt; \u0026lt;!-- 端口转发 --\u0026gt; \u0026lt;forward mode=\u0026#39;nat\u0026#39;\u0026gt; \u0026lt;nat\u0026gt; \u0026lt;port start=\u0026#39;1024\u0026#39; end=\u0026#39;65535\u0026#39;/\u0026gt; \u0026lt;/nat\u0026gt; \u0026lt;/forward\u0026gt; \u0026lt;!-- 网桥配置 --\u0026gt; \u0026lt;bridge name=\u0026#39;virbr0\u0026#39; stp=\u0026#39;on\u0026#39; delay=\u0026#39;0\u0026#39;/\u0026gt; \u0026lt;mac address=\u0026#39;52:54:00:c9:6a:e2\u0026#39;/\u0026gt; \u0026lt;ip address=\u0026#39;192.168.122.1\u0026#39; netmask=\u0026#39;255.255.255.0\u0026#39;\u0026gt; \u0026lt;dhcp\u0026gt; \u0026lt;range start=\u0026#39;192.168.122.2\u0026#39; end=\u0026#39;192.168.122.254\u0026#39;/\u0026gt; \u0026lt;/dhcp\u0026gt; \u0026lt;/ip\u0026gt; \u0026lt;/network\u0026gt;   宿主机网桥\nDEVICE=br0 HWADDR=B8:2A:72:CE:DA:75 TYPE=Bridge UUID=325e2119-f293-4555-b984-ae8ae886b4de ONBOOT=yes NM_CONTROLLED=no BOOTPROTO=static\tIPADDR=10.106.36.135 NETMASK=255.255.255.128 GATEWAY=10.106.36.1   虚主机网卡\nTYPE=Ethernet BOOTPROTO=none DEFROUTE=yes NAME=eth0 DEVICE=eth0 NM_CONTROLLED=no USERCTL=no ONBOOT=yes IPADDR=60.206.36.164 GATEWAY=60.206.36.129 NETMASK=255.255.255.128 DNS1=114.114.114.114 ARPCHECK=no   2.关于宿主机网桥配置 1.物理网卡配置\nTYPE=\u0026#34;Ethernet\u0026#34; BOOTPROTO=\u0026#34;no\u0026#34; DEFROUTE=\u0026#34;yes\u0026#34; NAME=\u0026#34;em1\u0026#34; UUID=\u0026#34;d4b9c4cb-b04c-4d91-9e9c-bc1b0c47a416\u0026#34; DEVICE=\u0026#34;em1\u0026#34; ONBOOT=\u0026#34;yes\u0026#34; BRIDGE=\u0026#34;br0\u0026#34; 2.网桥配置\nTYPE=\u0026#34;Bridge\u0026#34; BOOTPROTO=\u0026#34;static\u0026#34; DEVICE=\u0026#34;br0\u0026#34; NAME=\u0026#34;br0\u0026#34; ONBOOT=\u0026#34;yes\u0026#34; IPADDR=\u0026#34;10.36.24.180\u0026#34; NETMASK=\u0026#34;255.255.255.0\u0026#34; GATEWAY=\u0026#34;10.36.24.1\u0026#34; NM_CONTROLLED=\u0026#34;no\u0026#34; ","date":"2019-10-12T01:36:27+08:00","permalink":"https://example.com/p/1.kvm%E5%85%A5%E9%97%A8/","title":"1.KVM入门"},{"content":"TCP/IP入门 1.1 协议分层 ✌🏼😂😅😅\n","date":"2019-10-12T01:36:27+08:00","permalink":"https://example.com/p/1.tcp/ip%E5%85%A5%E9%97%A8/","title":"1.TCP/IP入门"},{"content":"双网卡网关配置 1.在系统路由表文件/etc/iproute2/rt_tables增加配置\n252 e1 251 e0 2.执行以下命令，并在/etc/rc.d/network追加此内容\n# 此内容防止服务器重启路由失效 ip route flush table e0 ip route add default via 10.3.3.1 dev eth0 src 10.3.3.25 table e0 ip route add 127.0.0.0/8 dev lo table e0 ip rule add from 10.3.3.25 table e0 ip route flush table e1 ip route add default via 10.2.2.1 dev eth1 src 10.2.2.10 table e1 ip route add 127.0.0.0/8 dev lo table e1 ip rule add from 10.2.2.10 table e1 ","date":"2019-10-12T01:36:27+08:00","permalink":"https://example.com/p/2.kvm-%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BD%91%E5%85%B3%E9%85%8D%E7%BD%AE/","title":"2.KVM-双网卡网关配置"},{"content":"关于UML图 学习设计模式前，UML还是需要学习了解一下。\nUML UML(Unified Modeling Language),即统一建模语言。是让系统可视化、让规格与设计文档化的变现方法。\n旨在目的：  为用户提供现成的、有表现力的可视化建模语言，以便开发与交换有意义的模型。 为核心概念提供可扩展性与特殊化机制。 独立特定的编程语言与开发过程。 鼓励面向对象工具市场的发展。 支持更高层次的开发概念。 为了解建模语言提供一个正式环境。 整合最佳的工作方法。  UML分类  机构性图表  类图 组件图 部署图 对象图 对象图 包图 复合机构图 轮廓图   行为性图表  用例图 活动图 状态机图 序列图 通讯图 交互概述图 时序图    UML词汇表及术语  抽象类 Actor 活动 活动图 聚合 工件 关联 关联类 属性 基类 分支 类 类图 分类器 协作 通信图 组件 组件图 概念 构建阶段 依赖关系 部署图 域 精化阶段 元素 封装 泛化 事件 最终状态 叉 泛化 GoF 高凝聚力 启动阶段 继承 初始状态 实例 接口 迭代 加入 成员 合并 消息 方法 模型 多重性 可导航型 符号 注意 对象 包 包图 模式 参数 多态性 私有 处理器 受保护 公开 读取方向箭头 实现 角色 顺序图 状态 状态图 静态 刻板印象 子类 互动区 时间拳击 过渡 过渡阶段 统一建模语言 用例 用例图 可见性： 工作流程：一组产生特定结果的活动。  ","date":"2019-08-22T15:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-0.%E5%85%B3%E4%BA%8Euml%E5%9B%BE/","title":"[ 设计模式 ] 0.关于UML图"},{"content":"原型模式 原型模式：通过复制生成实例。\n①.角色分配   Prototype(原型)\n负责定义用于复制现有实例来生成新实例的方法。\n  ConcretePrototype(具体原型)\n负责实现现有实例并生成新实例的方法。\n  Client(使用者)\n负责使用复制实例的方法生成的新实例。\n  ②.UML图 ③.代码清单  简单形式  定义抽象接口\npublic interface Prototype extends Cloneable { Object clone(); } 具体实现原型拷贝\npublic class ConcretePrototype implements Prototype { public ConcretePrototype(){ System.out.println(\u0026#34;Prototype Design Patterns\u0026#34;); } @Override public Object clone() { ConcretePrototype concretePrototype=null; try { concretePrototype=(ConcretePrototype)super.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } return concretePrototype; } } 原型实例创建\npublic static void main(String[] args) { ConcretePrototype concretePrototype1=new ConcretePrototype(); ConcretePrototype concretePrototype2=(ConcretePrototype) concretePrototype1.clone(); System.out.println(concretePrototype1.hashCode()); System.out.println(concretePrototype2.hashCode()); }  登记形式  抽象原型接口\npublic interface Prototype { Object clone(); String getName(); void setName(String name); } 具体实现原型接口方法\npublic class ConcretePrototype implements Prototype { private String name; @Override public Object clone() { ConcretePrototype concretePrototype = new ConcretePrototype(); concretePrototype.setName(this.name); return concretePrototype; } @Override public String getName() { return this.name; } @Override public void setName(String name) { this.name = name; } } 原型登记管理器\npublic class PrototypeManager { private static Map\u0026lt;String, Prototype\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); private PrototypeManager() { } public synchronized static void setPrototype(String prototypeId, Prototype prototype) { map.put(prototypeId, prototype); } public synchronized static void removePrototype(String prototypeId) { map.remove(prototypeId); } public synchronized static Prototype getPrototype(String prototypeId) throws Exception { Prototype prototype = map.get(prototypeId); if (prototype == null) { throw new Exception(\u0026#34;未找到\u0026#34; + prototypeId + \u0026#34;所对应的Prototype\u0026#34;); } return prototype; } } 客户端调用\npublic static void main(String[] args) { Prototype prototype=new ConcretePrototype(); System.out.println(prototype.hashCode()); PrototypeManager.setPrototype(\u0026#34;one\u0026#34;,prototype); Prototype prototype1=(Prototype) PrototypeManager.getPrototype(\u0026#34;one\u0026#34;).clone(); System.out.println(prototype1.hashCode()); Prototype prototype2=new ConcretePrototype(); System.out.println(prototype2.hashCode()); PrototypeManager.setPrototype(\u0026#34;one\u0026#34;,prototype2); Prototype prototype3=(Prototype) PrototypeManager.getPrototype(\u0026#34;one\u0026#34;).clone(); System.out.println(prototype3.hashCode()); prototype3.setName(\u0026#34;registration type\u0026#34;); System.out.println(prototype3.hashCode()); PrototypeManager.removePrototype(\u0026#34;one\u0026#34;); Prototype prototype4=(Prototype) PrototypeManager.getPrototype(\u0026#34;one\u0026#34;).clone(); System.out.println(prototype4.hashCode()); } ④.思路拓展  为什么要使用原型模式？  1.对象种类繁多，无法将他们整合至一个类中 2.难以根据类生成实例 3.想解耦框架与生成的实例 ","date":"2019-07-16T23:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-6.%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 6.原型模式"},{"content":"Java IO 1.关于BIO、NIO、AIO   BIO(Blocking I/O,阻塞IO)\n数据的读取、写入必须阻塞在一个线程内等待完成。\n经典BIO案例：烧开水 存在一排水壶烧开水，BIO的工作模式：叫一个线程停留在水壶出，知道水壶烧开， 才去处理下一个水壶。(实际上线程在等待水壶烧开的过程，什么事情都没有做。)   使用场景：\n适用于连接数量较小且模式固定的架构。JDK1.4前的唯一选择。\n    NIO(Non-Blocking I/O,非阻塞IO)\n是一种同时支持阻塞与非阻塞模式I/O模型。处于 java.nio包中。是面向缓冲区的。\n  使用场景：\n适用于连接数目多且连接较短(轻操作)，例如聊天室服务器，并发局限在应用中，编程较为复杂。\n   NIO重点概念：Channel(通道)、Buffer(缓冲区)、Selector(选择器)\n   Channel(通道)\nChannel是一个通道，可以通过Channel读取和写入数据。Channel与Stream不同之处：数据在Channel中是双向的，在Stream中是单向的。同时Channel可以用于写、读或者读写。\nChannel存在四种实现方式： - FileChannel：从文件中读取数据 - DatagramChannel: 从UDP网络中读取或写入数据 - SocketChannel：从TCP网络中读取或者写入数据 - ServerSocketChannel：允许监听来自TCP的连接。每产生一个连接将产生一个SocketChannel。   Buffer(缓冲区)\nBuffer是一个对象。包含着要写入、读取的数据，在面向流的I/O中，可以讲数据写入或者直接读取到stream中。实质上缓冲区是一个数组(通常使用ByteBuffer[])，但同时还提供有对数据的结构话访问、维护读写位置的信息。\nJava中每一种基本类型都将对应一种缓冲区 - ByteBuffer(字节缓冲区) # 最为常用 - CharBuffer(字符缓冲区) - ShortBuffer(短整型缓冲区) - IntBuffer(整型缓冲区) - LongBuffer(长整型缓冲区) - FloatBuffer(浮点型缓冲区) - DoubleBuffer(双精度浮点型缓存区)   Selector Selector选择器可以监听多个Channel。Selector只能管理非阻塞Channel：FileChannel是个例外，属于阻塞I/O，无法进行管理。\n监听事件： - OP_ACCEPT:接受就绪，serverSocketChannel使用 - OP_READ: 读取就绪，socketChannel使用 - OP_WRITE：写入就绪，socketChannel使用 - OP_CONNECT：连接就绪，socketChannel使用 关键对象： - Selector：选择器对象。用于Channel注册、Channel监听对象和Selector相关。 - SelectorKey：Channel监听关键字，通过此对象监听Channel状态。     AIO(Asynchronous Non-Blocking I/O,异步IO) 是一种异步非阻塞I/O模型。异步I/O是基于事件、回调机制实现的。目前应用不多。\n  使用场景：\n适用于连接数目多且连接较长(重操作)，例如云相册服务器，充分调用OS参与并发操作，编程比较复杂。JDK1.7开始支持。\n    ","date":"2019-07-12T15:36:27+08:00","permalink":"https://example.com/p/java-10.java-io/","title":"[ Java ] 10.Java IO"},{"content":"单例模式 单例模式：保证任何情况下都绝对的只生成一个实例的模式。\n①.单例角色  Singleton: 有且仅有的一个角色(实例)。  Tips:当存在多个实例时，实例间互相影响，会出现意想不到异常。当且仅当，第一次调用类中静态方法的时候，Singleton类会被初始化，生成唯一的静态实例，重复调用时直接返回已经初始化完成的实例。\n②.实现单例  **方式一：**简化实现的单例模式  public class Singleton { private static Singleton singleton=null; /* 私有化，不给外界直接new的机会 */ private Singleton() { } /* 1.简化实现的单例模式，但遇到多线程肯定有问题 */ public static Singleton getInstance(){ if (singleton==null){ singleton=new Singleton(); } return singleton; } }  **方式二：**加锁控制多线程  public class Singleton { private static Singleton singleton=null; /* 私有化，不给外界直接new的机会 */ private Singleton() { } /* 2.通过加锁进行控制多线程临界资源冲突，不推荐，对线程资源消耗大 */ public static synchronized Singleton getInstance(){ if(singleton==null){ singleton=new Singleton(); } return singleton; } }  **方式三：**懒汉模式  public class Singleton { /* 私有化，不给外界直接new的机会 */ private Singleton() { } /* 3.懒汉模式，直接new出来 */ privite static Singleton singleton=new Singleton(); }  **方式四：**双重加锁机制  public class Singleton { privite volatile static Singleton singleton=null; /* 私有化，不给外界直接new的机会 */ private Singleton() { } /* 4.双重加锁机制 */ public static Singleton getInstance(){ if(singleton==null){ synchronized(Singleton.class){ if(singleton==null){ singleton=new Singleton(); } } } return singleton; } } ","date":"2019-07-11T23:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-5.%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 5.单例模式"},{"content":"工厂模式 工厂模式：父类决定实例的生成方式，但并不决定所要生成的具体类，具体的处理细节全部交由子类做具体实现。从而可以将生成实例的框架和实际负责生成实例的类进行解耦。是模板方法模式的典型应用。工厂模式中应会有模板方法模式的出现。\n①.工厂模式分类   工厂方法模式 简单工厂模式：工厂方法模式的一种特例.\n 一个抽象产品类，可以派生出多个具体的产品类。 一个抽象工厂类，可以派生出多个具体的工厂类。 每一个具体工厂只能创建一个具体产品类的实例。    抽象工厂公式\n 多个抽象产品类，每一个抽象产品类可以派生出多个具体产品类。 一个抽象工厂类，可以派生出多个具体工厂类。 每一个具体工厂可以创建多个具体的产品类实例    区别:\n# 1.工厂方法模式只存在一个抽象产品类，但抽象工厂具有多个抽象产品类。 # 2.工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个具体产品类实例。 ②.工厂角色职责   Product(产品) 一个抽象类：定义工厂模式中生成的那些实例的所持有的接口。具体的处理由子类ConcreateProduct类所决定。\n  ConcreateProduct(具体产品) 属于具体加工职责：决定了具体生产出的产品。\n  Creator(创建者) 一个抽象类:不适用new关键字生成实例，而是通过调用生成实例的专用方法生成实例，以至于降低父类与其他类的耦合性。Creator角色对实际负责具体产品生产的ConcreateCreator角色全然不知。唯一清楚的是：只要调用Product角色和生成实例的方法，就能生成Product的实例。\n  ConcreateCreator(具体创建者) 属于具体加工职责：负责生产出具体的抽象产品。\n  ③.UML图 ④.代码清单 ⑤.注意事项 使用设计模式设计类时，开发人员必须交代清楚使用这些设计模式设计类的意图。 否则，在后续更新迭代中及其容易违背原始意图。 所以，在程序中需要注释出所有设计模式所包含的名称、意图等。 ","date":"2019-07-10T23:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-4.%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 4.工厂模式"},{"content":"模板模式 模板模式： 是带有模板功能的模式，组成模板的方法被定义在父类中，由于这些方法是抽像的，所以在父类代码中无法知道具体实现，唯一能知道的是父类在如何调用这些方法，具体的实现全由子类方法处理。\n①.UML图 ②.代码清单  AbstractDisplay类  public abstract class AbstractDisplay { /* 模板类中的模板方法规定了实现的流程,但不做具体抽象方法的具体实现 */ public void display() { open(); print(); close(); } /* 定义流程中指定的抽象方法，具体细节交给子类去实现 */ abstract void open(); abstract void print(); abstract void close(); }  CharDisplayTemplate类  public class CharDisplayTemplate extends AbstractDisplay { private char aChar; public CharDisplayTemplate(char a) { this.aChar = a; } /* 具体实现父类模板类中抽象方法 */ @Override void open() { System.out.println(\u0026#34;Char Display open()\u0026#34;); } @Override void print() { System.out.println(\u0026#34;Char Display print():\u0026#34; + this.aChar); } @Override void close() { System.out.println(\u0026#34;Char Display close()\u0026#34;); } }  StringDisplayTemplate类  public class StringDisplayTemplate extends AbstractDisplay { private String charString; public StringDisplayTemplate(String string) { this.charString = string; } /* 具体实现父类模板类中抽象方法 */ @Override void open() { System.out.println(\u0026#34;String Display open()\u0026#34;); } @Override void print() { System.out.println(this.charString); } @Override void close() { System.out.println(\u0026#34;String Display close()\u0026#34;); } } ③.思路分析  逻辑处理通用化  由于在父类模板方法中编写了算法，无需在子类中在编写算法。当发现模板方法中存在Bug，仅需要改动模板方法即可解决问题。并非像传统编码方式上的修改所有ConcreteClass角色类的相关逻辑代码。\n 父、子类间的协作性  子类实现父类抽象方法时，必须理解这些抽象方法被调用的时机、逻辑。如果看不到父类代码，不能了解到父类方法中所定义的相关逻辑，想要编写子类抽象方法实现代码是很困难的。\n 父、子类间的一致性  通过父类类型定义子类实例变量，即时不使用instanceof指定子类的类型，程序依然可以正常运行。 (里氏替换原则[LSP],通用的继承原则。)\n④.类的层次与抽象类  父类对子类的约束  在子类中可以使用父类中定义的方法 可以通过在子类中增加方法的形式实现新功能 在子类中重写父类方法可以改变程序的行为 期待子类实现抽象方法 要求子类实现抽象方法   抽象类  在模板方法中：抽象方法并不会有具体的实现代码，仅仅是确立了抽象方法的名称，通过调用使用了抽象方法的模板方法去实现编写实现。抽象类确立了实现的流程，子类决定了流程中具体要处理的内容。\n","date":"2019-07-08T15:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-3.%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 3.模板模式"},{"content":"适配器模式 适配器模式包含两种：  类适配器模式(使用继承的适配器) 对象适配器模式(使用委托的适配器)  适配器模式角色组成：  目标角色 源角色 适配器角色  ①.类适配器模式 继承于源类的同时实现目标接口\n表1-1 类与接口说明    类名 备注     Print 表示目标角色   Banner 表示源角色   PrintBanner 表示适配器角色    代码清单  Print(目标角色)  public interface Print { abstract void printWeak(); abstract void printStrong(); }  Banner(源角色)  public class Banner { private String nameString; public Banner(String nameString) { this.nameString=nameString; } public void showWithParen() { System.out.println(\u0026#34;(\u0026#34;+nameString+\u0026#34;)\u0026#34;); } public void showWithAster() { System.out.println(\u0026#34;*\u0026#34;+nameString+\u0026#34;*\u0026#34;); } }  PrintBanner(适配器)  /** * 适配器角色 */ public class PrintBanner extends Banner implements Print { public PrintBanner(String nameString) { super(nameString); } /* * 实现Print接口(目标)的两个方法 * 同时，继承Banner父类(源)的两个方法 */ @Override public void printWeak() { showWithParen(); } @Override public void printStrong() { showWithAster(); } } Tips:PrintBanner与Banner是继承关系，这决定了这个适配器模式是类的\n②.对象适配器模式 代码清单  PrintTwo(目标角色)  /** * 如果目标角色不是接口而是抽象类 */ public abstract class PrintTwo { public abstract void printWeak(); public abstract void printStrong(); }  Banner(源角色)  # 源角色无变化，与继承适配器使用同一类  PrintBannerTwo(适配器)  public class PrintBannerTwo extends PrintTwo { private Banner banner; // 初始化类的时候获取到委派对象  public PrintBannerTwo(String nameString) { this.banner = new Banner(nameString); } @Override public void printWeak() { /** * 通过委派形式实现适配器 */ banner.showWithParen(); } @Override public void printStrong() { banner.showWithAster(); } } ③.类适配器与对象适配器对比     优点 缺点     类适配器 使用方便，仅需要引入一个对象 高耦合、灵活性差。使用对象继承的方式，是静态的定义方式   对象适配器 低耦合、灵活性高。采用 “对象组合”的方式，是动态组合方式 使用复杂    ④.使用要点  在系统中，现有的类经过充分测试，Bug很少或不存在，可以使用适配者模式，在新功能上进行现有类的复用。 在适配者模式中，并不一定需要有现成的代码，只要知道现有的类的功能，就可以编写出新的类。 系统部分功能更新迭代兼容性问题，可以通过适配者模式做新老版本兼容。例如：新版本扮演Adaptee角色，旧版本扮演Target角色，编写一个新的Adapter角色的类（使用新版本的类实现旧版本类中的方法）。  ","date":"2019-07-06T15:36:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-2.%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 2.适配器模式"},{"content":"迭代器模式 表1-1 类与接口说明    类名 备注     Aggregate 表示集合的接口   Iterator 遍历集合接口   Book 表示书的类   BookShelf 表示书架的类   BookShelfIterator 遍历书架的类    代码清单  Aggregate接口  /** * 表示集合接口 */ public interface Aggregate { /* 用于生成一个遍历集合的迭代器 */ public abstract Iterator iterator(); }  Iterator接口  /** * 遍历集合接口 */ public interface Iterator { /* 判断是否存在下一个元素 */ public abstract boolean hasNext(); /* 获取下一个元素 */ public abstract Object next(); }  Book类  /** * 表示书的类 */ public class Book { /* 书名属性 */ private String name; /* Default constructor */ public Book(String name) { this.name=name; } /* 获取书名方法 */ public String getName() { return name; } }  BookShelf类  /** * 表示书架的类 * 当外部想要遍历书架时则会调用iterator方法 */ public class BookShelf implements Aggregate { /* 书架的属性--书 * 私有属性，防止外部进行篡改 */ private Book[] books; /* 书架的容量 */ private int last=0; public BookShelf(int maxSize){ this.books=new Book[maxSize]; } /* 根据位置获取对应的书 */ public Book getBookAt(int index){ return books[index]; } /* 向书架添加书 */ public void appendBook(Book book){ this.books[last]=book; last++; } /* 获取书架存放书的数量 */ public int getLength(){ return last; } /* 迭代器 */ @Override public Iterator iterator(){ return new BookShelfIterator(this); } }  BookShelfIterator类  /** * 遍历书架的类,发挥Iterator的作用 */ public class BookShelfIterator implements Iterator { /* 表示BookShelfIterator迭代器所要遍历的书架 */ private BookShelf bookShelf; /* 表示迭代器当前指向书的下标 */ private int index; public BookShelfIterator(BookShelf bookShelf) { this.bookShelf = bookShelf; this.index = 0; } /* 判断是否存在下一个元素 */ @Override public boolean hasNext(){ if (index\u0026lt;bookShelf.getLength()){ return true; } return false; } /* 获取下一个元素 */ @Override public Object next() { /* 获取迭代器当前所指向的书 */ Book book=bookShelf.getBookAt(index); /* 并把下标指向下一本书的下标 */ index++; return book; } }  Main主类  public class Main { public static void main(String[] args) { /* 先初始化来一个存放书的书架 */ BookShelf bookShelf = new BookShelf(4); bookShelf.appendBook(new Book(\u0026#34;firstOneBook\u0026#34;)); bookShelf.appendBook(new Book(\u0026#34;firstTwoBook\u0026#34;)); bookShelf.appendBook(new Book(\u0026#34;firstThreeBook\u0026#34;)); bookShelf.appendBook(new Book(\u0026#34;firstFourBook\u0026#34;)); /* 通过Iterator拿到遍历书架的实例 */ Iterator iterator = bookShelf.iterator(); /* 没有下一个元素就停止遍历 */ while (iterator.hasNext()) { /* 通过next()方法拿出下一本书 */ System.out.println(((Book) iterator.next()).getName()); } } } Iterator之角色职责   Iterator迭代器\n负责定义按照顺序逐个遍历元素的迭代器接口。\n  ConcreateIterator具体迭代器\n负责具体实现Iterator接口中的具体实现。\n  Aggregate集合\n负责定义创建Iterator角色的接口。\n  ConcreteAggregate具体集合\n负责实现Aggregate角色所定义的接口,会创建出具体的Iterator角色。\n  若不使用Aggregate、Iterator接口，直接通过ConcreteAggregate、 ConcreateIterator具体类解决所有的问题， 极容易导致类之间的强耦合；同时也难以作为组件供其他类调用。 为弱化耦合，需要引入抽象类与接口。 ","date":"2019-07-06T05:16:27+08:00","permalink":"https://example.com/p/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-1.%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"[ 设计模式 ] 1.迭代器模式 "},{"content":"对象入门 ​\t首先一个重要的概念：OOP (Object Oriented Programming),即面向对象编程。对于面向对象会有三大特征：封装、继承、多态。\n 封装：就是把客观事物封装成具体抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象进行操作，对不可信的进行隐藏。一个类就是封装了数据以及操作这些数据的代码的逻辑实体。在一个对象内部，某些代码或者某些数据可以是私有的，不能被外界所访问。通过这种方式，对象对内部数据提供了不同级别的保护，以防止程序中无关的部分意外的改变或者错误的使用了对象的私有部分。 继承：指可以让某个类型的对象获得另一个类型的对象的属性的方法。它支持按级分类的概念。继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。 通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。继承的过程，就是从一般到特殊的过程。要实现继承，可以通过 “继承”（Inheritance）和“组合”（Composition）来实现。继承概念的实现方式有二类：实现继承与接口继承。实现继承是指直接使用 基类的属性和方法而无需额外编码的能力；接口继承是指仅使用属性和方法的名称、但是子类必须提供实现的能力。 多态：是指一个类实例的相同方法在不同情形有不同表现形式。多态机制使具有不同内部结构的对象可以共享相同的外部接口。这意味着，虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用。  一、抽象 ​\tJava基础语言的面向对象程序设计方法具有的一下五大基本特征：\n 所有东西都是对象。可将对象想象成一种新型变量；它保存着数据，但是可要求它对自身进行操作。理论来说，可以从要解决的问题身上提出所有概念性的组件，然后在程序中将其表达为一个对象。 程序是一大堆对象的组合。通过消息的传递，各对象知道自己该做什么。为了向面向对象发出请求，需向那个对象发送一条消息。更确切的来说，可以将消息想象成为一个请求，他调用的是从属于目标对象的一个子例程或者说是函数。 每个对象都有自己的存储空间，可以容纳其他对象。或者说是，通过封装现有的对象，可以制造出一个新型对象。所以，尽管对象的概念非常简单，但是在程序中却可以达到任意高的复杂程度。 每个对象都有一个类型。根据语法，每个对象都是某个类中的一个实例。其中，类**(Class)**是类型(type)的同义词。一个类最为重要的特征就是“能将什么消息发送给它”。 同一个类所有的对象都能接收相同的消息。这实际是别有含义的一种说法。由于类型为“圆”的一个对象也属于类型为“形状”的一个对象。所以一个圆完全可以接收形状消息。这意味着可以让程序代码统一指挥“形状”，使得其自动控制所有的形状对象。其中自然包括圆这一个对象。这一个特性成为对象的可替代性。是OOP的重要概念之一。  二、对象的接口 ","date":"2019-06-22T15:36:27+08:00","permalink":"https://example.com/p/java-1.%E5%AF%B9%E8%B1%A1%E5%85%A5%E9%97%A8/","title":"[ Java ] 1.对象入门"},{"content":"Java反射 一、反射： 1.概念： 反射，即：动态获取类的信息，以及动态调用对象的方法的功能。  2.作用：   在运行时判断任意一个对象所属的类\n  在运行时构造任意一个类的对象\n  在运行时判断任意一个类所具有的成员变量和方法\n  在运行时调用任意一个对象的方法\n可以生成动态代理\n  通过Java反射机制，可以在程序中访问已经装载到jvm中的Java对象的描述，以实现访问、检测和修改描述Java对象本身信息的功能。Java反射机制很强大。其中，java.lang.reflect包中提供了对该功能的支持。\n 二、实现反射获取类的方法： 方式一 ： 通过Class.forName(\u0026ldquo;类名字符串\u0026rdquo;)获取（最为常用的方法） //类名字符串是“包名+类名”，返回Class的对象。 Class class = Class.forName(\u0026#34;cheneyHao.Student\u0026#34;); 方式二 ： 通过示例对象的getClass()方法获取 //先创建一个对象，在调用对象的getClass()方法。（任何一个Java对象都会有getClass()方法） Student student = new Student(); Class class = student.getClass(); 方法三 ： 通过 .class 获取 //通过类名.class,返回Class对象。(每个类都有Class属性) Class class = Student.class; ","date":"2019-06-22T15:36:27+08:00","permalink":"https://example.com/p/java-2.java%E5%8F%8D%E5%B0%84/","title":"[ Java ] 2.Java反射"},{"content":"Java注解 1.基本语法 首先是注解的声明方式如下\n// @Target注解传入ElementType指明Nullable的作用域 @Target({ElementType.METHOD, ElementType.PARAMETER, ElementType.FIELD}) // @Retention注解用来指定其声明周期为运行时 @Retention(RetentionPolicy.RUNTIME) // @Documented指定Javadoc进行记录此对象 @Documented // @Nonnull为了告诉编译器这个域不可能为空 @Nonnull(when = When.MAYBE) // @TypeQualifierNickname为类型限定符别称(备注部分具体解释此注解) @TypeQualifierNickname public @interface Nullable { // @interface 声明注解 } 2.JDK元注解    Annotation Type Action     @Override 普通注解 用来限定子类重写父类的方法   @Deprecated 普通注解 标记已经过时的方法   @SuppressWarnings 普通注解 抑制编译器的警告   @SafeVarargs 普通注解 Java7 抑制“堆污染”警告   @FunctionalInterface 普通注解 Java8 函数式接口   @Retention 元注解 指定本修饰的注解可以保留多长时间   @Target 元注解 指定被修饰的注解能用于哪些程序元素   @Documented 元注解 被该注解修饰的注解会被javadoc工具提取成文档   @Inherited 元注解 此注解修饰的注解具有继承性   @Repeatable 元注解 重复注解，Java8的新特性    3.Retention    Retention Effect     CLASS 默认值，编译器将注解记录在字节码文件中，程序运行时，JVM不保留注解信息。   RUNTIME 编译器将注解记录在字节码文件中，程序运行时，JVM可以获得注解信息，可通过反射获取该注解的信息。   SOURCE 注解只保留在源代码中，编译器直接丢弃。    4.ElementType注解类型    ElementType Effect     TYPE 作用于类，接口，枚举   FIELD 作用于属性   METHOD 作用于函数   PARAMETER 作用于参数   CONSTRUCTOR 作用于构造函数   LOCAL_VARIABLE 作用于局部变量   ANNOTATION_TYPE 作用于注解   PACKAGE 作用于包   TYPE_PARAMETER 作用于类型变量(since 1.8)   TYPE_USER 作用于任何类型(since 1.8)    ","date":"2019-06-22T15:36:27+08:00","permalink":"https://example.com/p/java-3.java%E6%B3%A8%E8%A7%A3/","title":"[ Java ] 3.Java注解"},{"content":"三、Pod对象详解 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"4-1.K8s构建高可用Mysql集群 一、MySQL高可用架构图 1.主从复制+读写分离  此方案更适用于数据库读数据的场景(针对数据强一致性非严格的情况)，毕竟Replication存在一定的时延。 通过快速扩容Slave节点提高MySQL集群读取数据能力，不用过度依赖于Master节点。\n 实现过程 ①.为其提供PV存储盘 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"1.Kuberbetes-dashboard(Web UI)  Kuberbetes-dashboard是基于web的Kubernetes用户界面。\n ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"云原生 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"目录   云原生探索\n  第一部分-Goland学习\n Go并发  协程      第二部分-Docker\n 1.Docker命令 2.Docker安装 3.Docker之jdk最简镜像构建 4.Docker-SpringBoot构建 5.Docker-本地构建none包处理 6.Docker-Linux Namespace 7.Docker-Linux cgroup 8.Docker-Linux UFS    第三部分-Kubernetes\n 1.初识K8s  1-1.K8s基础 1-2.Kubectl工具 1-3.Kubeadm工具 1-4.Kubenetes集群初始化 1-5.Kubenetes之Helm包管理工具   2.深入Pod  2-1.Pod对象 2-2.Pod示例 2-3.Pod详解   3.深入Service  3-1.Service对象   4.K8s服务构建  4-1.Mysql-K8s主从构建   K8s-PlugIn  1.Dashboard插件       第四部分-ServiceMesh\n  ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"Go编程之指针 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"17.观察者模式 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"设计模式 设计模式是一把双刃剑。正确使用可以提高系统的适应性，误用、错用则会反过来降低系统的适应性。\n宗旨：帮助我们编写可复用的类，所谓的可复用：即，类的实现为‘组件’，当一个组件发生变化时，不需要对其他组件进行修改或者只需要做很小的改动。\n","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"2.Java基础 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"4.Java多线程 ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"Introduction ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"背景：不是为了推荐大家去使用Spring5 文档很少、资料难找 没有实战实践，包括老师自己没有用过 目的：1、带大家来看看眼界 2、了解一下未来的一个发展趋势\n鸡肋\n推荐：SpringBoot，Spring生态链（框架的框架）\nSpring5新特性：\n 依赖JDK 8+和Java EE7+以上版本 支持使用注解进行编程 新增函数式编程 支持使用REST断点执行反应式编程 支持HTTP 2.0 新增Kotlin和Spring WebFlux 可使用Lambda表达式注册Bean Spring WebMVC支持最新的API 使用JUnit5执行条件和并发测试 使用Spring WebFlux执行集成测试 核心容器优化  Spring5对WebFlux的支持\nSevlet2.x 单实例多线程的阻塞式IO （BIO） Sevlet3.x 单实例多线程异步非阻塞式IO （AIO异步非阻塞、NIO 同步非阻塞）\nWebFlux 是在Servlet3.x 的基础之上应运而生\n特点： 1、基于Servlet3.x 实现异步非阻塞的HTTP响应 2、API完美支持Rest风格 3、支持函数式编程 4、Mono是表示返回单个对象、Flux表示返回集合\n结论： 1、为了让大家开一下眼界，了解未来的发展趋势 2、如果要应用在项目之中，建议大家直接用Spring Boot\nSpring5集成测试 JUnit集成 1、 * @BeforeEach 相当于 JUnit 4 @Before * @BeforeAll 相当于 JUnit 4 @BeforeClass * @AfterEach 相当于 JUnit 4 @After * @AfterAll 相当于 JUnit 4 @AfterClass * @Test 不在org.unit这个包下，转到了org.junit.jupiter.api下 2、支持从外部注入参数\n问题收集：\n  问：刚才那个点重点说了多个线程，而完全没有强调非阻塞， 所有我才有一问好吧，如果讲过的所有点都必须百度过才懂， 课又有多大意义 答：只是为告诉大家有这个特性存在，多线程提升性能（高吞吐量的情况才能体现） 从框架内部解决了一些问题。\n  问：Spring和spring Boot的关系 答：Spring Boot是一个框架的框架，只要是在Spring生态之内，它真的能够实现零配置启动 集成的工具，框架（自己内部就实现了Web容器） http://start.spring.io/\n  问：老师说推荐用SpringBoot，不用WebFlux。 就是说Spring Boot Rest接口性能比Spring的好？ 答：不是这个意思，没有性能区别，只有方便与不方便的区别\n  问：SpringBoot有什么优势呢 面试会问的 答：以上可以回答此问题\n  问：SpringBoot不是方便创建工程吗？和Spring WebFlux关系大吗？ 答：以上可以回答此问题\n  问：怎么从官方文档之类的知道Spring需要哪些jar包？ 答：spring.io 官网上，啥都有 例如：https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html\n  问：AOP和Aspect的关系 答：asm是一个Java字节码操纵框架，它能被用来动态生成类或者增强既有类的功能。 asm \u0026ndash;\u0026gt; cglib(替代JDK Proxy) \u0026ndash;\u0026gt; aspect(作为SpringAOP底层支持) \u0026ndash;\u0026gt; AOP\n  问：MessageConverter 和Mono的作用相同，有没有区别和优劣 答：无所谓优势与劣势之说，无非就是应用环境不一样，在发展中进步 MessageConverter 旧版本的实现方式，手动 Mono 是新版的实现方式，使用更加方便，自动\n都是针对：Response 输出而进行处理 resp.getWrite(\u0026quot;\u0026quot;) 最底层实际都是对字符串的输出格式进行处理而已\n  问：Spring Bean IOC 容器为什么使用ConcurrentHashMap来存储，是由哪些原因导致 答：Spring的IOC容器包括很多种，最终都是会调用到DefaultListableBeanFactory(只实现了部分功能) XML Annotation Proxy Web 最终的容器会归总成一个，是不是有可能重复操作？（删、改、覆盖，取不会影响）\n  问：Spring事务，在Service方法中必须要抛异常，事务才会回滚么？ 答：当然，必须要抛异常，没有异常就认为没有出问题,也就不涉及到数据回滚。\n  问：能再详细说下Spring Web Flux的异步么？多线程就等于异步 答：是异步的。但是多线程不一定就是异步，但是在Java异步必须由多线程来实现。\n  ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"基于Spring5实现ORM 初衷： 单表查询不写一句SQL，自动生成 查询的结果自动映射为Java对象\n*1、我要传一个复杂的查询条件，怎么传？\n想到了用对象来传，但是有问题 a)、跨表联查的条件 b)、无法携带判断逻辑的运算符 c)、or 或者 and 无法区分\n 2、自动映射类型判断麻烦 ，用rs.getObject()方法  3、跨多种数据库如何统一API\n*4、数据源的动态切换如何来做？ AbstractRoutingDataSource数据源自动路由，执行数据连接以前，根据业务规则来动态获取到一个连接 从而达到动态切换数据库连接的效果 为了操作方便，每次执换完，执行成以后，会将数据源恢复到默认的设置\n*5、SQL注入 1、首先将QueryRule构建好，把所有的查询条件保存到一个ruleList中 2、再写一个工具类QueryRuleSqlBuilder，循环ruleList对每一个条件分别处理processAnything，主要是构建where后面语句 3、process以后propertisList 保存诸如 and name = ? ， values tom,利用索引位置相同，来进行一一对应\n问：selectbysql就相当于没有使用框架，不符合之前统一参数，统一查询方法拉？ 答：不推荐使用，如果一定要多表查询，只有两种方案 a) 写SQL语句 b) 查多次，在内存中处理数据关系，一般会在Service中进行处理 在Java代码中处理，会让程序员更加容易理解 如果给大串SQL，这后来接手的人直接想死 我见过一条SQL语句有10行之长的，我直接看晕了 \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 在我的团队中，极少数使用多表关联查询 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n问：······这个PK主键传过来怎么用？有什么好处 答：\u0026lt;T extends Serializable,PK extends Serializable\u0026gt; 传于不传不影响功能 目的：返回结果不需要再手动的强制类型转换\n问：如用老师这个框架来组装sql，复杂查询的话，会不会难以组装， 比如说查某个表的字段是另外一个表的条件，以此类推多个表的话？ 答：这就是属于多表查询\n问：连接操作，还有如果表没有主键PK 还需要传？ 答：只要用的我框架，每个表必须有主键，哪怕是自增 为了降低程序设计的复杂度\n","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"一、关于springboot项目基础知识 /** * 初始化用户信息 * 注：Spring Boot2不能像1.x一样，用spring.datasource.schema/data指定初始化SQL脚本，否则与actuator不能共存 * 原因详见： * https://github.com/spring-projects/spring-boot/issues/13042 * https://github.com/spring-projects/spring-boot/issues/13539 * * @param repository repo * @return runner */ @Bean ApplicationRunner init(UserRepository repository) { return args -\u0026gt; { User user1 = new User(1L, \u0026quot;account1\u0026quot;, \u0026quot;张三\u0026quot;, 20, new BigDecimal(100.00)); User user2 = new User(2L, \u0026quot;account2\u0026quot;, \u0026quot;李四\u0026quot;, 28, new BigDecimal(180.00)); User user3 = new User(3L, \u0026quot;account3\u0026quot;, \u0026quot;王五\u0026quot;, 32, new BigDecimal(280.00)); Stream.of(user1, user2, user3) .forEach(repository::save); }; }   @SpringBootApplication是一个组合注解，它整合了@Configuration、@EnableAutoConfiguration和@ComponentScan注解，并开启了Spring Boot程序的组件扫描和自动配置功能。在开发Spring Boot程序的过程中，常常会组合使用@Configuration、@EnableAutoConfiguration和@ComponentScan等注解，所以Spring Boot提供了@SpringBootApplication，来简化开发。\n  @Bean 则是一个方法注解，作用是实例化一个Bean并使用该方法的名称命名。\n  二、SpringCloud核心功能  Distributed/versioned configuration 分布式/版本化的配置管理 Service registration and discovery 服务注册与服务发现 Routing 路由 Service-to-service calls 端到端的调用 Load balancing 负载均衡 Circuit Breakers 断路器 Global locks 全局锁 Leadership election and cluster state 选举与集群状态管理 Distributed messaging 分布式消息  三、SpringBoot与SpringCloud版本对应关系    Spring Cloud版本 Spring Boot版本     Greenwich 2.1.x   Finchley 2.0.x   Edgware 1.5.x   Dalston 1.5.x    四、关于细节 Spring 5开始，WebFlux提供了Reactive的Web Client：WebClinet ，使用方式和RestTemplate基本类似，但性能更强，吞吐更好。\n","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"SpringCloudEureka注册中心 1.基础注解  @EnableEurekaServer:一般用在SpringBoot的启动类上,直接声明当前Project为注册与发现中心。\n  @EnableEurekaClient:一般用在SpringBoot的启动类上，表明当前Project是一个EurekaClient。 需要将其本身连接并发送基本信息至注册中心（这一过程即发现注册）\n 2.配置及用法 所有Eureka服务都被称作实例，但其角色有所不同，可将其分为两类EurekaServer与EurekaClient。EurekaClient也将有两种不同的角色出现：Application Provider与Application Consumer。\n EurekaInstance  EurekaServer：即为发现注册中心(同时EurekaServer也将是一个特殊的EurekaClient) EurekaClient：除发现注册中心之外的所有Eureka实例  ApplicationProvider：服务提供者 ApplicationConsumer：服务调用者      ### 以下一段内容将在EurekaInstanceProject中必须出现spring:application:name:icc-transfereureka:instance:# 声明当前实例的主机名称，用于发现注册hostname:cloud-eureka-peer1# 心跳频率，默认值30slease-renewal-interval-in-seconds:30# 无心跳超时频率，默认值90slease-expiration-duration-in-seconds:90# 以下内容将作为EurekaClient必须配置# 如果配置一个高可用的EurekaServer，也许进行此配置，EurekaServer将作为EurekaClient与其他节点进行数据同步client:serviceUrl:# 声明发现注册中心(EurekaServer)的地址defaultZone:http://cloud-eureka-peer:8080/eureka/,http://cloud-eureka-peer:8080/eureka/# 当前实例是否向EurekaServer注册自己，默认值为true即注册此实例register-with-eureka:true# 当前实例是否向EurekaServer服务器获取所有实例的注册信息表,默认值truefetch-registry:true# 拉取EurekaServer中EurekaInstance注册信息表频率,默认值为30sregister-fetch-interval-seconds:30","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"一、关于Spring Boot Actuator Spring Boot Actuator是Spring Boot官方提供的监控组件。只需为项目添加以下依赖，即可就整合Spring Boot Actuator。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 二、Actuator监控端点 只需访问http://{ip}:{port}/actuator/{endpoint} 端点，即可监控应用的运行状况。\n   端点（Spring Boot 2.x） 描述 HTTP方法 是否敏感 端点（Spring Boot 1.x）     conditions 显示自动配置的信息 GET 是 autoconfig   beans 显示应用程序上下文所有的Spring bean GET 是 beans   configprops 显示所有@ConfigurationProperties的配置属性列表 GET 是 configprops   dump 显示线程活动的快照 GET 是 dump   env 显示环境变量，包括系统环境变量以及应用环境变量 GET 是 env   health 显示应用程序的健康指标，值由HealthIndicator的实现类提供；结果有UP、 DOWN、OUT_OF_SERVICE、UNKNOWN；如需查看详情，需配置：management.endpoint.health.show-details GET 否 health   info 显示应用的信息，可使用info.* 属性自定义info端点公开的数据 GET 否 info   mappings 显示所有的URL路径 GET 是 mappings   metrics 显示应用的度量标准信息 GET 是 metrics    ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"GatewayCloud网关服务 1.项目配置说明 1.1 关于Project Yaml配置文件 spring:cloud:gateway:routes:# 自定义路由ID，要保持唯一- id:device# 目标服务地址(lb标识集群)uri:lb://cloud-service-media# 路由条件，Predicate接受一个输入参数，返回一个bool值。通过多种默认方法将Predicates组合成一个复杂路由逻辑# Predicate函数源于Java8，具体使用可参考Java源码进一步了解# 当匹配规则存在多种情况时，一个请求满足多个路由条件是请求将被第一个路由转发predicates:# 通过请求路径匹配- Path=/device# 通过时间匹配- After=2020-04-20T06:06:06+08:00[Asia/Shanghai]# 通过Cookie匹配- Cookie=cloudp.cc,cheneyin# 通过Header匹配- Header=X-Request-Id, \\d+# 通过Host匹配- Host=**.cloudp.cc# 通过请求匹配- Method=GET# 通过请求方式匹配- Query=deviceMac# 通过请求IP匹配- RemoteAddr=192.168.1.1/24","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"服务提供者、服务消费者、服务发现组件这三者之间的关系大致如下：\n 各个微服务在启动时，将自己的网络地址等信息注册到服务发现组件中，服务发现组件会存储这些信息； 服务消费者可从服务发现组件查询服务提供者的网络地址，并使用该地址调用服务提供者的接口； 各个微服务与服务发现组件使用一定机制（例如心跳）通信。服务发现组件如长时间无法与某微服务实例通信，就会自动注销（即：删除）该实例； 当微服务网络地址发生变更（例如实例增减或者IP端口发生变化等）时，会重新注册到服务发现组件； 客户端缓存：各个微服务将需要调用服务的地址缓存在本地，并使用一定机制更新（例如定时任务更新、事件推送更新等）。这样既能降低服务发现组件的压力，同时，即使服务发现组件出问题，也不会影响到服务之间的调用。  综上，服务发现组件应具备以下功能。\n 服务注册表：服务注册表是服务发现组件的核心（其实就是类似于上面的registry表），它用来记录各个微服务的信息，例如微服务的名称、IP、端口等。服务注册表提供查询API和管理API，查询API用于查询可用的微服务实例，管理API用于服务的注册和注销； 服务注册与服务发现：服务注册是指微服务在启动时，将自己的信息注册到服务发现组件上的过程。服务发现是指查询可用微服务列表及其网络地址的机制； 服务检查：服务发现组件使用一定机制定时检测已注册的服务，如发现某实例长时间无法访问，就会从服务注册表中移除该实例。  Spring Cloud为我们提供多种服务发现组件的支持，例如Eureka、Consul（spring-cloud-consul）、Zookeeper（spring-cloud-zookeeper）、Aliaba Nacos（孵化中：spring-cloud-alibaba）、Etcd（孵化中：spring-cloud-etcd）等。\n","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"目录  前言 第一部分:Spring5 第二部分:SpringBoot 第三部分:SpringCloud  1-SpringCloud注册中心  1-1.EurekaServer配置   2-SpringCloud网关  2-1.Gateway网关配置   3-SpringCloud配置中心 4-SpringCloud链路跟踪  4-1.分布式链路跟踪Sleuth      ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"一、OpenCV-Java的入门  OpenCV的Java官方文档地址\n 1.OpenCV的Java环境构建 首先，声明一下在本文中选用的环境配置如下：\n  MacOS操作系统\n  IntelliJ IDEA开发编译器\n   MacOS的安装有两种方式：一种是靠强大的BrewHome安装器自动安装；另外一种就是相对麻烦的手动安装了。\n在这里我选择的是BrewHome进行安装。（前提是MacOS已经安装了BrewHome）\n","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"一、相关概念的简介  在了解深度学习前应该还有两个专业名词大家也想必是耳熟能详，那么就是人工智能、机器学习。\n  人工智能(Artificial Intelligence)：也就是我们经常听到的AI。它是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。但是在早期的时候，人工智能充满了局限性，只是在特定的环境范围下。 机器学习(Machine Learning)：简称ML。机器学习其实是人工智能的一个分支。如果一个程序可以在**任务*(T)上，随着经验(E)***的增加，*效果(P)***也可以随之增加，则就可以说这个程序可以从经验中得到学习。 深度学习(Deep Learning)：简称DL。深度学习也是机器学习的一个分支。主要是在机器学习的基础之上有所改进：它除了可以学习特征和任务之间的关联，还可以自动的将简单的特征组合成更加复杂的特征，并使用这些组合特征解决问题。   二、了解机器学习(ML)  1. 用例子认识机器学习的概念 其实，邮件系统中判断收到的邮件是否为垃圾邮件就可以看做是一个机器学习的过程。首先对垃圾邮件分类概念进行一个拆分、类比：\n  一个程序 \u0026lt;======\u0026gt; 需要用到的机器学习算法，比如逻辑回归算法 任务(T) \u0026lt;======\u0026gt; 区分此邮件是否是垃圾邮件这个任务 经验(E) \u0026lt;======\u0026gt; 已经区分过是否为垃圾邮件的历史事件 效果(P) \u0026lt;======\u0026gt; 机器学习算法在区分此邮件是否是垃圾邮件这个任务的精确率   在整个过程中，首先会从每一封邮件中抽取出对分类结果可能有影响的因素（比如：发件人的地址、邮件的标题、收件人的数量、邮件正题内容，so on）。这样的每一个**因素**其实可以成为是一个**特征** ***(feature)***。然而机器学习算法中的**逻辑回归算法**可以从训练数据中计算出每个特征和预测结果的相关度。例如，在垃圾邮件分类过程中，可能会发现如果一个邮件的收件人越多，那么这封邮件是垃圾邮件的可能性越大。 在对一封完全未知的邮件进行区分时，**逻辑回归算法**会根据这封邮件中抽取到的每一个**特征**以及**这些特征**和垃圾邮件的**相关度**进行判断是否为垃圾邮件。 所以，从例子中不难看出：一般情况下，在训练数据达到一定数量之前，越多的训练数据可以使得逻辑回归算法对未知邮件做出的判断越精确。\n 也就是说**逻辑回归算法可以根据训练数据【经验(E)】提高垃圾邮件分类问题【任务(T)】上的准确率【效果(P)】**\n 2.机器学习的分类  有监督学习(Supervised Learning)   有监督学习可分为回归和分类问题。例如上述示例垃圾邮件分类就属于有监督学习。 1.在回归问题中，我们会预测一个连续值；也就是我们试图将输入变量和输出用一个连续函数对应起来。 2.在分类问题中，我们会预测一个离散值，我们试图将输入变量与离散的类别对应起来。\n  无监督学习(Unsupervised Leanring)   这种学习方式，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。\n  增强式学习(Reinforcement Learning)   输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。\n ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"一、关于神经网络  训练神经网络主要包含以下四部分：  层，多个层组合成网络(模型) 输入数据和相应的目标 损失函数，即用于学习的反馈信号 优化器，决定学习过程如何进行    ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":" ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"Introduction ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"Linux杂记  CentOS系统基本操作  1.命令操作  ①.sed、grep、awk命令操作   2.CentOS修改镜像源   CentOS之KVM操作  1.KVM笔记    ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""},{"content":"Linux的虚拟网络设备  Bridge TAP VLAN Veth MacVlan IPVlan   ","date":"0001-01-01T00:00:00Z","permalink":"https://example.com/p/","title":""}]